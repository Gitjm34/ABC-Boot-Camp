{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1970년대 보스턴 지역의 주택 가격을 예측하는 회귀 문제"
      ],
      "metadata": {
        "id": "VOLF2pYO8wal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 보스턴 주택 가격 데이터 준비하기"
      ],
      "metadata": {
        "id": "yy1C6cAL86rv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qORKQ5hH8fIN",
        "outputId": "0ca48e6f-d8a6-482e-e130-0c80f4f3c25c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57026/57026 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets.boston_housing import load_data\n",
        "\n",
        "# 데이터 다운로드 (훈련셋 80 : 테스트셋 20)\n",
        "(X_train, y_train), (X_test, y_test) = load_data(path = 'boston_housing.npz',\n",
        "                                                 test_split = 0.2,\n",
        "                                                 seed = 777)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 형태 확인하기"
      ],
      "metadata": {
        "id": "N1c4a-6x9nyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_train.shape', X_train.shape) # 정답까지 포함하면 14개의 feature\n",
        "print('y_train.shape', y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnHTO3Xp9JIq",
        "outputId": "e7584ab1-202a-4391-ec21-3bb90a6b382e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape (404, 13)\n",
            "y_train.shape (404,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_test.shape', X_test.shape) # 정답까지 포함하면 14개의 feature\n",
        "print('y_test.shape', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5krQwzqh95ZF",
        "outputId": "fdefd8f1-6a64-407a-86a8-ef36d056f5f8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test.shape (102, 13)\n",
            "y_test.shape (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train) # type() : 어떤 데이터 형태인지 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-Nhf_F--LuK",
        "outputId": "81ef9288-4684-4eb4-e7f5-9878a8bdf43d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 어떻게 데이터 전처리할지 파악하기 위해 데이터를 직접 확인\n",
        "X_train[0] # 각 feature의 값이 13개 들어 있음\n",
        "\n",
        "# feature마다 범위가 들쑥날쑥하므로 표준화를 활용해서 데이터 전처리하는 게 바람직함\n",
        "# 표준화 : 데이터에서 평균을 빼고, 표준편차로 나눠줌"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO55cswY-vt9",
        "outputId": "e503c72f-b8c1-4638-d551-a868aab07e30"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.5199e-01, 0.0000e+00, 1.0590e+01, 0.0000e+00, 4.8900e-01,\n",
              "       5.7830e+00, 7.2700e+01, 4.3549e+00, 4.0000e+00, 2.7700e+02,\n",
              "       1.8600e+01, 3.8943e+02, 1.8060e+01])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0] # 집값이 담겨 있음 (천 달러 단위)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYHt-bHq-g5k",
        "outputId": "abff9f53-fe89-41fb-fa65-93d15d854f20"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22.5"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리 (feature만) - 표준화 (Standardzation)"
      ],
      "metadata": {
        "id": "Tb_Rd0w8-J03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 표준화 : (데이터 - 전체 평균) / 표준편차\n",
        "mean = np.mean(X_train, axis = 0) # 모든 데이터의 평균을 구해야 하기 때문에, axis는 0\n",
        "std = np.std(X_train, axis = 0)"
      ],
      "metadata": {
        "id": "orEaZcymALJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train을 전처리했기 때문에, X_test도 전처리해 줘야 함\n",
        "# 전처리에서는 X_train과 X_test 둘 다 처리\n",
        "# 만약 처음부터 데이터가 합쳐진 상태에서 받아왔다면, 전처리 이후에 X_train과 X_test로 분리하는 게 더 편리함\n",
        "\n",
        "X_train = (X_train - mean) / std\n",
        "X_test = (X_test - mean) / std\n",
        "\n",
        "print(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzOH3bNTBQgg",
        "outputId": "273bcea3-86f6-473f-81e9-36b282327346"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.40102395 -0.48033655 -0.12089418 -0.28828791 -0.58254176 -0.68137272\n",
            "  0.11117586  0.26484408 -0.65187119 -0.80249043  0.0756568   0.37366783\n",
            "  0.69211835]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 검증 데이터셋 분리하기"
      ],
      "metadata": {
        "id": "aSzCPVxTB9EC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
        "                                                  test_size = 0.33, random_state = 777)\n",
        "\n",
        "print(X_train.shape, X_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YoNJ3MPCA3C",
        "outputId": "115b6df6-3f36-4a34-d8f4-b1bfaaaee993"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(270, 13) (134, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 구성하기"
      ],
      "metadata": {
        "id": "0NxhQxc_GmKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(64, activation = 'relu', input_shape = (13, )))\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dense(1)) # 집값을 예측하므로 출력값 1개 / activation 지정하지 않으면 기본값 'linear'"
      ],
      "metadata": {
        "id": "NIDoYO-BCbgy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 설정하기"
      ],
      "metadata": {
        "id": "P93_Gab-HZxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'mse', # 오차율이 가장 중요한 데이터이므로 'mse' (실제 집값과 예측 집값의 차이)\n",
        "              metrics = ['mae', 'mse']) # 회귀 모델에서 사용하는 성능 평가 지표\n",
        "\n",
        "# mse, mae : 둘 다 오차를 양수로 만드는 방법  (실제 정답보다 적어서 오차이든 많아서 오차이든 동일한 오차율로 내기 위함)\n",
        "# mae : 절댓값으로 오차율 계산 - 음수인 값만 양수로 변경하여 비교\n",
        "# mse : 제곱값으로 오차율 계산 - 음수인 값과 양수인 값 모두 제곱을 계산하여 비교"
      ],
      "metadata": {
        "id": "UaAg6Cb2Gv3R"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습하기"
      ],
      "metadata": {
        "id": "htArEi6bJEwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs = 300,\n",
        "                    validation_data = (X_val, y_val))"
      ],
      "metadata": {
        "id": "xmojBM2mJGKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습 결과 분석"
      ],
      "metadata": {
        "id": "33CNlEhXJ9tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "his_dict = history.history\n",
        "mse = his_dict['mse']\n",
        "val_mse = his_dict['val_mse'] # 검증 데이터가 있는 경우 ‘val_’ 수식어가 붙습니다.\n",
        "\n",
        "epochs = range(1, len(mse) + 1)\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "\n",
        "# 훈련 및 검증 손실 그리기\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax1.plot(epochs, mse, color = 'blue', label = 'train_mse')\n",
        "ax1.plot(epochs, val_mse, color = 'orange', label = 'val_mse')\n",
        "ax1.set_title('train and val mse')\n",
        "ax1.set_xlabel('epochs')\n",
        "ax1.set_ylabel('mse')\n",
        "ax1.legend()\n",
        "\n",
        "mae = his_dict['mae']\n",
        "val_mae = his_dict['val_mae']\n",
        "\n",
        "# 훈련 및 검증 정확도 그리기\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "ax2.plot(epochs, mae, color = 'blue', label = 'train_mae')\n",
        "ax2.plot(epochs, val_mae, color = 'orange', label = 'val_mae')\n",
        "ax2.set_title('train and val mae')\n",
        "ax2.set_xlabel('epochs')\n",
        "ax2.set_ylabel('mae')\n",
        "ax2.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# 회귀 모델에서는 상승하는 그래프는 나오지 않음\n",
        "# 회귀 모델에서 훈련셋은 오차율 0을 만들 때까지 학습하고, 검증셋은 일정 오차율 이후로 떨어지지 않음\n",
        "# → 그 시점 이후로는 훈련셋과 검증셋의 오차율이 벌어지기만 하게 됨 (과대적합)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "lJhIWAhDJ_7e",
        "outputId": "33b014f8-baa8-4faf-d898-8d6c37124db0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 평가하기"
      ],
      "metadata": {
        "id": "ozof8m-jLeJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test) # 한 번도 학습하지 않았던 테스트셋으로 평가\n",
        "# 모델 오차율 2.14 → 실제 집값과 +-2,140 달러 정도 차이로 집값을 예측"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW_1XhGqLflY",
        "outputId": "85e8cdf9-8893-4b00-f85f-5bdde4830b50"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step - loss: 9.1186 - mae: 2.1440 - mse: 9.1186\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9.11860466003418, 2.1440281867980957, 9.11860466003418]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 예측하고 결과 확인"
      ],
      "metadata": {
        "id": "e2D7_s3aMIXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model.predict(X_test).flatten()\n",
        "\n",
        "plt.scatter(y_test, test_predictions) # (실제 정답, 모델 예측값)\n",
        "plt.xlabel('True Values [Price]')\n",
        "plt.ylabel('Predictions [Price]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])\n",
        "\n",
        "# 결과 해석\n",
        "# (기준선 아래에 더 많은 점이 찍혀 있으므로) 모델은 주로 실제 집값보다 더 낮게 집값을 예측하고 있음을 확인 가능함\n",
        "# 실제 집값이 싸거나(10~20) 비쌀수록(40~50) 오차율이 심해지고 있음을 확인 가능 → 집값이 쌀 때와 비쌀 때의 데이터를 더 수집하여 학습시켜야겠다는 생각"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "LZnnuJizLlx5",
        "outputId": "c19541ef-1fc4-4237-96c1-ad565e41fd1d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Fold 사용하여 모델 학습하기\n",
        "\n",
        "*   학습 데이터셋 부족으로 성능이 낮은 경우 적용 가능\n",
        "*   검증 데이터셋을 K-Fold로 사용하여, 학습 데이터셋 확보\n",
        "\n"
      ],
      "metadata": {
        "id": "b6r5H7WWNeKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Fold를 위한 데이터 준비하기"
      ],
      "metadata": {
        "id": "f4-mjdOhN7Jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets.boston_housing import load_data\n",
        "\n",
        "# 데이터 다운로드 (훈련셋 80 : 테스트셋 20)\n",
        "(X_train, y_train), (X_test, y_test) = load_data(path = 'boston_housing.npz',\n",
        "                                                 test_split = 0.2,\n",
        "                                                 seed = 777)"
      ],
      "metadata": {
        "id": "F_rA5sy5NzNi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 전처리"
      ],
      "metadata": {
        "id": "dFa3BtHmOFj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 표준화 : (데이터 - 전체 평균) / 표준편차\n",
        "mean = np.mean(X_train, axis = 0) # 모든 데이터의 평균을 구해야 하기 때문에, axis는 0\n",
        "std = np.std(X_train, axis = 0)\n",
        "\n",
        "# X_train을 전처리했기 때문에, X_test도 전처리해 줘야 함\n",
        "# 전처리에서는 X_train과 X_test 둘 다 처리\n",
        "# 만약 처음부터 데이터가 합쳐진 상태에서 받아왔다면, 전처리 이후에 X_train과 X_test로 분리하는 게 더 편리함\n",
        "\n",
        "X_train = (X_train - mean) / std\n",
        "X_test = (X_test - mean) / std"
      ],
      "metadata": {
        "id": "9On79mH2OEfa"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Fold를 사용한 모델 학습"
      ],
      "metadata": {
        "id": "mfUKh0PTOUXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# 몇 번에 나눠서 학습할 것인지 k를 지정해 줘야 함\n",
        "# 3-Fold로 나눠서 검증 데이터셋 사용하여 학습\n",
        "k = 3\n",
        "\n",
        "kfold = KFold(n_splits = k) # n_splits : 몇 개로 나눠서 학습할지\n",
        "\n",
        "# 재사용을 위해 모델 구성 및 설정 함수로 선언\n",
        "\n",
        "def get_model() :\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(64, activation = 'relu', input_shape = (13, )))\n",
        "  model.add(Dense(32, activation = 'relu'))\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# 각 모델(3개의 KFold)의 평가 정보 담는 리스트 선언\n",
        "mae_list = []\n",
        "\n",
        "# k번 학습 및 평가\n",
        "for train_idx, val_idx in kfold.split(X_train) :\n",
        "  # 각각의 fold를 만드는 과정 : 학습 데이터와 검증 데이터 분리\n",
        "  X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
        "  y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "  # 모델 불러오기\n",
        "  model = get_model()\n",
        "\n",
        "  # 모델 학습하기 → 총 3번(900) 학습될 것\n",
        "  model.fit(X_train_fold, y_train_fold,\n",
        "            epochs = 300, validation_data = (X_val_fold, y_val_fold))\n",
        "\n",
        "  # 모델 평가하기\n",
        "  _, test_mae = model.evaluate(X_test, y_test) # _, : 첫 번째 평가 결과인 loss는 사용 안 한다는 의미\n",
        "  mae_list.append(test_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8ucCwB5Obk3",
        "outputId": "1278fb67-33aa-4f43-ec1d-15584cc88efc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 25ms/step - loss: 585.3326 - mae: 22.3988 - val_loss: 553.8597 - val_mae: 21.7828\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 554.8535 - mae: 21.7579 - val_loss: 527.6288 - val_mae: 21.1892\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 526.7626 - mae: 21.1308 - val_loss: 500.5550 - val_mae: 20.5652\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 496.1549 - mae: 20.4383 - val_loss: 470.1035 - val_mae: 19.8472\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 460.7883 - mae: 19.6204 - val_loss: 433.4684 - val_mae: 18.9600\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 417.5748 - mae: 18.5761 - val_loss: 389.8819 - val_mae: 17.8714\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 366.9645 - mae: 17.3361 - val_loss: 340.0340 - val_mae: 16.5494\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 311.0723 - mae: 15.8099 - val_loss: 285.0155 - val_mae: 14.9586\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 253.4145 - mae: 14.0323 - val_loss: 227.7330 - val_mae: 13.0993\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 196.0719 - mae: 12.0068 - val_loss: 175.9679 - val_mae: 11.1957\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 149.5555 - mae: 10.1252 - val_loss: 132.1974 - val_mae: 9.4407\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 111.7806 - mae: 8.4974 - val_loss: 100.0476 - val_mae: 7.9698\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 89.1068 - mae: 7.3291 - val_loss: 77.5098 - val_mae: 6.8986\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 73.0109 - mae: 6.5486 - val_loss: 62.6616 - val_mae: 6.1493\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 60.7413 - mae: 5.9534 - val_loss: 52.5998 - val_mae: 5.5562\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 52.0337 - mae: 5.5271 - val_loss: 44.7701 - val_mae: 5.0337\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 44.9813 - mae: 5.1300 - val_loss: 39.1190 - val_mae: 4.6212\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 39.5442 - mae: 4.8017 - val_loss: 34.7294 - val_mae: 4.3240\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 35.2118 - mae: 4.4711 - val_loss: 31.3137 - val_mae: 4.0980\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 32.1520 - mae: 4.2208 - val_loss: 28.8645 - val_mae: 3.9335\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 29.4556 - mae: 3.9957 - val_loss: 27.1373 - val_mae: 3.8130\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 27.5144 - mae: 3.8122 - val_loss: 26.0665 - val_mae: 3.7384\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 25.9434 - mae: 3.6661 - val_loss: 25.2312 - val_mae: 3.6746\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 24.8451 - mae: 3.5506 - val_loss: 24.5502 - val_mae: 3.6320\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 23.8746 - mae: 3.4653 - val_loss: 24.0193 - val_mae: 3.5995\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 22.9998 - mae: 3.3946 - val_loss: 23.5848 - val_mae: 3.5767\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 22.4038 - mae: 3.3423 - val_loss: 23.2185 - val_mae: 3.5560\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 21.7507 - mae: 3.2900 - val_loss: 22.9332 - val_mae: 3.5341\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 21.1726 - mae: 3.2331 - val_loss: 22.6655 - val_mae: 3.5110\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 20.6574 - mae: 3.1815 - val_loss: 22.3527 - val_mae: 3.4868\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 20.3503 - mae: 3.1573 - val_loss: 22.1318 - val_mae: 3.4709\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 19.8277 - mae: 3.1056 - val_loss: 21.9148 - val_mae: 3.4486\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 19.4355 - mae: 3.0512 - val_loss: 21.7069 - val_mae: 3.4302\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 19.0629 - mae: 3.0200 - val_loss: 21.5350 - val_mae: 3.4170\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 18.7031 - mae: 2.9804 - val_loss: 21.3831 - val_mae: 3.4050\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 18.4272 - mae: 2.9568 - val_loss: 21.0916 - val_mae: 3.3902\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 17.9398 - mae: 2.9347 - val_loss: 20.9150 - val_mae: 3.3766\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 17.6535 - mae: 2.8977 - val_loss: 20.7660 - val_mae: 3.3609\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 17.3566 - mae: 2.8658 - val_loss: 20.6463 - val_mae: 3.3479\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 17.0723 - mae: 2.8342 - val_loss: 20.4311 - val_mae: 3.3291\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.7947 - mae: 2.8149 - val_loss: 20.2196 - val_mae: 3.3103\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 16.6095 - mae: 2.7841 - val_loss: 20.1020 - val_mae: 3.2919\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 16.3053 - mae: 2.7563 - val_loss: 19.9274 - val_mae: 3.2767\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 16.0593 - mae: 2.7353 - val_loss: 19.7282 - val_mae: 3.2543\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.8218 - mae: 2.7077 - val_loss: 19.5495 - val_mae: 3.2355\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.5744 - mae: 2.6868 - val_loss: 19.4523 - val_mae: 3.2266\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.3557 - mae: 2.6731 - val_loss: 19.2917 - val_mae: 3.2180\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.1573 - mae: 2.6683 - val_loss: 19.1426 - val_mae: 3.2073\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.9444 - mae: 2.6397 - val_loss: 19.0002 - val_mae: 3.1869\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.7401 - mae: 2.6092 - val_loss: 18.8864 - val_mae: 3.1710\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.6468 - mae: 2.6026 - val_loss: 18.6648 - val_mae: 3.1615\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.3293 - mae: 2.5845 - val_loss: 18.5972 - val_mae: 3.1489\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.1787 - mae: 2.5725 - val_loss: 18.5590 - val_mae: 3.1468\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.0704 - mae: 2.5529 - val_loss: 18.4610 - val_mae: 3.1311\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.9053 - mae: 2.5422 - val_loss: 18.2635 - val_mae: 3.1201\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.8404 - mae: 2.5456 - val_loss: 18.2256 - val_mae: 3.1182\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.5357 - mae: 2.5169 - val_loss: 18.1738 - val_mae: 3.1141\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.4506 - mae: 2.4962 - val_loss: 18.1939 - val_mae: 3.1156\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.2768 - mae: 2.4825 - val_loss: 17.9899 - val_mae: 3.1014\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.1961 - mae: 2.4847 - val_loss: 17.8030 - val_mae: 3.0926\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.0210 - mae: 2.4904 - val_loss: 17.7162 - val_mae: 3.0888\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.8269 - mae: 2.4648 - val_loss: 17.7177 - val_mae: 3.0805\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.7397 - mae: 2.4471 - val_loss: 17.6536 - val_mae: 3.0775\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.6072 - mae: 2.4442 - val_loss: 17.5331 - val_mae: 3.0737\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.5290 - mae: 2.4634 - val_loss: 17.3381 - val_mae: 3.0657\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.3976 - mae: 2.4564 - val_loss: 17.3007 - val_mae: 3.0594\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.2685 - mae: 2.4315 - val_loss: 17.2424 - val_mae: 3.0541\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 12.1523 - mae: 2.4211 - val_loss: 17.1652 - val_mae: 3.0519\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 12.0993 - mae: 2.4203 - val_loss: 17.0885 - val_mae: 3.0417\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.9235 - mae: 2.4004 - val_loss: 17.0691 - val_mae: 3.0431\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.8592 - mae: 2.3995 - val_loss: 16.9414 - val_mae: 3.0370\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 11.7340 - mae: 2.3870 - val_loss: 16.9072 - val_mae: 3.0281\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.6299 - mae: 2.3694 - val_loss: 16.8498 - val_mae: 3.0226\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 11.6072 - mae: 2.3665 - val_loss: 16.8660 - val_mae: 3.0194\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.4432 - mae: 2.3558 - val_loss: 16.7103 - val_mae: 3.0114\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.3616 - mae: 2.3499 - val_loss: 16.6528 - val_mae: 3.0036\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.3033 - mae: 2.3401 - val_loss: 16.6097 - val_mae: 2.9981\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.2230 - mae: 2.3502 - val_loss: 16.6034 - val_mae: 3.0211\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.1823 - mae: 2.3612 - val_loss: 16.5459 - val_mae: 3.0156\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.1332 - mae: 2.3379 - val_loss: 16.7082 - val_mae: 3.0153\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.9767 - mae: 2.3140 - val_loss: 16.5690 - val_mae: 3.0034\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 10.8833 - mae: 2.3118 - val_loss: 16.5330 - val_mae: 3.0051\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 10.7847 - mae: 2.3054 - val_loss: 16.4817 - val_mae: 3.0030\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 10.6955 - mae: 2.2999 - val_loss: 16.5121 - val_mae: 3.0059\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 10.6088 - mae: 2.2896 - val_loss: 16.4920 - val_mae: 2.9993\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 10.5191 - mae: 2.2767 - val_loss: 16.3950 - val_mae: 2.9924\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 10.4457 - mae: 2.2734 - val_loss: 16.3315 - val_mae: 2.9879\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 10.3363 - mae: 2.2597 - val_loss: 16.3413 - val_mae: 2.9842\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 10.3333 - mae: 2.2516 - val_loss: 16.3889 - val_mae: 2.9881\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 10.1676 - mae: 2.2400 - val_loss: 16.3099 - val_mae: 2.9883\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 10.1491 - mae: 2.2434 - val_loss: 16.2437 - val_mae: 2.9834\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 10.1080 - mae: 2.2459 - val_loss: 16.1556 - val_mae: 2.9808\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.9673 - mae: 2.2274 - val_loss: 16.1087 - val_mae: 2.9698\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.8856 - mae: 2.2204 - val_loss: 16.0666 - val_mae: 2.9626\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.8343 - mae: 2.2170 - val_loss: 16.0627 - val_mae: 2.9694\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.7602 - mae: 2.2126 - val_loss: 15.9847 - val_mae: 2.9648\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.6676 - mae: 2.2031 - val_loss: 15.9313 - val_mae: 2.9606\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.6026 - mae: 2.1954 - val_loss: 15.8543 - val_mae: 2.9439\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.4983 - mae: 2.1811 - val_loss: 15.8684 - val_mae: 2.9504\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.4750 - mae: 2.1811 - val_loss: 15.8819 - val_mae: 2.9572\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.4069 - mae: 2.1713 - val_loss: 15.8193 - val_mae: 2.9518\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.3239 - mae: 2.1625 - val_loss: 15.8010 - val_mae: 2.9542\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.2880 - mae: 2.1593 - val_loss: 15.7528 - val_mae: 2.9405\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.2132 - mae: 2.1578 - val_loss: 15.5440 - val_mae: 2.9271\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.0976 - mae: 2.1467 - val_loss: 15.5156 - val_mae: 2.9251\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.9970 - mae: 2.1332 - val_loss: 15.4433 - val_mae: 2.9213\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.0336 - mae: 2.1423 - val_loss: 15.4818 - val_mae: 2.9217\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.9099 - mae: 2.1250 - val_loss: 15.5010 - val_mae: 2.9149\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.7557 - mae: 2.1094 - val_loss: 15.4019 - val_mae: 2.9110\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.7905 - mae: 2.1174 - val_loss: 15.4950 - val_mae: 2.9327\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.6647 - mae: 2.1117 - val_loss: 15.5792 - val_mae: 2.9361\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.5631 - mae: 2.0952 - val_loss: 15.5835 - val_mae: 2.9407\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.4954 - mae: 2.0906 - val_loss: 15.5573 - val_mae: 2.9297\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.5816 - mae: 2.0973 - val_loss: 15.4373 - val_mae: 2.9124\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.4548 - mae: 2.0773 - val_loss: 15.4102 - val_mae: 2.9205\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.2727 - mae: 2.0650 - val_loss: 15.3240 - val_mae: 2.9128\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.1886 - mae: 2.0522 - val_loss: 15.3299 - val_mae: 2.9112\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.1666 - mae: 2.0507 - val_loss: 15.3009 - val_mae: 2.9068\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.0319 - mae: 2.0353 - val_loss: 15.1743 - val_mae: 2.8953\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.0145 - mae: 2.0366 - val_loss: 15.1716 - val_mae: 2.8994\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.9276 - mae: 2.0186 - val_loss: 15.1196 - val_mae: 2.8854\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.8702 - mae: 2.0131 - val_loss: 15.1122 - val_mae: 2.8888\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.7848 - mae: 2.0080 - val_loss: 15.1926 - val_mae: 2.8920\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.7207 - mae: 1.9934 - val_loss: 15.0481 - val_mae: 2.8839\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.6179 - mae: 1.9892 - val_loss: 15.0654 - val_mae: 2.8857\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.5757 - mae: 1.9907 - val_loss: 15.0177 - val_mae: 2.8837\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.5830 - mae: 1.9870 - val_loss: 14.9425 - val_mae: 2.8771\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.5392 - mae: 1.9753 - val_loss: 15.1475 - val_mae: 2.8770\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.4789 - mae: 1.9739 - val_loss: 15.0340 - val_mae: 2.8726\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3781 - mae: 1.9651 - val_loss: 14.8326 - val_mae: 2.8558\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.2462 - mae: 1.9474 - val_loss: 14.8438 - val_mae: 2.8565\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.2103 - mae: 1.9480 - val_loss: 14.9303 - val_mae: 2.8688\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.1069 - mae: 1.9325 - val_loss: 14.8514 - val_mae: 2.8614\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.0428 - mae: 1.9195 - val_loss: 14.7687 - val_mae: 2.8529\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.9990 - mae: 1.9117 - val_loss: 14.7380 - val_mae: 2.8468\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.9797 - mae: 1.9191 - val_loss: 14.8856 - val_mae: 2.8690\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.8833 - mae: 1.9055 - val_loss: 14.7464 - val_mae: 2.8535\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.8371 - mae: 1.8981 - val_loss: 14.7271 - val_mae: 2.8460\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7853 - mae: 1.8895 - val_loss: 14.7610 - val_mae: 2.8443\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8239 - mae: 1.9089 - val_loss: 14.8104 - val_mae: 2.8600\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.6463 - mae: 1.8844 - val_loss: 14.6726 - val_mae: 2.8323\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.6404 - mae: 1.8725 - val_loss: 14.6334 - val_mae: 2.8290\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.6355 - mae: 1.8757 - val_loss: 14.5917 - val_mae: 2.8223\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5873 - mae: 1.8614 - val_loss: 14.5535 - val_mae: 2.8137\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.4954 - mae: 1.8575 - val_loss: 14.4365 - val_mae: 2.8122\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.5011 - mae: 1.8624 - val_loss: 14.5097 - val_mae: 2.8282\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.4080 - mae: 1.8478 - val_loss: 14.4716 - val_mae: 2.8079\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.3678 - mae: 1.8430 - val_loss: 14.4450 - val_mae: 2.8078\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.3002 - mae: 1.8417 - val_loss: 14.4821 - val_mae: 2.8179\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.1929 - mae: 1.8260 - val_loss: 14.4858 - val_mae: 2.8060\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.1942 - mae: 1.8170 - val_loss: 14.6500 - val_mae: 2.8183\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.1492 - mae: 1.8102 - val_loss: 14.5441 - val_mae: 2.8102\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0637 - mae: 1.8071 - val_loss: 14.4566 - val_mae: 2.8003\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.0236 - mae: 1.8035 - val_loss: 14.5190 - val_mae: 2.8109\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9709 - mae: 1.8025 - val_loss: 14.5732 - val_mae: 2.8141\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9321 - mae: 1.7920 - val_loss: 14.5306 - val_mae: 2.8091\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9234 - mae: 1.7979 - val_loss: 14.5441 - val_mae: 2.8150\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8643 - mae: 1.7884 - val_loss: 14.6387 - val_mae: 2.8166\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8984 - mae: 1.7876 - val_loss: 14.5946 - val_mae: 2.7993\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8651 - mae: 1.7874 - val_loss: 14.6093 - val_mae: 2.8184\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7592 - mae: 1.7773 - val_loss: 14.5463 - val_mae: 2.7977\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6478 - mae: 1.7530 - val_loss: 14.6082 - val_mae: 2.8087\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6605 - mae: 1.7625 - val_loss: 14.6639 - val_mae: 2.8157\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.6135 - mae: 1.7524 - val_loss: 14.7267 - val_mae: 2.8305\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.5596 - mae: 1.7529 - val_loss: 14.5230 - val_mae: 2.8032\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.5508 - mae: 1.7382 - val_loss: 14.4132 - val_mae: 2.7873\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4891 - mae: 1.7279 - val_loss: 14.3968 - val_mae: 2.7886\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4603 - mae: 1.7227 - val_loss: 14.4621 - val_mae: 2.7883\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4723 - mae: 1.7407 - val_loss: 14.4934 - val_mae: 2.8036\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.3992 - mae: 1.7253 - val_loss: 14.4097 - val_mae: 2.7893\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.3744 - mae: 1.7124 - val_loss: 14.4983 - val_mae: 2.7910\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.3008 - mae: 1.7083 - val_loss: 14.5076 - val_mae: 2.7985\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2568 - mae: 1.7077 - val_loss: 14.5046 - val_mae: 2.7964\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2296 - mae: 1.6991 - val_loss: 14.4917 - val_mae: 2.7901\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2491 - mae: 1.6874 - val_loss: 14.5549 - val_mae: 2.7870\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1942 - mae: 1.6857 - val_loss: 14.5252 - val_mae: 2.7903\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1926 - mae: 1.6952 - val_loss: 14.6238 - val_mae: 2.8059\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1208 - mae: 1.6734 - val_loss: 14.5637 - val_mae: 2.7925\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0207 - mae: 1.6603 - val_loss: 14.6095 - val_mae: 2.8016\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.9963 - mae: 1.6564 - val_loss: 14.4629 - val_mae: 2.7861\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 4.9554 - mae: 1.6487 - val_loss: 14.4582 - val_mae: 2.7862\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 4.9498 - mae: 1.6523 - val_loss: 14.5269 - val_mae: 2.7965\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 4.9360 - mae: 1.6583 - val_loss: 14.4233 - val_mae: 2.7787\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.8735 - mae: 1.6473 - val_loss: 14.5427 - val_mae: 2.7869\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 4.8386 - mae: 1.6277 - val_loss: 14.4586 - val_mae: 2.7767\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 4.8065 - mae: 1.6271 - val_loss: 14.4653 - val_mae: 2.7701\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.7987 - mae: 1.6266 - val_loss: 14.5929 - val_mae: 2.7920\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.7629 - mae: 1.6229 - val_loss: 14.4609 - val_mae: 2.7765\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.7158 - mae: 1.6087 - val_loss: 14.4809 - val_mae: 2.7762\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6986 - mae: 1.5959 - val_loss: 14.4910 - val_mae: 2.7811\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.6495 - mae: 1.6025 - val_loss: 14.4840 - val_mae: 2.7829\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.6503 - mae: 1.6024 - val_loss: 14.4417 - val_mae: 2.7786\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.5981 - mae: 1.5892 - val_loss: 14.6199 - val_mae: 2.7979\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.6139 - mae: 1.5891 - val_loss: 14.6126 - val_mae: 2.7955\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.5285 - mae: 1.5780 - val_loss: 14.4345 - val_mae: 2.7738\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.5002 - mae: 1.5678 - val_loss: 14.4195 - val_mae: 2.7673\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4628 - mae: 1.5614 - val_loss: 14.5130 - val_mae: 2.7750\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4446 - mae: 1.5576 - val_loss: 14.4941 - val_mae: 2.7724\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4301 - mae: 1.5565 - val_loss: 14.4639 - val_mae: 2.7712\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.4089 - mae: 1.5594 - val_loss: 14.5126 - val_mae: 2.7872\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 4.3987 - mae: 1.5679 - val_loss: 14.5536 - val_mae: 2.7834\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.3658 - mae: 1.5469 - val_loss: 14.5401 - val_mae: 2.7732\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3091 - mae: 1.5339 - val_loss: 14.6353 - val_mae: 2.7810\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3113 - mae: 1.5492 - val_loss: 14.6318 - val_mae: 2.7830\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.2865 - mae: 1.5432 - val_loss: 14.5205 - val_mae: 2.7674\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.2634 - mae: 1.5281 - val_loss: 14.6261 - val_mae: 2.7764\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.2222 - mae: 1.5237 - val_loss: 14.6372 - val_mae: 2.7802\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2381 - mae: 1.5398 - val_loss: 14.9140 - val_mae: 2.8159\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.1872 - mae: 1.5230 - val_loss: 14.7658 - val_mae: 2.7902\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 4.1476 - mae: 1.5088 - val_loss: 14.8066 - val_mae: 2.7987\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 4.1238 - mae: 1.5054 - val_loss: 14.7866 - val_mae: 2.7955\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 4.2018 - mae: 1.5321 - val_loss: 14.7741 - val_mae: 2.7961\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.0636 - mae: 1.5068 - val_loss: 14.8625 - val_mae: 2.7988\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 4.1534 - mae: 1.5125 - val_loss: 14.8191 - val_mae: 2.7979\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.0681 - mae: 1.4920 - val_loss: 14.4914 - val_mae: 2.7542\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.0359 - mae: 1.4803 - val_loss: 14.4237 - val_mae: 2.7474\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 4.0148 - mae: 1.4864 - val_loss: 14.5476 - val_mae: 2.7600\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 3.9965 - mae: 1.4891 - val_loss: 14.6309 - val_mae: 2.7732\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.9638 - mae: 1.4880 - val_loss: 14.6867 - val_mae: 2.7759\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.9465 - mae: 1.4717 - val_loss: 14.7846 - val_mae: 2.7861\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 3.9044 - mae: 1.4708 - val_loss: 14.7228 - val_mae: 2.7730\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3.8695 - mae: 1.4638 - val_loss: 14.8989 - val_mae: 2.7994\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.8791 - mae: 1.4562 - val_loss: 14.8125 - val_mae: 2.7822\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 3.8555 - mae: 1.4460 - val_loss: 14.6876 - val_mae: 2.7660\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 3.8050 - mae: 1.4411 - val_loss: 15.0144 - val_mae: 2.8046\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 3.8692 - mae: 1.4567 - val_loss: 14.7478 - val_mae: 2.7680\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 3.7609 - mae: 1.4382 - val_loss: 14.9317 - val_mae: 2.7956\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 3.7487 - mae: 1.4354 - val_loss: 14.9979 - val_mae: 2.7981\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 3.7481 - mae: 1.4311 - val_loss: 14.8120 - val_mae: 2.7752\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3.7555 - mae: 1.4335 - val_loss: 14.9753 - val_mae: 2.8005\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.7139 - mae: 1.4273 - val_loss: 14.9018 - val_mae: 2.7859\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 3.6794 - mae: 1.4247 - val_loss: 14.9998 - val_mae: 2.7949\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 3.6748 - mae: 1.4116 - val_loss: 14.8181 - val_mae: 2.7712\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 3.6248 - mae: 1.3979 - val_loss: 14.8872 - val_mae: 2.7832\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 3.6586 - mae: 1.4014 - val_loss: 14.7316 - val_mae: 2.7613\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 3.6359 - mae: 1.4037 - val_loss: 14.8827 - val_mae: 2.7801\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3.5747 - mae: 1.3933 - val_loss: 14.9318 - val_mae: 2.7882\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 3.5974 - mae: 1.3969 - val_loss: 14.7177 - val_mae: 2.7505\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.5391 - mae: 1.3901 - val_loss: 14.8709 - val_mae: 2.7778\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.5033 - mae: 1.3778 - val_loss: 14.8830 - val_mae: 2.7771\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.4559 - mae: 1.3609 - val_loss: 14.8613 - val_mae: 2.7689\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 3.4561 - mae: 1.3631 - val_loss: 15.0188 - val_mae: 2.7917\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.4810 - mae: 1.3889 - val_loss: 15.1224 - val_mae: 2.7990\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.4496 - mae: 1.3600 - val_loss: 15.0217 - val_mae: 2.7841\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.4203 - mae: 1.3567 - val_loss: 14.8366 - val_mae: 2.7717\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.3762 - mae: 1.3542 - val_loss: 14.8010 - val_mae: 2.7648\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3.3565 - mae: 1.3522 - val_loss: 14.8885 - val_mae: 2.7712\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 3.4178 - mae: 1.3642 - val_loss: 15.1864 - val_mae: 2.8068\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.3680 - mae: 1.3546 - val_loss: 14.9909 - val_mae: 2.7794\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.3390 - mae: 1.3470 - val_loss: 15.1893 - val_mae: 2.8142\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.3309 - mae: 1.3383 - val_loss: 14.9219 - val_mae: 2.7764\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 3.3172 - mae: 1.3427 - val_loss: 14.9570 - val_mae: 2.7795\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.2950 - mae: 1.3261 - val_loss: 15.0320 - val_mae: 2.7897\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.2542 - mae: 1.3222 - val_loss: 14.9717 - val_mae: 2.7833\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.2411 - mae: 1.3135 - val_loss: 15.0567 - val_mae: 2.7886\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3.2675 - mae: 1.3356 - val_loss: 15.0432 - val_mae: 2.7845\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 3.2042 - mae: 1.3102 - val_loss: 15.2282 - val_mae: 2.8048\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.2376 - mae: 1.3149 - val_loss: 15.0623 - val_mae: 2.7816\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.2342 - mae: 1.3155 - val_loss: 15.0209 - val_mae: 2.7810\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.1623 - mae: 1.2985 - val_loss: 14.9624 - val_mae: 2.7765\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.2254 - mae: 1.3350 - val_loss: 15.2984 - val_mae: 2.8096\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.1717 - mae: 1.2997 - val_loss: 15.1600 - val_mae: 2.7919\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.1535 - mae: 1.2991 - val_loss: 14.9586 - val_mae: 2.7721\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.1340 - mae: 1.2962 - val_loss: 15.1344 - val_mae: 2.7884\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.1779 - mae: 1.3226 - val_loss: 15.0293 - val_mae: 2.7717\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.0530 - mae: 1.2723 - val_loss: 15.4275 - val_mae: 2.8240\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1196 - mae: 1.2907 - val_loss: 15.0409 - val_mae: 2.7734\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3.0677 - mae: 1.2763 - val_loss: 14.9864 - val_mae: 2.7685\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 3.0267 - mae: 1.2772 - val_loss: 15.2620 - val_mae: 2.8055\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.0649 - mae: 1.2947 - val_loss: 15.2098 - val_mae: 2.7936\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 3.0257 - mae: 1.2657 - val_loss: 15.1720 - val_mae: 2.7855\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 3.0126 - mae: 1.2617 - val_loss: 15.1665 - val_mae: 2.7872\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 3.0259 - mae: 1.2626 - val_loss: 15.1406 - val_mae: 2.7785\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.0281 - mae: 1.2808 - val_loss: 15.2736 - val_mae: 2.7931\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.9705 - mae: 1.2539 - val_loss: 15.2835 - val_mae: 2.7945\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.9715 - mae: 1.2501 - val_loss: 15.2551 - val_mae: 2.7924\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.9651 - mae: 1.2667 - val_loss: 15.2796 - val_mae: 2.7907\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2.9279 - mae: 1.2501 - val_loss: 15.2012 - val_mae: 2.7825\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.9174 - mae: 1.2429 - val_loss: 15.1137 - val_mae: 2.7633\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.8958 - mae: 1.2326 - val_loss: 15.3134 - val_mae: 2.7870\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2.9676 - mae: 1.2687 - val_loss: 15.2487 - val_mae: 2.7781\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2.9063 - mae: 1.2459 - val_loss: 15.3255 - val_mae: 2.7860\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.9058 - mae: 1.2442 - val_loss: 15.2303 - val_mae: 2.7734\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.9228 - mae: 1.2417 - val_loss: 15.1887 - val_mae: 2.7696\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.8850 - mae: 1.2465 - val_loss: 15.3163 - val_mae: 2.7811\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 2.9035 - mae: 1.2289 - val_loss: 15.2014 - val_mae: 2.7709\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 2.8540 - mae: 1.2349 - val_loss: 15.3819 - val_mae: 2.7892\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.7992 - mae: 1.2166 - val_loss: 15.1801 - val_mae: 2.7693\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.8051 - mae: 1.2232 - val_loss: 15.2932 - val_mae: 2.7740\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.8315 - mae: 1.2079 - val_loss: 15.2651 - val_mae: 2.7685\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 2.7974 - mae: 1.2171 - val_loss: 15.2828 - val_mae: 2.7701\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2.8153 - mae: 1.2200 - val_loss: 15.2947 - val_mae: 2.7804\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.7459 - mae: 1.2002 - val_loss: 15.3430 - val_mae: 2.7820\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.7763 - mae: 1.2222 - val_loss: 15.5422 - val_mae: 2.8056\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.7680 - mae: 1.2116 - val_loss: 15.4367 - val_mae: 2.7954\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.7559 - mae: 1.1992 - val_loss: 15.1756 - val_mae: 2.7613\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.7374 - mae: 1.2103 - val_loss: 15.4987 - val_mae: 2.7970\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 2.7020 - mae: 1.1832 - val_loss: 15.2653 - val_mae: 2.7660\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.7099 - mae: 1.1857 - val_loss: 15.4330 - val_mae: 2.7784\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.6747 - mae: 1.1776 - val_loss: 15.4074 - val_mae: 2.7787\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 8.9465 - mae: 2.0781\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 32ms/step - loss: 541.3725 - mae: 21.4834 - val_loss: 627.2049 - val_mae: 23.1542\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 508.7769 - mae: 20.7394 - val_loss: 589.5265 - val_mae: 22.3591\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 475.9961 - mae: 19.9471 - val_loss: 547.7126 - val_mae: 21.4561\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 440.0949 - mae: 19.0263 - val_loss: 500.9193 - val_mae: 20.3949\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 398.5027 - mae: 17.9386 - val_loss: 448.7497 - val_mae: 19.1477\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 353.2501 - mae: 16.6164 - val_loss: 390.2905 - val_mae: 17.6805\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 303.0481 - mae: 15.1440 - val_loss: 326.7882 - val_mae: 15.9588\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 250.3336 - mae: 13.5999 - val_loss: 263.7568 - val_mae: 14.0962\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 200.3608 - mae: 12.0081 - val_loss: 203.0369 - val_mae: 12.0688\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 152.9293 - mae: 10.3450 - val_loss: 151.3899 - val_mae: 10.0590\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 113.9090 - mae: 8.7798 - val_loss: 111.7381 - val_mae: 8.3297\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 83.1410 - mae: 7.4104 - val_loss: 85.0340 - val_mae: 7.0415\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 62.0409 - mae: 6.3019 - val_loss: 68.4409 - val_mae: 6.1452\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 48.9240 - mae: 5.4258 - val_loss: 58.9509 - val_mae: 5.5994\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 40.7429 - mae: 4.8485 - val_loss: 52.4225 - val_mae: 5.2385\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 35.1085 - mae: 4.4621 - val_loss: 47.4835 - val_mae: 4.9591\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 31.2380 - mae: 4.2023 - val_loss: 43.3756 - val_mae: 4.6891\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 28.1142 - mae: 3.9707 - val_loss: 40.2078 - val_mae: 4.4684\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 25.9505 - mae: 3.8030 - val_loss: 37.9501 - val_mae: 4.3120\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 24.3400 - mae: 3.6776 - val_loss: 36.1378 - val_mae: 4.1800\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 23.2573 - mae: 3.5913 - val_loss: 34.5821 - val_mae: 4.0727\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 22.2517 - mae: 3.5138 - val_loss: 33.3057 - val_mae: 3.9704\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 21.3855 - mae: 3.4406 - val_loss: 32.3628 - val_mae: 3.9003\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 20.6825 - mae: 3.3732 - val_loss: 31.5617 - val_mae: 3.8364\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 20.1057 - mae: 3.3224 - val_loss: 30.6155 - val_mae: 3.7707\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 19.5286 - mae: 3.2672 - val_loss: 29.7947 - val_mae: 3.7049\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 18.9872 - mae: 3.2276 - val_loss: 29.1017 - val_mae: 3.6496\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 18.5196 - mae: 3.1824 - val_loss: 28.5872 - val_mae: 3.6143\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 18.0892 - mae: 3.1377 - val_loss: 27.9400 - val_mae: 3.5710\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 17.6877 - mae: 3.0986 - val_loss: 27.4956 - val_mae: 3.5462\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 17.1993 - mae: 3.0524 - val_loss: 26.9691 - val_mae: 3.4994\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 16.8973 - mae: 3.0243 - val_loss: 26.4438 - val_mae: 3.4593\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 16.5133 - mae: 2.9859 - val_loss: 26.0495 - val_mae: 3.4305\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 16.1668 - mae: 2.9451 - val_loss: 25.7382 - val_mae: 3.4095\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 15.7872 - mae: 2.9139 - val_loss: 25.3943 - val_mae: 3.3853\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 15.5082 - mae: 2.8860 - val_loss: 25.0381 - val_mae: 3.3624\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 15.2131 - mae: 2.8500 - val_loss: 24.6808 - val_mae: 3.3258\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.9624 - mae: 2.8285 - val_loss: 24.3505 - val_mae: 3.3214\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.5645 - mae: 2.7981 - val_loss: 23.9909 - val_mae: 3.2749\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.2812 - mae: 2.7499 - val_loss: 23.7284 - val_mae: 3.2476\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.1164 - mae: 2.7091 - val_loss: 23.6038 - val_mae: 3.2097\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.7434 - mae: 2.6702 - val_loss: 23.2482 - val_mae: 3.2159\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.5482 - mae: 2.6572 - val_loss: 22.9639 - val_mae: 3.1861\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.2900 - mae: 2.6349 - val_loss: 22.6973 - val_mae: 3.1723\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.1069 - mae: 2.6205 - val_loss: 22.4280 - val_mae: 3.1341\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 12.8966 - mae: 2.5952 - val_loss: 22.3016 - val_mae: 3.1270\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.6778 - mae: 2.5866 - val_loss: 22.0370 - val_mae: 3.1453\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.6101 - mae: 2.5866 - val_loss: 21.9253 - val_mae: 3.1163\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.3268 - mae: 2.5532 - val_loss: 21.7184 - val_mae: 3.1070\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.1288 - mae: 2.5366 - val_loss: 21.6495 - val_mae: 3.0980\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.9252 - mae: 2.5079 - val_loss: 21.5002 - val_mae: 3.0740\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.7938 - mae: 2.5022 - val_loss: 21.3913 - val_mae: 3.0708\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.6648 - mae: 2.4893 - val_loss: 21.2158 - val_mae: 3.0367\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.5194 - mae: 2.4743 - val_loss: 21.0850 - val_mae: 3.0458\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.3870 - mae: 2.4692 - val_loss: 20.8408 - val_mae: 2.9986\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.2385 - mae: 2.4388 - val_loss: 20.8179 - val_mae: 3.0009\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.2141 - mae: 2.4458 - val_loss: 20.8693 - val_mae: 3.0567\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.9651 - mae: 2.4310 - val_loss: 20.6926 - val_mae: 3.0017\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.9683 - mae: 2.4035 - val_loss: 20.7321 - val_mae: 2.9932\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.6872 - mae: 2.3786 - val_loss: 20.5989 - val_mae: 3.0124\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.5954 - mae: 2.3850 - val_loss: 20.3904 - val_mae: 2.9835\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.4968 - mae: 2.3768 - val_loss: 20.4507 - val_mae: 2.9922\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.4278 - mae: 2.3519 - val_loss: 20.3575 - val_mae: 2.9648\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.3223 - mae: 2.3563 - val_loss: 20.2071 - val_mae: 2.9541\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.2079 - mae: 2.3675 - val_loss: 20.1341 - val_mae: 2.9655\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.1764 - mae: 2.3531 - val_loss: 20.0914 - val_mae: 2.9412\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.9877 - mae: 2.3127 - val_loss: 20.0005 - val_mae: 2.9374\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.8964 - mae: 2.3117 - val_loss: 19.9305 - val_mae: 2.9326\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8579 - mae: 2.3115 - val_loss: 19.7783 - val_mae: 2.8988\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8119 - mae: 2.2992 - val_loss: 19.7403 - val_mae: 2.8890\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.7636 - mae: 2.2973 - val_loss: 19.8220 - val_mae: 2.9336\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.5759 - mae: 2.2718 - val_loss: 19.8551 - val_mae: 2.9289\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.5623 - mae: 2.2460 - val_loss: 19.8110 - val_mae: 2.8882\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.4685 - mae: 2.2385 - val_loss: 19.7413 - val_mae: 2.9144\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.3666 - mae: 2.2534 - val_loss: 19.7088 - val_mae: 2.9156\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.2751 - mae: 2.2398 - val_loss: 19.7457 - val_mae: 2.9108\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.2250 - mae: 2.2282 - val_loss: 19.6989 - val_mae: 2.8907\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.1038 - mae: 2.2310 - val_loss: 19.6782 - val_mae: 2.9081\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.1770 - mae: 2.2410 - val_loss: 19.6418 - val_mae: 2.9144\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.0066 - mae: 2.2052 - val_loss: 19.6014 - val_mae: 2.8974\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.9236 - mae: 2.1799 - val_loss: 19.4515 - val_mae: 2.8551\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.9366 - mae: 2.1781 - val_loss: 19.4924 - val_mae: 2.8717\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.8224 - mae: 2.1756 - val_loss: 19.4544 - val_mae: 2.8760\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.7630 - mae: 2.1732 - val_loss: 19.4044 - val_mae: 2.8534\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.6994 - mae: 2.1621 - val_loss: 19.4628 - val_mae: 2.8634\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 8.6683 - mae: 2.1669 - val_loss: 19.5702 - val_mae: 2.8841\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.5965 - mae: 2.1575 - val_loss: 19.5288 - val_mae: 2.8718\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.5545 - mae: 2.1483 - val_loss: 19.5274 - val_mae: 2.8675\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.5377 - mae: 2.1496 - val_loss: 19.4104 - val_mae: 2.8446\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.4409 - mae: 2.1273 - val_loss: 19.5679 - val_mae: 2.8786\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 8.4387 - mae: 2.1124 - val_loss: 19.6688 - val_mae: 2.8927\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.3745 - mae: 2.1126 - val_loss: 19.4169 - val_mae: 2.8444\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.3768 - mae: 2.1170 - val_loss: 19.4016 - val_mae: 2.8388\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.3049 - mae: 2.1014 - val_loss: 19.5119 - val_mae: 2.8524\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.2411 - mae: 2.0935 - val_loss: 19.4304 - val_mae: 2.8391\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 8.1831 - mae: 2.0917 - val_loss: 19.4696 - val_mae: 2.8454\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.1930 - mae: 2.0895 - val_loss: 19.5121 - val_mae: 2.8580\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.1114 - mae: 2.0794 - val_loss: 19.4317 - val_mae: 2.8346\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.0887 - mae: 2.0738 - val_loss: 19.4407 - val_mae: 2.8381\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.0430 - mae: 2.0662 - val_loss: 19.2922 - val_mae: 2.8001\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.0000 - mae: 2.0612 - val_loss: 19.3649 - val_mae: 2.8157\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 7.9905 - mae: 2.0618 - val_loss: 19.3780 - val_mae: 2.8209\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.8932 - mae: 2.0397 - val_loss: 19.3834 - val_mae: 2.8124\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.8830 - mae: 2.0249 - val_loss: 19.3825 - val_mae: 2.8035\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 7.8826 - mae: 2.0276 - val_loss: 19.3965 - val_mae: 2.8251\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.7772 - mae: 2.0219 - val_loss: 19.3415 - val_mae: 2.8146\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.7749 - mae: 2.0306 - val_loss: 19.2482 - val_mae: 2.7875\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.7189 - mae: 2.0215 - val_loss: 19.4225 - val_mae: 2.8267\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 7.7064 - mae: 2.0153 - val_loss: 19.3213 - val_mae: 2.8111\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.6386 - mae: 2.0036 - val_loss: 19.3996 - val_mae: 2.8189\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 7.5929 - mae: 1.9983 - val_loss: 19.3739 - val_mae: 2.8098\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 7.6076 - mae: 2.0058 - val_loss: 19.4661 - val_mae: 2.8211\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 7.6154 - mae: 1.9951 - val_loss: 19.4095 - val_mae: 2.7862\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 7.5457 - mae: 1.9767 - val_loss: 19.4058 - val_mae: 2.7859\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4457 - mae: 1.9715 - val_loss: 19.4117 - val_mae: 2.8171\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4670 - mae: 1.9851 - val_loss: 19.3171 - val_mae: 2.8094\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4167 - mae: 1.9768 - val_loss: 19.4903 - val_mae: 2.8314\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3180 - mae: 1.9551 - val_loss: 19.2980 - val_mae: 2.7911\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3759 - mae: 1.9693 - val_loss: 19.2384 - val_mae: 2.7822\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.2713 - mae: 1.9530 - val_loss: 19.4019 - val_mae: 2.8085\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.2828 - mae: 1.9409 - val_loss: 19.3246 - val_mae: 2.7962\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.2035 - mae: 1.9388 - val_loss: 19.2309 - val_mae: 2.7731\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.2019 - mae: 1.9369 - val_loss: 19.4110 - val_mae: 2.7964\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.1220 - mae: 1.9239 - val_loss: 19.3215 - val_mae: 2.7884\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.1138 - mae: 1.9189 - val_loss: 19.2867 - val_mae: 2.7909\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.0617 - mae: 1.9180 - val_loss: 19.4020 - val_mae: 2.7995\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.0247 - mae: 1.9060 - val_loss: 19.3319 - val_mae: 2.7786\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.0130 - mae: 1.9103 - val_loss: 19.2934 - val_mae: 2.7742\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.9359 - mae: 1.8910 - val_loss: 19.3897 - val_mae: 2.7969\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.0524 - mae: 1.9135 - val_loss: 19.5532 - val_mae: 2.8376\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.9825 - mae: 1.9128 - val_loss: 19.1423 - val_mae: 2.7556\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.8815 - mae: 1.8934 - val_loss: 19.2047 - val_mae: 2.7667\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.8703 - mae: 1.8861 - val_loss: 19.2518 - val_mae: 2.7787\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 6.8164 - mae: 1.8758 - val_loss: 19.1191 - val_mae: 2.7607\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 6.8635 - mae: 1.8892 - val_loss: 19.0532 - val_mae: 2.7470\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 6.7997 - mae: 1.8813 - val_loss: 19.2854 - val_mae: 2.7798\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.7257 - mae: 1.8623 - val_loss: 19.2929 - val_mae: 2.7596\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 6.6736 - mae: 1.8581 - val_loss: 19.3061 - val_mae: 2.7825\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 6.6337 - mae: 1.8629 - val_loss: 19.1622 - val_mae: 2.7524\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 6.6214 - mae: 1.8556 - val_loss: 19.1896 - val_mae: 2.7441\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 6.5947 - mae: 1.8568 - val_loss: 19.2143 - val_mae: 2.7737\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 6.5336 - mae: 1.8407 - val_loss: 19.2522 - val_mae: 2.7593\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 6.5265 - mae: 1.8338 - val_loss: 19.1361 - val_mae: 2.7521\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 6.4874 - mae: 1.8485 - val_loss: 19.1686 - val_mae: 2.7797\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 6.4826 - mae: 1.8403 - val_loss: 19.2821 - val_mae: 2.7631\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 6.4909 - mae: 1.8136 - val_loss: 19.2553 - val_mae: 2.7431\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6.4587 - mae: 1.8208 - val_loss: 19.1691 - val_mae: 2.7477\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 6.4220 - mae: 1.8360 - val_loss: 19.4534 - val_mae: 2.7983\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.3484 - mae: 1.8097 - val_loss: 19.2220 - val_mae: 2.7411\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6.3287 - mae: 1.8007 - val_loss: 19.2354 - val_mae: 2.7569\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.3197 - mae: 1.8025 - val_loss: 19.1974 - val_mae: 2.7675\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.3900 - mae: 1.8234 - val_loss: 19.3008 - val_mae: 2.7931\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2270 - mae: 1.7962 - val_loss: 19.1767 - val_mae: 2.7360\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2733 - mae: 1.7828 - val_loss: 19.1501 - val_mae: 2.7262\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.1308 - mae: 1.7698 - val_loss: 19.2796 - val_mae: 2.7744\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.1929 - mae: 1.7934 - val_loss: 19.1957 - val_mae: 2.7506\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1743 - mae: 1.7735 - val_loss: 19.1172 - val_mae: 2.7197\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.1270 - mae: 1.7662 - val_loss: 19.0755 - val_mae: 2.7463\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.3229 - mae: 1.8258 - val_loss: 19.4904 - val_mae: 2.8049\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.1000 - mae: 1.7837 - val_loss: 19.4276 - val_mae: 2.7419\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1060 - mae: 1.7466 - val_loss: 19.2457 - val_mae: 2.7449\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.0062 - mae: 1.7653 - val_loss: 19.2707 - val_mae: 2.7682\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9594 - mae: 1.7483 - val_loss: 19.0829 - val_mae: 2.7194\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9336 - mae: 1.7354 - val_loss: 19.1690 - val_mae: 2.7398\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8907 - mae: 1.7400 - val_loss: 19.2566 - val_mae: 2.7560\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9071 - mae: 1.7400 - val_loss: 19.2428 - val_mae: 2.7350\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8579 - mae: 1.7133 - val_loss: 19.0187 - val_mae: 2.7038\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8358 - mae: 1.7284 - val_loss: 19.0367 - val_mae: 2.7371\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8092 - mae: 1.7245 - val_loss: 19.0840 - val_mae: 2.7473\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.7946 - mae: 1.7261 - val_loss: 18.9544 - val_mae: 2.7158\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.7374 - mae: 1.7009 - val_loss: 19.1295 - val_mae: 2.7390\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6900 - mae: 1.7006 - val_loss: 19.2192 - val_mae: 2.7632\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6919 - mae: 1.6970 - val_loss: 19.0209 - val_mae: 2.7212\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6449 - mae: 1.6937 - val_loss: 19.0465 - val_mae: 2.7358\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.6120 - mae: 1.6943 - val_loss: 19.0287 - val_mae: 2.7272\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.6477 - mae: 1.6826 - val_loss: 18.9917 - val_mae: 2.7161\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 5.5316 - mae: 1.6856 - val_loss: 19.1648 - val_mae: 2.7540\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 5.5267 - mae: 1.6905 - val_loss: 19.0742 - val_mae: 2.7224\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.5915 - mae: 1.6648 - val_loss: 18.9153 - val_mae: 2.6931\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 5.4110 - mae: 1.6599 - val_loss: 19.1603 - val_mae: 2.7541\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 5.4928 - mae: 1.6804 - val_loss: 19.2504 - val_mae: 2.7419\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 5.4596 - mae: 1.6672 - val_loss: 19.1059 - val_mae: 2.7105\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 5.4388 - mae: 1.6491 - val_loss: 19.2259 - val_mae: 2.7517\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 5.3642 - mae: 1.6371 - val_loss: 18.9060 - val_mae: 2.7056\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 5.3314 - mae: 1.6305 - val_loss: 18.8692 - val_mae: 2.7047\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2967 - mae: 1.6480 - val_loss: 19.0793 - val_mae: 2.7357\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2956 - mae: 1.6391 - val_loss: 19.2488 - val_mae: 2.7370\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2414 - mae: 1.6211 - val_loss: 19.2266 - val_mae: 2.7258\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.3247 - mae: 1.6066 - val_loss: 18.9640 - val_mae: 2.7035\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4365 - mae: 1.6777 - val_loss: 18.9256 - val_mae: 2.7298\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.1295 - mae: 1.5829 - val_loss: 18.9717 - val_mae: 2.6929\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2273 - mae: 1.5856 - val_loss: 19.0705 - val_mae: 2.7172\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2778 - mae: 1.6321 - val_loss: 19.1117 - val_mae: 2.7401\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1464 - mae: 1.5917 - val_loss: 18.9555 - val_mae: 2.7055\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.0837 - mae: 1.5936 - val_loss: 19.0063 - val_mae: 2.7302\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0668 - mae: 1.5995 - val_loss: 18.8744 - val_mae: 2.7086\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0699 - mae: 1.5770 - val_loss: 18.9271 - val_mae: 2.7030\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1017 - mae: 1.5931 - val_loss: 18.8635 - val_mae: 2.7093\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.0024 - mae: 1.5845 - val_loss: 19.1211 - val_mae: 2.7439\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.9839 - mae: 1.5656 - val_loss: 18.9190 - val_mae: 2.7074\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9660 - mae: 1.5791 - val_loss: 18.9349 - val_mae: 2.7245\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9622 - mae: 1.5814 - val_loss: 18.9665 - val_mae: 2.7216\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9685 - mae: 1.5483 - val_loss: 18.8681 - val_mae: 2.6952\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.8845 - mae: 1.5375 - val_loss: 18.9516 - val_mae: 2.7209\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.9053 - mae: 1.5552 - val_loss: 18.8958 - val_mae: 2.7140\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.8238 - mae: 1.5453 - val_loss: 18.9022 - val_mae: 2.7150\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.8297 - mae: 1.5281 - val_loss: 18.8781 - val_mae: 2.7039\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.7979 - mae: 1.5288 - val_loss: 18.9193 - val_mae: 2.7128\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.8196 - mae: 1.5500 - val_loss: 18.9731 - val_mae: 2.7434\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.8577 - mae: 1.5248 - val_loss: 18.8734 - val_mae: 2.7007\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.7730 - mae: 1.5165 - val_loss: 19.0855 - val_mae: 2.7499\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.6985 - mae: 1.5231 - val_loss: 18.7506 - val_mae: 2.7056\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.6758 - mae: 1.5017 - val_loss: 18.8216 - val_mae: 2.6961\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.7015 - mae: 1.5016 - val_loss: 18.8341 - val_mae: 2.7027\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6695 - mae: 1.5029 - val_loss: 18.7096 - val_mae: 2.6850\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.8069 - mae: 1.5502 - val_loss: 18.7397 - val_mae: 2.7093\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.6019 - mae: 1.4956 - val_loss: 18.6453 - val_mae: 2.6779\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5743 - mae: 1.4843 - val_loss: 18.7265 - val_mae: 2.7062\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.5965 - mae: 1.5124 - val_loss: 18.8299 - val_mae: 2.7157\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.5258 - mae: 1.4669 - val_loss: 18.7746 - val_mae: 2.6940\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.5202 - mae: 1.4793 - val_loss: 18.8299 - val_mae: 2.7123\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5189 - mae: 1.4864 - val_loss: 18.7935 - val_mae: 2.7123\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4931 - mae: 1.4604 - val_loss: 18.7799 - val_mae: 2.7039\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4708 - mae: 1.4483 - val_loss: 18.8325 - val_mae: 2.7231\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4451 - mae: 1.4595 - val_loss: 18.7820 - val_mae: 2.7021\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4237 - mae: 1.4419 - val_loss: 18.7289 - val_mae: 2.6980\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.4199 - mae: 1.4450 - val_loss: 18.8146 - val_mae: 2.7166\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4161 - mae: 1.4392 - val_loss: 18.6106 - val_mae: 2.7069\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3619 - mae: 1.4403 - val_loss: 18.5061 - val_mae: 2.6947\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3927 - mae: 1.4667 - val_loss: 19.1260 - val_mae: 2.7320\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.3611 - mae: 1.4476 - val_loss: 19.0135 - val_mae: 2.7155\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3286 - mae: 1.4328 - val_loss: 18.9369 - val_mae: 2.7264\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.3781 - mae: 1.4729 - val_loss: 18.8123 - val_mae: 2.7150\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.2369 - mae: 1.4207 - val_loss: 18.6868 - val_mae: 2.6958\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.2294 - mae: 1.4087 - val_loss: 18.6536 - val_mae: 2.6951\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2358 - mae: 1.4161 - val_loss: 18.6018 - val_mae: 2.6918\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.3024 - mae: 1.4505 - val_loss: 19.0068 - val_mae: 2.7500\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.2205 - mae: 1.4158 - val_loss: 18.5160 - val_mae: 2.6818\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.1923 - mae: 1.4065 - val_loss: 18.6406 - val_mae: 2.7044\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1859 - mae: 1.4214 - val_loss: 18.5212 - val_mae: 2.6845\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.1337 - mae: 1.3769 - val_loss: 18.4048 - val_mae: 2.6731\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.0454 - mae: 1.3951 - val_loss: 18.6329 - val_mae: 2.7120\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.1233 - mae: 1.4289 - val_loss: 18.5790 - val_mae: 2.6911\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0738 - mae: 1.3791 - val_loss: 18.6148 - val_mae: 2.6992\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0411 - mae: 1.3843 - val_loss: 18.4327 - val_mae: 2.6822\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.0336 - mae: 1.3894 - val_loss: 18.4396 - val_mae: 2.6760\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.0417 - mae: 1.3723 - val_loss: 18.6677 - val_mae: 2.7055\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.0531 - mae: 1.3652 - val_loss: 18.3471 - val_mae: 2.6819\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.9631 - mae: 1.3816 - val_loss: 18.5507 - val_mae: 2.7057\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.9586 - mae: 1.3606 - val_loss: 18.5037 - val_mae: 2.6955\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.9544 - mae: 1.3692 - val_loss: 18.5377 - val_mae: 2.6990\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.8819 - mae: 1.3636 - val_loss: 18.5906 - val_mae: 2.6973\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.8966 - mae: 1.3574 - val_loss: 18.4108 - val_mae: 2.6787\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.8988 - mae: 1.3427 - val_loss: 18.3753 - val_mae: 2.6824\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.8876 - mae: 1.3750 - val_loss: 18.5994 - val_mae: 2.7094\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.8759 - mae: 1.3684 - val_loss: 18.3005 - val_mae: 2.6685\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.9154 - mae: 1.3312 - val_loss: 18.4864 - val_mae: 2.7060\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.8259 - mae: 1.3545 - val_loss: 18.4033 - val_mae: 2.7069\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.8771 - mae: 1.3467 - val_loss: 18.4041 - val_mae: 2.6901\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.7587 - mae: 1.3282 - val_loss: 18.4121 - val_mae: 2.6922\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 3.7631 - mae: 1.3366 - val_loss: 18.1032 - val_mae: 2.6594\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.8241 - mae: 1.3398 - val_loss: 18.3560 - val_mae: 2.6712\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.7252 - mae: 1.3163 - val_loss: 18.4539 - val_mae: 2.6998\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.6893 - mae: 1.3012 - val_loss: 18.4052 - val_mae: 2.6940\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.6783 - mae: 1.3074 - val_loss: 18.4362 - val_mae: 2.6868\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.6790 - mae: 1.3316 - val_loss: 18.3868 - val_mae: 2.6808\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.6800 - mae: 1.3265 - val_loss: 18.2855 - val_mae: 2.6755\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.8841 - mae: 1.3222 - val_loss: 18.1937 - val_mae: 2.6661\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 4.0459 - mae: 1.4422 - val_loss: 19.0791 - val_mae: 2.7702\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.8353 - mae: 1.3888 - val_loss: 18.6498 - val_mae: 2.6854\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3.6593 - mae: 1.3139 - val_loss: 18.8555 - val_mae: 2.7376\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3.6761 - mae: 1.3412 - val_loss: 18.5417 - val_mae: 2.6991\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.5800 - mae: 1.3054 - val_loss: 18.4046 - val_mae: 2.6917\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3.5422 - mae: 1.2887 - val_loss: 18.3292 - val_mae: 2.6813\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 3.5630 - mae: 1.2823 - val_loss: 18.2882 - val_mae: 2.6837\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.5321 - mae: 1.2736 - val_loss: 18.1526 - val_mae: 2.6666\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.4907 - mae: 1.2679 - val_loss: 18.3239 - val_mae: 2.6925\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3.5370 - mae: 1.2832 - val_loss: 18.5538 - val_mae: 2.6944\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.5788 - mae: 1.2513 - val_loss: 18.4566 - val_mae: 2.7051\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.4719 - mae: 1.2902 - val_loss: 18.2930 - val_mae: 2.6829\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.5113 - mae: 1.3070 - val_loss: 18.4401 - val_mae: 2.6968\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.4932 - mae: 1.2592 - val_loss: 18.1825 - val_mae: 2.6672\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3.5380 - mae: 1.3134 - val_loss: 18.4114 - val_mae: 2.7007\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.4731 - mae: 1.2709 - val_loss: 18.2625 - val_mae: 2.6781\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.3962 - mae: 1.2831 - val_loss: 18.3807 - val_mae: 2.7079\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.3834 - mae: 1.2759 - val_loss: 18.1616 - val_mae: 2.6717\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 3.4004 - mae: 1.2500 - val_loss: 18.2927 - val_mae: 2.6960\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.3562 - mae: 1.2632 - val_loss: 18.1852 - val_mae: 2.6798\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 3.3219 - mae: 1.2365 - val_loss: 18.2449 - val_mae: 2.6833\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.2872 - mae: 1.2269 - val_loss: 18.1598 - val_mae: 2.6795\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.2927 - mae: 1.2449 - val_loss: 18.1083 - val_mae: 2.6752\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.2992 - mae: 1.2506 - val_loss: 18.1930 - val_mae: 2.6751\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.2768 - mae: 1.2494 - val_loss: 18.2829 - val_mae: 2.7029\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2707 - mae: 1.2361 - val_loss: 18.3331 - val_mae: 2.7081\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2824 - mae: 1.2304 - val_loss: 18.2402 - val_mae: 2.6814\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.2452 - mae: 1.2590 - val_loss: 18.5496 - val_mae: 2.7178\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.2215 - mae: 1.2186 - val_loss: 18.3421 - val_mae: 2.6889\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.1681 - mae: 1.2084 - val_loss: 18.3509 - val_mae: 2.7016\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.2502 - mae: 1.2483 - val_loss: 18.1797 - val_mae: 2.6806\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1747 - mae: 1.2058 - val_loss: 18.1691 - val_mae: 2.6864\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 8.9208 - mae: 2.1526\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 2s 40ms/step - loss: 597.6297 - mae: 22.5455 - val_loss: 488.4862 - val_mae: 20.2459\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 567.9250 - mae: 21.9324 - val_loss: 463.0576 - val_mae: 19.6523\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 538.9010 - mae: 21.2977 - val_loss: 435.7135 - val_mae: 18.9945\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 505.5976 - mae: 20.5683 - val_loss: 403.7394 - val_mae: 18.1981\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 466.1201 - mae: 19.6771 - val_loss: 365.3463 - val_mae: 17.1915\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 418.1401 - mae: 18.5267 - val_loss: 320.6044 - val_mae: 15.9223\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 362.2948 - mae: 17.0813 - val_loss: 270.1705 - val_mae: 14.3815\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 300.9239 - mae: 15.3371 - val_loss: 216.6996 - val_mae: 12.6225\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 237.0145 - mae: 13.2814 - val_loss: 165.3514 - val_mae: 10.7749\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 177.0470 - mae: 11.0225 - val_loss: 122.4999 - val_mae: 8.9760\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 129.9865 - mae: 8.9948 - val_loss: 91.8835 - val_mae: 7.6234\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 95.9384 - mae: 7.4253 - val_loss: 74.2899 - val_mae: 6.7618\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 75.8571 - mae: 6.4994 - val_loss: 64.3895 - val_mae: 6.3536\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.4806 - mae: 5.9590 - val_loss: 56.9114 - val_mae: 5.9902\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 55.6656 - mae: 5.4772 - val_loss: 49.8247 - val_mae: 5.5592\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 47.8079 - mae: 5.0447 - val_loss: 43.9504 - val_mae: 5.1728\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 42.1292 - mae: 4.6734 - val_loss: 38.8803 - val_mae: 4.8490\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 37.5235 - mae: 4.3690 - val_loss: 34.6815 - val_mae: 4.5542\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 34.1642 - mae: 4.1383 - val_loss: 32.0503 - val_mae: 4.3636\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 31.6906 - mae: 3.9965 - val_loss: 30.2160 - val_mae: 4.2386\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 29.7868 - mae: 3.8757 - val_loss: 28.5203 - val_mae: 4.1129\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 28.4576 - mae: 3.7747 - val_loss: 27.0721 - val_mae: 4.0134\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 27.3564 - mae: 3.6891 - val_loss: 25.7514 - val_mae: 3.9034\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 26.3589 - mae: 3.6261 - val_loss: 24.9533 - val_mae: 3.8452\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 25.4973 - mae: 3.5690 - val_loss: 24.0744 - val_mae: 3.7724\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 24.7720 - mae: 3.5210 - val_loss: 23.4968 - val_mae: 3.7294\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 24.1977 - mae: 3.4723 - val_loss: 22.8518 - val_mae: 3.6696\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 23.7066 - mae: 3.4421 - val_loss: 22.5895 - val_mae: 3.6569\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 22.9665 - mae: 3.3883 - val_loss: 21.9149 - val_mae: 3.5828\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 22.4282 - mae: 3.3363 - val_loss: 21.4851 - val_mae: 3.5320\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 21.8518 - mae: 3.2995 - val_loss: 21.1806 - val_mae: 3.5057\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 21.3290 - mae: 3.2629 - val_loss: 20.6029 - val_mae: 3.4440\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 20.8638 - mae: 3.2201 - val_loss: 20.0189 - val_mae: 3.3807\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 20.4631 - mae: 3.1795 - val_loss: 19.5922 - val_mae: 3.3174\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 20.0169 - mae: 3.1459 - val_loss: 19.4264 - val_mae: 3.3074\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 19.5945 - mae: 3.1256 - val_loss: 19.3338 - val_mae: 3.2856\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 19.2334 - mae: 3.0868 - val_loss: 18.9220 - val_mae: 3.2275\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 18.8878 - mae: 3.0574 - val_loss: 18.7767 - val_mae: 3.2083\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 18.4561 - mae: 3.0302 - val_loss: 18.4823 - val_mae: 3.1841\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 18.0950 - mae: 3.0101 - val_loss: 18.2420 - val_mae: 3.1454\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 17.7661 - mae: 2.9812 - val_loss: 18.0072 - val_mae: 3.1202\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 17.5121 - mae: 2.9632 - val_loss: 17.8765 - val_mae: 3.0908\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 17.1429 - mae: 2.9308 - val_loss: 17.7193 - val_mae: 3.0726\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 16.8490 - mae: 2.9095 - val_loss: 17.4922 - val_mae: 3.0353\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 16.5778 - mae: 2.8850 - val_loss: 17.2517 - val_mae: 2.9980\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 16.3649 - mae: 2.8652 - val_loss: 17.1506 - val_mae: 2.9786\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 16.0949 - mae: 2.8330 - val_loss: 16.9220 - val_mae: 2.9411\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.8171 - mae: 2.8097 - val_loss: 16.8402 - val_mae: 2.9247\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 15.6100 - mae: 2.7889 - val_loss: 16.8006 - val_mae: 2.9280\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 15.3696 - mae: 2.7666 - val_loss: 16.4275 - val_mae: 2.8872\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 15.1894 - mae: 2.7541 - val_loss: 16.6281 - val_mae: 2.8995\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 14.9276 - mae: 2.7306 - val_loss: 16.3819 - val_mae: 2.8738\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 14.7388 - mae: 2.7111 - val_loss: 16.3679 - val_mae: 2.8740\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 14.4729 - mae: 2.6864 - val_loss: 16.0819 - val_mae: 2.8446\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 14.3334 - mae: 2.6721 - val_loss: 16.0777 - val_mae: 2.8496\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.1616 - mae: 2.6583 - val_loss: 15.9296 - val_mae: 2.8392\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.9919 - mae: 2.6318 - val_loss: 15.7183 - val_mae: 2.8074\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.8289 - mae: 2.6157 - val_loss: 15.7680 - val_mae: 2.8113\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.6677 - mae: 2.6139 - val_loss: 15.6635 - val_mae: 2.8044\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.5157 - mae: 2.5881 - val_loss: 15.4187 - val_mae: 2.7776\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.3991 - mae: 2.5855 - val_loss: 15.5989 - val_mae: 2.7901\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.2265 - mae: 2.5698 - val_loss: 15.4564 - val_mae: 2.7720\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.0929 - mae: 2.5627 - val_loss: 15.5070 - val_mae: 2.7803\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 12.9920 - mae: 2.5617 - val_loss: 15.4098 - val_mae: 2.7776\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.7708 - mae: 2.5410 - val_loss: 15.4905 - val_mae: 2.7766\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.6550 - mae: 2.5456 - val_loss: 15.6986 - val_mae: 2.7989\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.6161 - mae: 2.5677 - val_loss: 15.8431 - val_mae: 2.8334\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.4875 - mae: 2.5486 - val_loss: 15.3010 - val_mae: 2.7761\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.3426 - mae: 2.5105 - val_loss: 14.9701 - val_mae: 2.7346\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.4001 - mae: 2.4795 - val_loss: 14.6924 - val_mae: 2.7131\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.2538 - mae: 2.4780 - val_loss: 15.1082 - val_mae: 2.7534\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 12.1271 - mae: 2.4683 - val_loss: 14.9439 - val_mae: 2.7312\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.9906 - mae: 2.4540 - val_loss: 15.0580 - val_mae: 2.7330\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.8715 - mae: 2.4519 - val_loss: 15.1369 - val_mae: 2.7447\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 11.7727 - mae: 2.4480 - val_loss: 14.9189 - val_mae: 2.7259\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 11.7061 - mae: 2.4397 - val_loss: 14.9731 - val_mae: 2.7399\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 11.7491 - mae: 2.4214 - val_loss: 14.5104 - val_mae: 2.6850\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.6148 - mae: 2.4107 - val_loss: 14.7623 - val_mae: 2.7039\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 11.4393 - mae: 2.4095 - val_loss: 14.6636 - val_mae: 2.6956\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 11.3656 - mae: 2.4000 - val_loss: 14.6149 - val_mae: 2.7083\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.3563 - mae: 2.3804 - val_loss: 14.3694 - val_mae: 2.6866\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 11.2754 - mae: 2.3806 - val_loss: 14.5784 - val_mae: 2.7016\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 11.1811 - mae: 2.3735 - val_loss: 14.4066 - val_mae: 2.6842\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 11.1055 - mae: 2.3681 - val_loss: 14.5051 - val_mae: 2.6971\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 11.0356 - mae: 2.3601 - val_loss: 14.4241 - val_mae: 2.6816\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.9958 - mae: 2.3565 - val_loss: 14.4375 - val_mae: 2.6854\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.8866 - mae: 2.3477 - val_loss: 14.2895 - val_mae: 2.6772\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 10.8471 - mae: 2.3399 - val_loss: 14.1573 - val_mae: 2.6671\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 10.8603 - mae: 2.3316 - val_loss: 14.2065 - val_mae: 2.6653\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.7597 - mae: 2.3208 - val_loss: 14.1546 - val_mae: 2.6691\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 10.7705 - mae: 2.3314 - val_loss: 14.5773 - val_mae: 2.7119\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 10.6062 - mae: 2.3328 - val_loss: 14.3735 - val_mae: 2.6940\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 10.5997 - mae: 2.3219 - val_loss: 13.9549 - val_mae: 2.6613\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 10.4922 - mae: 2.3048 - val_loss: 14.2148 - val_mae: 2.6660\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 10.4475 - mae: 2.3050 - val_loss: 14.1050 - val_mae: 2.6653\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 10.3492 - mae: 2.2975 - val_loss: 14.1307 - val_mae: 2.6770\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 10.3568 - mae: 2.2992 - val_loss: 14.1516 - val_mae: 2.6890\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 10.2587 - mae: 2.2945 - val_loss: 14.1631 - val_mae: 2.6668\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.1929 - mae: 2.2816 - val_loss: 14.1563 - val_mae: 2.6755\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 10.1344 - mae: 2.2815 - val_loss: 14.1564 - val_mae: 2.6948\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 10.1034 - mae: 2.2684 - val_loss: 13.8265 - val_mae: 2.6566\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.0292 - mae: 2.2645 - val_loss: 13.9860 - val_mae: 2.6629\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.9667 - mae: 2.2593 - val_loss: 13.9428 - val_mae: 2.6578\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.9457 - mae: 2.2513 - val_loss: 13.8878 - val_mae: 2.6833\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.8599 - mae: 2.2547 - val_loss: 14.1835 - val_mae: 2.6894\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.8548 - mae: 2.2607 - val_loss: 14.0916 - val_mae: 2.6622\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.7788 - mae: 2.2472 - val_loss: 13.9689 - val_mae: 2.6625\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.6953 - mae: 2.2366 - val_loss: 14.0705 - val_mae: 2.6954\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.7351 - mae: 2.2320 - val_loss: 13.8609 - val_mae: 2.6748\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.6459 - mae: 2.2212 - val_loss: 14.0006 - val_mae: 2.6679\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.6004 - mae: 2.2242 - val_loss: 13.8739 - val_mae: 2.6585\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.5923 - mae: 2.2161 - val_loss: 13.7655 - val_mae: 2.6615\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.4986 - mae: 2.1995 - val_loss: 13.6406 - val_mae: 2.6509\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.4344 - mae: 2.1950 - val_loss: 13.9157 - val_mae: 2.6624\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.4002 - mae: 2.2091 - val_loss: 14.1629 - val_mae: 2.6970\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.4070 - mae: 2.2151 - val_loss: 14.0170 - val_mae: 2.6794\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.3056 - mae: 2.1895 - val_loss: 13.6431 - val_mae: 2.6518\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.2859 - mae: 2.1792 - val_loss: 13.5530 - val_mae: 2.6279\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.2492 - mae: 2.1746 - val_loss: 13.7132 - val_mae: 2.6550\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 9.1948 - mae: 2.1800 - val_loss: 13.6702 - val_mae: 2.6482\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.1582 - mae: 2.1856 - val_loss: 13.7350 - val_mae: 2.6565\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 9.1632 - mae: 2.1747 - val_loss: 13.4081 - val_mae: 2.6476\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 9.0884 - mae: 2.1631 - val_loss: 13.6349 - val_mae: 2.6180\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 9.0584 - mae: 2.1730 - val_loss: 13.7406 - val_mae: 2.6616\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 8.9764 - mae: 2.1653 - val_loss: 13.6932 - val_mae: 2.6591\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 8.9048 - mae: 2.1509 - val_loss: 13.3560 - val_mae: 2.6324\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.9409 - mae: 2.1382 - val_loss: 13.3347 - val_mae: 2.6262\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.9530 - mae: 2.1541 - val_loss: 13.7122 - val_mae: 2.6435\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.7974 - mae: 2.1414 - val_loss: 13.3698 - val_mae: 2.6277\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.7703 - mae: 2.1329 - val_loss: 13.5167 - val_mae: 2.6433\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 8.7766 - mae: 2.1346 - val_loss: 13.4812 - val_mae: 2.6448\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.8351 - mae: 2.1297 - val_loss: 13.1438 - val_mae: 2.6113\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.7388 - mae: 2.1395 - val_loss: 13.6691 - val_mae: 2.6271\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.6256 - mae: 2.1209 - val_loss: 13.4385 - val_mae: 2.6350\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 8.6410 - mae: 2.1201 - val_loss: 13.3432 - val_mae: 2.6460\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.5460 - mae: 2.1180 - val_loss: 13.9565 - val_mae: 2.6774\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.5703 - mae: 2.1336 - val_loss: 13.6893 - val_mae: 2.6460\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.5289 - mae: 2.1151 - val_loss: 13.2525 - val_mae: 2.6110\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 8.4613 - mae: 2.0976 - val_loss: 13.3531 - val_mae: 2.6416\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 8.3838 - mae: 2.0989 - val_loss: 13.5367 - val_mae: 2.6440\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.4301 - mae: 2.1165 - val_loss: 13.5403 - val_mae: 2.6247\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.3584 - mae: 2.0907 - val_loss: 13.2347 - val_mae: 2.6024\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.3425 - mae: 2.0782 - val_loss: 13.3496 - val_mae: 2.6190\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 8.3064 - mae: 2.0714 - val_loss: 13.2236 - val_mae: 2.6109\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.2240 - mae: 2.0818 - val_loss: 13.6730 - val_mae: 2.6418\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.2091 - mae: 2.0957 - val_loss: 13.5766 - val_mae: 2.6545\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.1074 - mae: 2.0819 - val_loss: 13.4055 - val_mae: 2.6107\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.0740 - mae: 2.0749 - val_loss: 13.1770 - val_mae: 2.5881\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.0581 - mae: 2.0585 - val_loss: 13.0302 - val_mae: 2.5979\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.0241 - mae: 2.0454 - val_loss: 13.1915 - val_mae: 2.6071\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.9907 - mae: 2.0645 - val_loss: 13.3822 - val_mae: 2.6083\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.9416 - mae: 2.0646 - val_loss: 13.2065 - val_mae: 2.5950\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.9526 - mae: 2.0452 - val_loss: 12.9358 - val_mae: 2.5976\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.8914 - mae: 2.0393 - val_loss: 13.0186 - val_mae: 2.5775\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.8071 - mae: 2.0421 - val_loss: 13.1801 - val_mae: 2.6049\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.8167 - mae: 2.0511 - val_loss: 13.0875 - val_mae: 2.5816\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.7352 - mae: 2.0195 - val_loss: 12.8110 - val_mae: 2.5704\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.7276 - mae: 2.0180 - val_loss: 12.9676 - val_mae: 2.5652\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.7050 - mae: 2.0254 - val_loss: 13.1474 - val_mae: 2.5897\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.6398 - mae: 2.0162 - val_loss: 13.0660 - val_mae: 2.5654\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.6810 - mae: 2.0116 - val_loss: 12.9338 - val_mae: 2.5523\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.6207 - mae: 2.0453 - val_loss: 13.9689 - val_mae: 2.6831\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.6117 - mae: 2.0342 - val_loss: 13.0963 - val_mae: 2.5851\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4954 - mae: 1.9929 - val_loss: 12.9203 - val_mae: 2.5573\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4552 - mae: 1.9829 - val_loss: 13.0379 - val_mae: 2.5727\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4392 - mae: 1.9878 - val_loss: 12.9889 - val_mae: 2.5585\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4117 - mae: 1.9985 - val_loss: 13.3420 - val_mae: 2.5987\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3533 - mae: 1.9935 - val_loss: 13.2370 - val_mae: 2.5863\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3968 - mae: 1.9692 - val_loss: 12.7203 - val_mae: 2.5420\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.3104 - mae: 1.9666 - val_loss: 13.0258 - val_mae: 2.5665\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.2848 - mae: 1.9861 - val_loss: 13.3400 - val_mae: 2.6002\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.3160 - mae: 1.9820 - val_loss: 13.0839 - val_mae: 2.5913\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.3005 - mae: 1.9866 - val_loss: 13.1939 - val_mae: 2.5743\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.1568 - mae: 1.9601 - val_loss: 12.9511 - val_mae: 2.5523\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.2972 - mae: 1.9720 - val_loss: 12.7416 - val_mae: 2.5545\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.1396 - mae: 1.9515 - val_loss: 12.8285 - val_mae: 2.5319\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.1100 - mae: 1.9588 - val_loss: 12.8965 - val_mae: 2.5493\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.0374 - mae: 1.9474 - val_loss: 12.8444 - val_mae: 2.5524\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.0317 - mae: 1.9404 - val_loss: 12.9473 - val_mae: 2.5557\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9897 - mae: 1.9410 - val_loss: 13.0619 - val_mae: 2.5634\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9509 - mae: 1.9403 - val_loss: 13.0716 - val_mae: 2.5545\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9987 - mae: 1.9558 - val_loss: 13.1539 - val_mae: 2.5598\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.9099 - mae: 1.9266 - val_loss: 12.8663 - val_mae: 2.5514\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9107 - mae: 1.9172 - val_loss: 12.7396 - val_mae: 2.5289\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.9025 - mae: 1.9333 - val_loss: 13.0354 - val_mae: 2.5685\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9184 - mae: 1.9231 - val_loss: 12.7069 - val_mae: 2.5381\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.9462 - mae: 1.9360 - val_loss: 13.0795 - val_mae: 2.5480\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7979 - mae: 1.9132 - val_loss: 12.6462 - val_mae: 2.5125\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7861 - mae: 1.8946 - val_loss: 12.7478 - val_mae: 2.5371\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7347 - mae: 1.9148 - val_loss: 12.9018 - val_mae: 2.5523\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7296 - mae: 1.9053 - val_loss: 12.7639 - val_mae: 2.5169\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.7023 - mae: 1.9101 - val_loss: 12.8876 - val_mae: 2.5430\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.6783 - mae: 1.9124 - val_loss: 12.7132 - val_mae: 2.5332\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.6367 - mae: 1.8980 - val_loss: 12.8085 - val_mae: 2.5174\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.5494 - mae: 1.8892 - val_loss: 13.0559 - val_mae: 2.5433\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.5730 - mae: 1.8938 - val_loss: 13.1452 - val_mae: 2.5537\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4959 - mae: 1.8679 - val_loss: 12.6667 - val_mae: 2.4991\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5468 - mae: 1.8674 - val_loss: 12.6369 - val_mae: 2.4989\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.5026 - mae: 1.8753 - val_loss: 12.6576 - val_mae: 2.5138\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.4498 - mae: 1.8738 - val_loss: 12.8563 - val_mae: 2.5172\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.4149 - mae: 1.8681 - val_loss: 12.7534 - val_mae: 2.5121\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.3982 - mae: 1.8598 - val_loss: 12.6347 - val_mae: 2.5105\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.3928 - mae: 1.8639 - val_loss: 12.8819 - val_mae: 2.5326\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.3841 - mae: 1.8710 - val_loss: 12.7418 - val_mae: 2.5072\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.3228 - mae: 1.8504 - val_loss: 12.6275 - val_mae: 2.5036\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4489 - mae: 1.8483 - val_loss: 12.5554 - val_mae: 2.4821\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.3068 - mae: 1.8507 - val_loss: 12.7487 - val_mae: 2.5187\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2229 - mae: 1.8406 - val_loss: 12.5487 - val_mae: 2.4942\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2326 - mae: 1.8382 - val_loss: 12.5311 - val_mae: 2.4838\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2239 - mae: 1.8355 - val_loss: 12.4516 - val_mae: 2.4753\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.1953 - mae: 1.8353 - val_loss: 12.8541 - val_mae: 2.5298\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1748 - mae: 1.8491 - val_loss: 12.5900 - val_mae: 2.4965\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.1586 - mae: 1.8382 - val_loss: 12.6782 - val_mae: 2.4920\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.1310 - mae: 1.8203 - val_loss: 12.3523 - val_mae: 2.4568\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.0913 - mae: 1.8202 - val_loss: 12.7098 - val_mae: 2.5098\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0942 - mae: 1.8346 - val_loss: 12.6726 - val_mae: 2.4942\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.0666 - mae: 1.8095 - val_loss: 12.3015 - val_mae: 2.4662\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.0148 - mae: 1.8013 - val_loss: 12.5123 - val_mae: 2.4841\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9875 - mae: 1.8097 - val_loss: 12.6846 - val_mae: 2.4918\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9529 - mae: 1.8087 - val_loss: 12.6217 - val_mae: 2.4849\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9944 - mae: 1.8011 - val_loss: 12.5182 - val_mae: 2.4733\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.0215 - mae: 1.8192 - val_loss: 13.1176 - val_mae: 2.5233\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9721 - mae: 1.8058 - val_loss: 12.5535 - val_mae: 2.4625\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9436 - mae: 1.7965 - val_loss: 12.6319 - val_mae: 2.4973\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.8996 - mae: 1.8025 - val_loss: 12.4862 - val_mae: 2.4563\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8264 - mae: 1.7594 - val_loss: 12.2130 - val_mae: 2.4346\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.8810 - mae: 1.7599 - val_loss: 12.3366 - val_mae: 2.4610\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8118 - mae: 1.7825 - val_loss: 12.9730 - val_mae: 2.5273\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8187 - mae: 1.8048 - val_loss: 12.6357 - val_mae: 2.4753\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.7276 - mae: 1.7747 - val_loss: 12.4814 - val_mae: 2.4569\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7311 - mae: 1.7553 - val_loss: 12.3774 - val_mae: 2.4515\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.7147 - mae: 1.7651 - val_loss: 12.4926 - val_mae: 2.4695\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.8037 - mae: 1.8107 - val_loss: 12.8061 - val_mae: 2.4986\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.6464 - mae: 1.7525 - val_loss: 12.3447 - val_mae: 2.4291\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.6797 - mae: 1.7540 - val_loss: 12.5110 - val_mae: 2.4716\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.6768 - mae: 1.7624 - val_loss: 12.3670 - val_mae: 2.4462\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5845 - mae: 1.7488 - val_loss: 12.3934 - val_mae: 2.4519\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.6603 - mae: 1.7315 - val_loss: 12.4563 - val_mae: 2.4545\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.6560 - mae: 1.7629 - val_loss: 12.8555 - val_mae: 2.4970\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.7458 - mae: 1.7691 - val_loss: 12.1230 - val_mae: 2.4295\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.5774 - mae: 1.7290 - val_loss: 12.8891 - val_mae: 2.4637\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.5509 - mae: 1.7392 - val_loss: 12.7195 - val_mae: 2.4887\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.4493 - mae: 1.7365 - val_loss: 12.5215 - val_mae: 2.4394\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.4139 - mae: 1.7126 - val_loss: 12.2905 - val_mae: 2.4177\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.3830 - mae: 1.7024 - val_loss: 12.5100 - val_mae: 2.4546\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.4008 - mae: 1.7175 - val_loss: 12.3395 - val_mae: 2.4498\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.3440 - mae: 1.7026 - val_loss: 12.3167 - val_mae: 2.4352\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3076 - mae: 1.6946 - val_loss: 12.2917 - val_mae: 2.4300\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3296 - mae: 1.6838 - val_loss: 12.0882 - val_mae: 2.4133\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3410 - mae: 1.7030 - val_loss: 12.4163 - val_mae: 2.4519\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.2462 - mae: 1.6919 - val_loss: 12.2735 - val_mae: 2.4202\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.2012 - mae: 1.6726 - val_loss: 12.1135 - val_mae: 2.4122\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1917 - mae: 1.6857 - val_loss: 12.3032 - val_mae: 2.4340\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.1851 - mae: 1.6818 - val_loss: 12.2554 - val_mae: 2.4085\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.1353 - mae: 1.6627 - val_loss: 12.2271 - val_mae: 2.4152\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.1256 - mae: 1.6590 - val_loss: 12.2401 - val_mae: 2.4127\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.1231 - mae: 1.6657 - val_loss: 12.1853 - val_mae: 2.4230\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.0899 - mae: 1.6477 - val_loss: 12.2768 - val_mae: 2.4201\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.0634 - mae: 1.6682 - val_loss: 12.3882 - val_mae: 2.4411\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.1127 - mae: 1.6561 - val_loss: 12.2152 - val_mae: 2.4155\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0180 - mae: 1.6392 - val_loss: 11.9513 - val_mae: 2.3992\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 4.9965 - mae: 1.6279 - val_loss: 11.9891 - val_mae: 2.3844\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.0319 - mae: 1.6727 - val_loss: 12.5236 - val_mae: 2.4501\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.9472 - mae: 1.6490 - val_loss: 12.1733 - val_mae: 2.3926\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.9420 - mae: 1.6238 - val_loss: 12.0041 - val_mae: 2.3961\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 4.9833 - mae: 1.6545 - val_loss: 12.3386 - val_mae: 2.4208\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.9935 - mae: 1.6451 - val_loss: 12.0578 - val_mae: 2.4001\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 4.8105 - mae: 1.6041 - val_loss: 12.2213 - val_mae: 2.4004\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.8346 - mae: 1.6093 - val_loss: 12.0520 - val_mae: 2.3935\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.8056 - mae: 1.6006 - val_loss: 11.8932 - val_mae: 2.3792\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.7564 - mae: 1.5951 - val_loss: 12.0563 - val_mae: 2.4122\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 4.7230 - mae: 1.6029 - val_loss: 12.1249 - val_mae: 2.4019\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 4.7590 - mae: 1.6157 - val_loss: 12.2441 - val_mae: 2.4132\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 4.7859 - mae: 1.6026 - val_loss: 12.2619 - val_mae: 2.3927\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.6592 - mae: 1.5820 - val_loss: 12.0808 - val_mae: 2.4191\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.6695 - mae: 1.5998 - val_loss: 12.0067 - val_mae: 2.3960\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.6074 - mae: 1.5700 - val_loss: 11.9558 - val_mae: 2.3762\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.6615 - mae: 1.5693 - val_loss: 11.9319 - val_mae: 2.3712\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.5890 - mae: 1.5703 - val_loss: 12.2739 - val_mae: 2.4236\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.5255 - mae: 1.5793 - val_loss: 12.0043 - val_mae: 2.3748\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 4.6001 - mae: 1.5529 - val_loss: 11.9140 - val_mae: 2.3754\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 4.5250 - mae: 1.5586 - val_loss: 12.1641 - val_mae: 2.4002\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 4.5072 - mae: 1.5464 - val_loss: 11.7223 - val_mae: 2.3464\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.4269 - mae: 1.5252 - val_loss: 12.1727 - val_mae: 2.4085\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.4618 - mae: 1.5487 - val_loss: 12.0814 - val_mae: 2.4098\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 4.4013 - mae: 1.5260 - val_loss: 12.0924 - val_mae: 2.3961\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.3768 - mae: 1.5411 - val_loss: 12.3171 - val_mae: 2.4378\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 4.4120 - mae: 1.5380 - val_loss: 11.7987 - val_mae: 2.3634\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 4.3684 - mae: 1.5225 - val_loss: 12.1000 - val_mae: 2.3919\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.3168 - mae: 1.5115 - val_loss: 11.8643 - val_mae: 2.3762\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.2895 - mae: 1.5063 - val_loss: 12.0910 - val_mae: 2.4055\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.2625 - mae: 1.5123 - val_loss: 11.9601 - val_mae: 2.3812\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.1953 - mae: 1.5010 - val_loss: 11.7892 - val_mae: 2.3711\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.2030 - mae: 1.4957 - val_loss: 11.8702 - val_mae: 2.3834\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.1661 - mae: 1.4810 - val_loss: 11.6994 - val_mae: 2.3652\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.1410 - mae: 1.4789 - val_loss: 11.9340 - val_mae: 2.3856\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.0999 - mae: 1.4849 - val_loss: 11.8957 - val_mae: 2.3780\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0746 - mae: 1.4798 - val_loss: 11.7788 - val_mae: 2.3665\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.0788 - mae: 1.4579 - val_loss: 11.7000 - val_mae: 2.3642\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.0904 - mae: 1.4779 - val_loss: 11.8609 - val_mae: 2.3874\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.1477 - mae: 2.1488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivqBS_2URJqJ",
        "outputId": "d07b9dbc-4deb-4da2-cd5b-a0af67f31b43"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.0781009197235107, 2.1526222229003906, 2.148803472518921]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Fold 사용한 모델 성능 평가"
      ],
      "metadata": {
        "id": "HCrMHGafSGqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(mae_list)\n",
        "# 2.12 → 실제 집값과 2,120달러 차이"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PhEYiUiSJ1j",
        "outputId": "265f574b-5826-43c5-b8c6-38519847d6ee"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.126508871714274"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 검증 데이터셋 사용하지 않고 학습한 모델 성능 평가"
      ],
      "metadata": {
        "id": "umcHEZ8pSbaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets.boston_housing import load_data\n",
        "\n",
        "# 데이터 다운로드 (훈련셋 80 : 테스트셋 20)\n",
        "(X_train, y_train), (X_test, y_test) = load_data(path = 'boston_housing.npz',\n",
        "                                                 test_split = 0.2,\n",
        "                                                 seed = 777)\n",
        "\n",
        "# 표준화 : (데이터 - 전체 평균) / 표준편차\n",
        "mean = np.mean(X_train, axis = 0) # 모든 데이터의 평균을 구해야 하기 때문에, axis는 0\n",
        "std = np.std(X_train, axis = 0)\n",
        "\n",
        "# X_train을 전처리했기 때문에, X_test도 전처리해 줘야 함\n",
        "# 전처리에서는 X_train과 X_test 둘 다 처리\n",
        "# 만약 처음부터 데이터가 합쳐진 상태에서 받아왔다면, 전처리 이후에 X_train과 X_test로 분리하는 게 더 편리함\n",
        "\n",
        "X_train = (X_train - mean) / std\n",
        "X_test = (X_test - mean) / std\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(64, activation = 'relu', input_shape = (13, )))\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
        "\n",
        "# 훈련 데이터셋에서 검증 데이터셋을 분리하지 않고, 모두 학습에 사용\n",
        "model.fit(X_train, y_train, epochs = 300)\n",
        "\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KZoo5egSNEo",
        "outputId": "bde0658f-3353-4abf-c4a9-1e4ff053c443"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "13/13 [==============================] - 1s 2ms/step - loss: 574.7262 - mae: 22.1167\n",
            "Epoch 2/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 533.4696 - mae: 21.1264\n",
            "Epoch 3/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 491.9438 - mae: 20.0579\n",
            "Epoch 4/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 443.0674 - mae: 18.7384\n",
            "Epoch 5/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 380.8099 - mae: 17.1154\n",
            "Epoch 6/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 304.2379 - mae: 15.1027\n",
            "Epoch 7/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 223.9538 - mae: 12.7432\n",
            "Epoch 8/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 146.6111 - mae: 10.0091\n",
            "Epoch 9/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 92.1826 - mae: 7.5926\n",
            "Epoch 10/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 65.5694 - mae: 6.2010\n",
            "Epoch 11/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 52.1582 - mae: 5.4459\n",
            "Epoch 12/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 42.9875 - mae: 4.8669\n",
            "Epoch 13/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 35.9620 - mae: 4.3924\n",
            "Epoch 14/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 31.6778 - mae: 4.0895\n",
            "Epoch 15/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 28.6434 - mae: 3.8589\n",
            "Epoch 16/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 26.4676 - mae: 3.6538\n",
            "Epoch 17/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 24.9595 - mae: 3.5251\n",
            "Epoch 18/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 23.7562 - mae: 3.4359\n",
            "Epoch 19/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 22.7432 - mae: 3.3511\n",
            "Epoch 20/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 22.0153 - mae: 3.2781\n",
            "Epoch 21/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 21.2245 - mae: 3.2180\n",
            "Epoch 22/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 20.5925 - mae: 3.1558\n",
            "Epoch 23/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 19.9702 - mae: 3.1087\n",
            "Epoch 24/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 19.4279 - mae: 3.0796\n",
            "Epoch 25/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 18.8938 - mae: 3.0281\n",
            "Epoch 26/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 18.5658 - mae: 2.9969\n",
            "Epoch 27/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 17.9421 - mae: 2.9349\n",
            "Epoch 28/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 17.5702 - mae: 2.9019\n",
            "Epoch 29/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 17.2334 - mae: 2.8723\n",
            "Epoch 30/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 16.8175 - mae: 2.8384\n",
            "Epoch 31/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 16.4623 - mae: 2.8034\n",
            "Epoch 32/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 16.1198 - mae: 2.7690\n",
            "Epoch 33/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 15.8156 - mae: 2.7404\n",
            "Epoch 34/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 15.6545 - mae: 2.7323\n",
            "Epoch 35/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 15.2768 - mae: 2.6960\n",
            "Epoch 36/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 14.9694 - mae: 2.6633\n",
            "Epoch 37/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 14.7497 - mae: 2.6465\n",
            "Epoch 38/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 14.4614 - mae: 2.6223\n",
            "Epoch 39/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 14.2475 - mae: 2.6062\n",
            "Epoch 40/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 14.0742 - mae: 2.5928\n",
            "Epoch 41/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 13.8049 - mae: 2.5770\n",
            "Epoch 42/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 13.6649 - mae: 2.5532\n",
            "Epoch 43/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 13.5463 - mae: 2.5656\n",
            "Epoch 44/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 13.5351 - mae: 2.5411\n",
            "Epoch 45/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 13.2453 - mae: 2.5245\n",
            "Epoch 46/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 13.0177 - mae: 2.5242\n",
            "Epoch 47/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 12.8225 - mae: 2.4894\n",
            "Epoch 48/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 12.6325 - mae: 2.4790\n",
            "Epoch 49/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 12.5411 - mae: 2.4742\n",
            "Epoch 50/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 12.4198 - mae: 2.4463\n",
            "Epoch 51/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 12.2484 - mae: 2.4397\n",
            "Epoch 52/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 12.0765 - mae: 2.4179\n",
            "Epoch 53/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 12.0161 - mae: 2.4273\n",
            "Epoch 54/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 11.8988 - mae: 2.4178\n",
            "Epoch 55/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.7270 - mae: 2.3772\n",
            "Epoch 56/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.6982 - mae: 2.3888\n",
            "Epoch 57/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 11.5077 - mae: 2.3815\n",
            "Epoch 58/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 11.3758 - mae: 2.3637\n",
            "Epoch 59/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 11.3054 - mae: 2.3587\n",
            "Epoch 60/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 11.3400 - mae: 2.3693\n",
            "Epoch 61/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 11.1084 - mae: 2.3357\n",
            "Epoch 62/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 11.0225 - mae: 2.3188\n",
            "Epoch 63/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.9206 - mae: 2.3121\n",
            "Epoch 64/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.8995 - mae: 2.3296\n",
            "Epoch 65/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 10.8660 - mae: 2.3220\n",
            "Epoch 66/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.7339 - mae: 2.2861\n",
            "Epoch 67/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.5213 - mae: 2.2676\n",
            "Epoch 68/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.5142 - mae: 2.2913\n",
            "Epoch 69/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.5544 - mae: 2.2697\n",
            "Epoch 70/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 10.4500 - mae: 2.2864\n",
            "Epoch 71/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 10.2812 - mae: 2.2652\n",
            "Epoch 72/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.2360 - mae: 2.2504\n",
            "Epoch 73/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.0854 - mae: 2.2391\n",
            "Epoch 74/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.0244 - mae: 2.2294\n",
            "Epoch 75/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.0239 - mae: 2.2300\n",
            "Epoch 76/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.8745 - mae: 2.2176\n",
            "Epoch 77/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.8594 - mae: 2.2210\n",
            "Epoch 78/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 9.7385 - mae: 2.2086\n",
            "Epoch 79/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.6570 - mae: 2.1858\n",
            "Epoch 80/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.5972 - mae: 2.1858\n",
            "Epoch 81/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.5603 - mae: 2.1837\n",
            "Epoch 82/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.4833 - mae: 2.1686\n",
            "Epoch 83/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 9.4998 - mae: 2.1820\n",
            "Epoch 84/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 9.3594 - mae: 2.1522\n",
            "Epoch 85/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.3612 - mae: 2.1722\n",
            "Epoch 86/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.2365 - mae: 2.1524\n",
            "Epoch 87/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 9.2489 - mae: 2.1373\n",
            "Epoch 88/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 9.1992 - mae: 2.1330\n",
            "Epoch 89/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 9.1450 - mae: 2.1347\n",
            "Epoch 90/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.0336 - mae: 2.1282\n",
            "Epoch 91/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.9295 - mae: 2.1179\n",
            "Epoch 92/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.9738 - mae: 2.1266\n",
            "Epoch 93/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.9265 - mae: 2.1133\n",
            "Epoch 94/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.8299 - mae: 2.1266\n",
            "Epoch 95/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.7983 - mae: 2.0974\n",
            "Epoch 96/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.8511 - mae: 2.1113\n",
            "Epoch 97/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.6259 - mae: 2.0907\n",
            "Epoch 98/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.5800 - mae: 2.0791\n",
            "Epoch 99/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.5708 - mae: 2.0936\n",
            "Epoch 100/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.4802 - mae: 2.0721\n",
            "Epoch 101/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.4254 - mae: 2.0708\n",
            "Epoch 102/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.3420 - mae: 2.0585\n",
            "Epoch 103/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.2704 - mae: 2.0519\n",
            "Epoch 104/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.2937 - mae: 2.0506\n",
            "Epoch 105/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.2261 - mae: 2.0597\n",
            "Epoch 106/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.1331 - mae: 2.0443\n",
            "Epoch 107/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.1142 - mae: 2.0330\n",
            "Epoch 108/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.1451 - mae: 2.0406\n",
            "Epoch 109/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.9941 - mae: 2.0205\n",
            "Epoch 110/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.0163 - mae: 2.0454\n",
            "Epoch 111/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.9502 - mae: 2.0095\n",
            "Epoch 112/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.8532 - mae: 2.0027\n",
            "Epoch 113/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 7.8750 - mae: 2.0388\n",
            "Epoch 114/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.7225 - mae: 2.0092\n",
            "Epoch 115/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.7216 - mae: 1.9929\n",
            "Epoch 116/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.7745 - mae: 2.0279\n",
            "Epoch 117/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.6718 - mae: 1.9837\n",
            "Epoch 118/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.5153 - mae: 1.9853\n",
            "Epoch 119/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.5199 - mae: 1.9857\n",
            "Epoch 120/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.3962 - mae: 1.9624\n",
            "Epoch 121/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.3717 - mae: 1.9516\n",
            "Epoch 122/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.4295 - mae: 1.9846\n",
            "Epoch 123/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.3083 - mae: 1.9543\n",
            "Epoch 124/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.2178 - mae: 1.9408\n",
            "Epoch 125/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.1606 - mae: 1.9476\n",
            "Epoch 126/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.1544 - mae: 1.9356\n",
            "Epoch 127/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.0057 - mae: 1.9205\n",
            "Epoch 128/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.9891 - mae: 1.9321\n",
            "Epoch 129/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.9765 - mae: 1.9159\n",
            "Epoch 130/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.9751 - mae: 1.9046\n",
            "Epoch 131/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.8349 - mae: 1.9009\n",
            "Epoch 132/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.8409 - mae: 1.9102\n",
            "Epoch 133/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.7499 - mae: 1.8917\n",
            "Epoch 134/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.7467 - mae: 1.8753\n",
            "Epoch 135/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.6918 - mae: 1.8959\n",
            "Epoch 136/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.6115 - mae: 1.8704\n",
            "Epoch 137/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.5534 - mae: 1.8659\n",
            "Epoch 138/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.5582 - mae: 1.8691\n",
            "Epoch 139/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.4861 - mae: 1.8519\n",
            "Epoch 140/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.4331 - mae: 1.8537\n",
            "Epoch 141/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.3641 - mae: 1.8436\n",
            "Epoch 142/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.3179 - mae: 1.8255\n",
            "Epoch 143/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.3000 - mae: 1.8519\n",
            "Epoch 144/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.2241 - mae: 1.8244\n",
            "Epoch 145/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.2212 - mae: 1.8151\n",
            "Epoch 146/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.1955 - mae: 1.8345\n",
            "Epoch 147/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.2059 - mae: 1.8179\n",
            "Epoch 148/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.1396 - mae: 1.8241\n",
            "Epoch 149/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.0485 - mae: 1.8132\n",
            "Epoch 150/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 6.0179 - mae: 1.8001\n",
            "Epoch 151/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.9488 - mae: 1.7806\n",
            "Epoch 152/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.9013 - mae: 1.7959\n",
            "Epoch 153/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.8601 - mae: 1.7819\n",
            "Epoch 154/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.0463 - mae: 1.8067\n",
            "Epoch 155/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.8445 - mae: 1.7717\n",
            "Epoch 156/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.7618 - mae: 1.7751\n",
            "Epoch 157/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.6711 - mae: 1.7512\n",
            "Epoch 158/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.6891 - mae: 1.7569\n",
            "Epoch 159/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.6544 - mae: 1.7545\n",
            "Epoch 160/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.6514 - mae: 1.7346\n",
            "Epoch 161/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.6190 - mae: 1.7584\n",
            "Epoch 162/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.5456 - mae: 1.7358\n",
            "Epoch 163/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.4737 - mae: 1.7434\n",
            "Epoch 164/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.5721 - mae: 1.7291\n",
            "Epoch 165/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.4229 - mae: 1.7241\n",
            "Epoch 166/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.4796 - mae: 1.7357\n",
            "Epoch 167/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.4290 - mae: 1.7288\n",
            "Epoch 168/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.3243 - mae: 1.7076\n",
            "Epoch 169/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.3099 - mae: 1.7201\n",
            "Epoch 170/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5.3450 - mae: 1.7267\n",
            "Epoch 171/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.2531 - mae: 1.6869\n",
            "Epoch 172/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.1832 - mae: 1.6845\n",
            "Epoch 173/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.1336 - mae: 1.6858\n",
            "Epoch 174/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.1477 - mae: 1.6834\n",
            "Epoch 175/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0888 - mae: 1.6763\n",
            "Epoch 176/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0867 - mae: 1.6751\n",
            "Epoch 177/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0258 - mae: 1.6658\n",
            "Epoch 178/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0545 - mae: 1.6548\n",
            "Epoch 179/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.1507 - mae: 1.6981\n",
            "Epoch 180/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0017 - mae: 1.6609\n",
            "Epoch 181/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.1241 - mae: 1.6877\n",
            "Epoch 182/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.9556 - mae: 1.6476\n",
            "Epoch 183/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.9305 - mae: 1.6660\n",
            "Epoch 184/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.8791 - mae: 1.6219\n",
            "Epoch 185/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8146 - mae: 1.6475\n",
            "Epoch 186/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8159 - mae: 1.6317\n",
            "Epoch 187/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7940 - mae: 1.6290\n",
            "Epoch 188/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7639 - mae: 1.6324\n",
            "Epoch 189/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7780 - mae: 1.6195\n",
            "Epoch 190/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 4.6870 - mae: 1.6160\n",
            "Epoch 191/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.6801 - mae: 1.6123\n",
            "Epoch 192/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.6936 - mae: 1.6120\n",
            "Epoch 193/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6820 - mae: 1.6269\n",
            "Epoch 194/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6721 - mae: 1.6135\n",
            "Epoch 195/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6041 - mae: 1.5959\n",
            "Epoch 196/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.6043 - mae: 1.5905\n",
            "Epoch 197/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6338 - mae: 1.5981\n",
            "Epoch 198/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5358 - mae: 1.5769\n",
            "Epoch 199/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5084 - mae: 1.5823\n",
            "Epoch 200/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.4769 - mae: 1.5984\n",
            "Epoch 201/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.4653 - mae: 1.5591\n",
            "Epoch 202/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.4475 - mae: 1.5847\n",
            "Epoch 203/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.4014 - mae: 1.5572\n",
            "Epoch 204/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.3933 - mae: 1.5613\n",
            "Epoch 205/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.3622 - mae: 1.5428\n",
            "Epoch 206/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.3785 - mae: 1.5575\n",
            "Epoch 207/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.3222 - mae: 1.5555\n",
            "Epoch 208/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.2988 - mae: 1.5347\n",
            "Epoch 209/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.3428 - mae: 1.5515\n",
            "Epoch 210/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.2565 - mae: 1.5463\n",
            "Epoch 211/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.2177 - mae: 1.5201\n",
            "Epoch 212/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.2184 - mae: 1.5315\n",
            "Epoch 213/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.2393 - mae: 1.5239\n",
            "Epoch 214/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.2094 - mae: 1.5327\n",
            "Epoch 215/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.1617 - mae: 1.5025\n",
            "Epoch 216/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.1122 - mae: 1.5209\n",
            "Epoch 217/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.1141 - mae: 1.4993\n",
            "Epoch 218/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.1648 - mae: 1.5375\n",
            "Epoch 219/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.1291 - mae: 1.5061\n",
            "Epoch 220/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.1021 - mae: 1.5213\n",
            "Epoch 221/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.0506 - mae: 1.4848\n",
            "Epoch 222/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.0359 - mae: 1.4955\n",
            "Epoch 223/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.9724 - mae: 1.4718\n",
            "Epoch 224/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.0532 - mae: 1.4931\n",
            "Epoch 225/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.0340 - mae: 1.5023\n",
            "Epoch 226/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.1095 - mae: 1.4950\n",
            "Epoch 227/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.9747 - mae: 1.4716\n",
            "Epoch 228/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.9791 - mae: 1.5079\n",
            "Epoch 229/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.9798 - mae: 1.4750\n",
            "Epoch 230/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.9642 - mae: 1.4768\n",
            "Epoch 231/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.9083 - mae: 1.4839\n",
            "Epoch 232/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.8524 - mae: 1.4670\n",
            "Epoch 233/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.8935 - mae: 1.4969\n",
            "Epoch 234/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.8524 - mae: 1.4605\n",
            "Epoch 235/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.8101 - mae: 1.4450\n",
            "Epoch 236/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.8334 - mae: 1.4629\n",
            "Epoch 237/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.7372 - mae: 1.4355\n",
            "Epoch 238/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.7845 - mae: 1.4481\n",
            "Epoch 239/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.7187 - mae: 1.4446\n",
            "Epoch 240/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.9268 - mae: 1.4592\n",
            "Epoch 241/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.7206 - mae: 1.4535\n",
            "Epoch 242/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.7238 - mae: 1.4319\n",
            "Epoch 243/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.6703 - mae: 1.4344\n",
            "Epoch 244/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.7061 - mae: 1.4278\n",
            "Epoch 245/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.7088 - mae: 1.4455\n",
            "Epoch 246/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.7673 - mae: 1.4301\n",
            "Epoch 247/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.7668 - mae: 1.4857\n",
            "Epoch 248/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.8259 - mae: 1.4397\n",
            "Epoch 249/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.7505 - mae: 1.4762\n",
            "Epoch 250/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.8114 - mae: 1.4433\n",
            "Epoch 251/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.7663 - mae: 1.4651\n",
            "Epoch 252/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.5919 - mae: 1.4027\n",
            "Epoch 253/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.6337 - mae: 1.4268\n",
            "Epoch 254/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.5595 - mae: 1.3938\n",
            "Epoch 255/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.5182 - mae: 1.4049\n",
            "Epoch 256/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.6154 - mae: 1.3906\n",
            "Epoch 257/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.5312 - mae: 1.4056\n",
            "Epoch 258/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.5320 - mae: 1.3985\n",
            "Epoch 259/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.5701 - mae: 1.4011\n",
            "Epoch 260/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.4773 - mae: 1.3896\n",
            "Epoch 261/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.4709 - mae: 1.3865\n",
            "Epoch 262/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.4564 - mae: 1.3624\n",
            "Epoch 263/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.4889 - mae: 1.3999\n",
            "Epoch 264/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.4119 - mae: 1.3634\n",
            "Epoch 265/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.4337 - mae: 1.3772\n",
            "Epoch 266/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.4155 - mae: 1.3775\n",
            "Epoch 267/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.4386 - mae: 1.3752\n",
            "Epoch 268/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.3681 - mae: 1.3670\n",
            "Epoch 269/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.3152 - mae: 1.3443\n",
            "Epoch 270/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.3478 - mae: 1.3580\n",
            "Epoch 271/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.3783 - mae: 1.3647\n",
            "Epoch 272/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.3379 - mae: 1.3526\n",
            "Epoch 273/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.3411 - mae: 1.3616\n",
            "Epoch 274/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.2974 - mae: 1.3391\n",
            "Epoch 275/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.2913 - mae: 1.3517\n",
            "Epoch 276/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.3162 - mae: 1.3375\n",
            "Epoch 277/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.2394 - mae: 1.3387\n",
            "Epoch 278/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.2428 - mae: 1.3287\n",
            "Epoch 279/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.2167 - mae: 1.3323\n",
            "Epoch 280/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.2416 - mae: 1.3263\n",
            "Epoch 281/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.2485 - mae: 1.3530\n",
            "Epoch 282/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.2251 - mae: 1.3225\n",
            "Epoch 283/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.2406 - mae: 1.3408\n",
            "Epoch 284/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.1635 - mae: 1.3229\n",
            "Epoch 285/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.1279 - mae: 1.3004\n",
            "Epoch 286/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.1206 - mae: 1.3023\n",
            "Epoch 287/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.1552 - mae: 1.3201\n",
            "Epoch 288/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.1627 - mae: 1.3191\n",
            "Epoch 289/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.2418 - mae: 1.3449\n",
            "Epoch 290/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.1404 - mae: 1.3218\n",
            "Epoch 291/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.0701 - mae: 1.2930\n",
            "Epoch 292/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.0738 - mae: 1.3022\n",
            "Epoch 293/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.0512 - mae: 1.2913\n",
            "Epoch 294/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.2139 - mae: 1.3484\n",
            "Epoch 295/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.0443 - mae: 1.3042\n",
            "Epoch 296/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.0651 - mae: 1.2951\n",
            "Epoch 297/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.1471 - mae: 1.3090\n",
            "Epoch 298/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.1065 - mae: 1.3111\n",
            "Epoch 299/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.0019 - mae: 1.2941\n",
            "Epoch 300/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.0862 - mae: 1.2960\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 8.7186 - mae: 2.1060\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8.718583106994629, 2.105992555618286]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test) # 2.1 → 실제 집값과 2,100달러 차이"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP6GhfeHTLbi",
        "outputId": "97416a33-1147-4b2c-fb7d-0a1159818728"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step - loss: 8.7186 - mae: 2.1060\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8.718583106994629, 2.105992555618286]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-Fold 사용한 모델의 성능 평가"
      ],
      "metadata": {
        "id": "VtG3OGMnT2gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets.boston_housing import load_data\n",
        "import numpy as np\n",
        "\n",
        "# 데이터 다운로드 (훈련셋 80 : 테스트셋 20)\n",
        "(X_train, y_train), (X_test, y_test) = load_data(path = 'boston_housing.npz',\n",
        "                                                 test_split = 0.2,\n",
        "                                                 seed = 777)\n",
        "\n",
        "# 표준화 : (데이터 - 전체 평균) / 표준편차\n",
        "mean = np.mean(X_train, axis = 0) # 모든 데이터의 평균을 구해야 하기 때문에, axis는 0\n",
        "std = np.std(X_train, axis = 0)\n",
        "\n",
        "# X_train을 전처리했기 때문에, X_test도 전처리해 줘야 함\n",
        "# 전처리에서는 X_train과 X_test 둘 다 처리\n",
        "# 만약 처음부터 데이터가 합쳐진 상태에서 받아왔다면, 전처리 이후에 X_train과 X_test로 분리하는 게 더 편리함\n",
        "\n",
        "X_train = (X_train - mean) / std\n",
        "X_test = (X_test - mean) / std\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# 몇 번에 나눠서 학습할 것인지 k를 지정해 줘야 함\n",
        "# 4-Fold로 나눠서 검증 데이터셋 사용하여 학습\n",
        "k = 4\n",
        "\n",
        "kfold = KFold(n_splits = k) # n_splits : 몇 개로 나눠서 학습할지\n",
        "\n",
        "# 재사용을 위해 모델 구성 및 설정 함수로 선언\n",
        "\n",
        "def get_model() :\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(64, activation = 'relu', input_shape = (13, )))\n",
        "  model.add(Dense(32, activation = 'relu'))\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# 각 모델(4개의 KFold)의 평가 정보 담는 리스트 선언\n",
        "mae_list = []\n",
        "\n",
        "# k번 학습 및 평가\n",
        "for train_idx, val_idx in kfold.split(X_train) :\n",
        "  # 각각의 fold를 만드는 과정 : 학습 데이터와 검증 데이터 분리\n",
        "  X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
        "  y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "  # 모델 불러오기\n",
        "  model = get_model()\n",
        "\n",
        "  # 모델 학습하기 → 총 4번(1200) 학습될 것\n",
        "  model.fit(X_train_fold, y_train_fold,\n",
        "            epochs = 300, validation_data = (X_val_fold, y_val_fold))\n",
        "\n",
        "  # 모델 평가하기\n",
        "  _, test_mae = model.evaluate(X_test, y_test) # _, : 첫 번째 평가 결과인 loss는 사용 안 한다는 의미\n",
        "  mae_list.append(test_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdUTszEDTiUa",
        "outputId": "01807ad7-742c-4665-9ab6-a3c80fd287ca"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "10/10 [==============================] - 1s 26ms/step - loss: 573.6636 - mae: 22.0799 - val_loss: 535.3454 - val_mae: 21.3773\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 546.2524 - mae: 21.3884 - val_loss: 510.8914 - val_mae: 20.7326\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 517.0464 - mae: 20.6248 - val_loss: 481.0990 - val_mae: 19.9306\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 479.1969 - mae: 19.6205 - val_loss: 443.0640 - val_mae: 18.8911\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 431.3797 - mae: 18.3398 - val_loss: 395.5465 - val_mae: 17.5743\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 373.0680 - mae: 16.7994 - val_loss: 337.6884 - val_mae: 16.0177\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 304.7454 - mae: 14.9022 - val_loss: 270.1310 - val_mae: 14.2033\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 229.0121 - mae: 12.7384 - val_loss: 199.9970 - val_mae: 11.9675\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 158.7559 - mae: 10.3062 - val_loss: 137.1258 - val_mae: 9.5514\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 104.4223 - mae: 8.1321 - val_loss: 93.3020 - val_mae: 7.5582\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 74.0539 - mae: 6.6588 - val_loss: 69.4587 - val_mae: 6.2441\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 59.3205 - mae: 5.8421 - val_loss: 56.4719 - val_mae: 5.4325\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 49.8476 - mae: 5.3287 - val_loss: 47.1358 - val_mae: 4.8431\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 41.6948 - mae: 4.8717 - val_loss: 40.8082 - val_mae: 4.4971\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 35.1335 - mae: 4.4605 - val_loss: 36.2781 - val_mae: 4.2607\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 31.0278 - mae: 4.1867 - val_loss: 33.0024 - val_mae: 4.0871\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 28.0003 - mae: 3.9554 - val_loss: 30.6245 - val_mae: 3.9360\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 25.6253 - mae: 3.7396 - val_loss: 28.9480 - val_mae: 3.8363\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 23.9749 - mae: 3.5894 - val_loss: 27.9016 - val_mae: 3.7878\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 22.6898 - mae: 3.4752 - val_loss: 27.0625 - val_mae: 3.7580\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 21.6585 - mae: 3.3780 - val_loss: 26.5030 - val_mae: 3.7356\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 20.8014 - mae: 3.2803 - val_loss: 26.0888 - val_mae: 3.7090\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 20.0742 - mae: 3.2064 - val_loss: 25.7118 - val_mae: 3.6891\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 19.4403 - mae: 3.1443 - val_loss: 25.2542 - val_mae: 3.6709\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 18.8096 - mae: 3.0935 - val_loss: 24.9480 - val_mae: 3.6465\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 18.2656 - mae: 3.0416 - val_loss: 24.6126 - val_mae: 3.6270\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 17.7796 - mae: 2.9859 - val_loss: 24.3148 - val_mae: 3.5920\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 17.3751 - mae: 2.9497 - val_loss: 24.0080 - val_mae: 3.5800\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 16.9305 - mae: 2.9110 - val_loss: 23.6439 - val_mae: 3.5603\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 16.4910 - mae: 2.8708 - val_loss: 23.3344 - val_mae: 3.5316\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 16.2015 - mae: 2.8436 - val_loss: 23.1592 - val_mae: 3.5180\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 15.8046 - mae: 2.8018 - val_loss: 22.7795 - val_mae: 3.4898\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 15.5596 - mae: 2.7790 - val_loss: 22.5690 - val_mae: 3.4808\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 15.3771 - mae: 2.7300 - val_loss: 22.5990 - val_mae: 3.4425\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 14.9139 - mae: 2.6836 - val_loss: 22.1394 - val_mae: 3.4484\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 14.7084 - mae: 2.6938 - val_loss: 21.7124 - val_mae: 3.4322\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 14.3156 - mae: 2.6593 - val_loss: 21.4812 - val_mae: 3.4045\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 14.0915 - mae: 2.6236 - val_loss: 21.3795 - val_mae: 3.3743\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 13.8803 - mae: 2.5895 - val_loss: 21.1786 - val_mae: 3.3543\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 13.6393 - mae: 2.5697 - val_loss: 20.8463 - val_mae: 3.3476\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 13.3704 - mae: 2.5514 - val_loss: 20.6923 - val_mae: 3.3237\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 13.2099 - mae: 2.5338 - val_loss: 20.4297 - val_mae: 3.3014\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 13.1878 - mae: 2.5384 - val_loss: 20.0834 - val_mae: 3.2887\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 13.0242 - mae: 2.4919 - val_loss: 20.2811 - val_mae: 3.2644\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.6084 - mae: 2.4613 - val_loss: 19.8784 - val_mae: 3.2508\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.4167 - mae: 2.4680 - val_loss: 19.7012 - val_mae: 3.2511\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.2661 - mae: 2.4545 - val_loss: 19.6308 - val_mae: 3.2471\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.1134 - mae: 2.4240 - val_loss: 19.6119 - val_mae: 3.2187\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 11.9837 - mae: 2.4076 - val_loss: 19.2747 - val_mae: 3.2063\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 11.7270 - mae: 2.4001 - val_loss: 19.2071 - val_mae: 3.2004\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.6946 - mae: 2.3835 - val_loss: 19.3406 - val_mae: 3.1951\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 11.5203 - mae: 2.3598 - val_loss: 19.1009 - val_mae: 3.1776\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.3194 - mae: 2.3529 - val_loss: 18.8049 - val_mae: 3.1585\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 11.1980 - mae: 2.3642 - val_loss: 18.6094 - val_mae: 3.1671\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 11.1118 - mae: 2.3590 - val_loss: 18.6000 - val_mae: 3.1603\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.9398 - mae: 2.3400 - val_loss: 18.4767 - val_mae: 3.1433\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.8263 - mae: 2.3179 - val_loss: 18.5344 - val_mae: 3.1369\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 10.7428 - mae: 2.2989 - val_loss: 18.4791 - val_mae: 3.1271\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 10.6046 - mae: 2.2854 - val_loss: 18.4139 - val_mae: 3.1292\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.5418 - mae: 2.2779 - val_loss: 18.3260 - val_mae: 3.1268\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.4258 - mae: 2.2776 - val_loss: 18.1594 - val_mae: 3.1181\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.3701 - mae: 2.2786 - val_loss: 17.9316 - val_mae: 3.0988\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.2363 - mae: 2.2581 - val_loss: 18.0103 - val_mae: 3.0952\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.1292 - mae: 2.2461 - val_loss: 17.8310 - val_mae: 3.0858\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.1085 - mae: 2.2405 - val_loss: 17.8064 - val_mae: 3.0803\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.9864 - mae: 2.2325 - val_loss: 17.7007 - val_mae: 3.0813\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.9886 - mae: 2.2350 - val_loss: 17.4851 - val_mae: 3.0566\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.8710 - mae: 2.2046 - val_loss: 17.6871 - val_mae: 3.0636\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.8313 - mae: 2.1997 - val_loss: 17.7253 - val_mae: 3.0691\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.7292 - mae: 2.2113 - val_loss: 17.4126 - val_mae: 3.0610\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.6094 - mae: 2.2019 - val_loss: 17.3140 - val_mae: 3.0522\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.5161 - mae: 2.1776 - val_loss: 17.3569 - val_mae: 3.0526\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 9.5000 - mae: 2.1684 - val_loss: 17.4351 - val_mae: 3.0511\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.3660 - mae: 2.1594 - val_loss: 17.1999 - val_mae: 3.0339\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.3643 - mae: 2.1637 - val_loss: 17.0419 - val_mae: 3.0330\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.2071 - mae: 2.1476 - val_loss: 17.1582 - val_mae: 3.0375\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.3037 - mae: 2.1646 - val_loss: 17.3905 - val_mae: 3.0546\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.1672 - mae: 2.1315 - val_loss: 17.1724 - val_mae: 3.0344\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 9.0973 - mae: 2.1266 - val_loss: 17.0333 - val_mae: 3.0316\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 9.0087 - mae: 2.1399 - val_loss: 16.9947 - val_mae: 3.0412\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 8.9490 - mae: 2.1338 - val_loss: 17.0012 - val_mae: 3.0378\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.8736 - mae: 2.1209 - val_loss: 16.9608 - val_mae: 3.0368\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 8.8266 - mae: 2.1172 - val_loss: 17.0015 - val_mae: 3.0364\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 8.7582 - mae: 2.1018 - val_loss: 16.7805 - val_mae: 3.0079\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 8.7401 - mae: 2.0847 - val_loss: 16.8577 - val_mae: 3.0039\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.6253 - mae: 2.0831 - val_loss: 16.7044 - val_mae: 3.0123\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.6603 - mae: 2.1036 - val_loss: 16.6380 - val_mae: 3.0194\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.5992 - mae: 2.0793 - val_loss: 16.7588 - val_mae: 3.0173\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.5288 - mae: 2.0798 - val_loss: 16.9732 - val_mae: 3.0454\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.4389 - mae: 2.0647 - val_loss: 16.7822 - val_mae: 3.0217\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.3603 - mae: 2.0489 - val_loss: 16.6216 - val_mae: 3.0241\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.3740 - mae: 2.0604 - val_loss: 16.5347 - val_mae: 3.0260\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.3264 - mae: 2.0607 - val_loss: 16.6995 - val_mae: 3.0198\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.3072 - mae: 2.0341 - val_loss: 16.6160 - val_mae: 2.9903\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.2557 - mae: 2.0328 - val_loss: 16.6374 - val_mae: 3.0271\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.1293 - mae: 2.0430 - val_loss: 16.5143 - val_mae: 3.0235\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.1137 - mae: 2.0294 - val_loss: 16.5563 - val_mae: 3.0111\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.0091 - mae: 2.0169 - val_loss: 16.2986 - val_mae: 2.9942\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.9955 - mae: 2.0076 - val_loss: 16.3185 - val_mae: 2.9794\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.8772 - mae: 1.9941 - val_loss: 16.2894 - val_mae: 2.9969\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.9239 - mae: 2.0102 - val_loss: 16.2424 - val_mae: 2.9941\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.8070 - mae: 1.9874 - val_loss: 16.2145 - val_mae: 2.9865\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.8437 - mae: 1.9797 - val_loss: 16.3265 - val_mae: 2.9910\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.7156 - mae: 1.9904 - val_loss: 16.2423 - val_mae: 3.0062\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.7125 - mae: 2.0045 - val_loss: 16.0881 - val_mae: 2.9877\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.6598 - mae: 1.9652 - val_loss: 16.1810 - val_mae: 2.9734\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7.7029 - mae: 1.9845 - val_loss: 16.1585 - val_mae: 3.0117\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.5231 - mae: 1.9675 - val_loss: 16.2205 - val_mae: 2.9930\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.5624 - mae: 1.9502 - val_loss: 16.2743 - val_mae: 2.9848\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.4787 - mae: 1.9519 - val_loss: 16.0884 - val_mae: 2.9992\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.4227 - mae: 1.9479 - val_loss: 15.9615 - val_mae: 2.9762\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.4260 - mae: 1.9369 - val_loss: 16.0059 - val_mae: 2.9734\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.3524 - mae: 1.9339 - val_loss: 16.0050 - val_mae: 2.9871\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.2970 - mae: 1.9335 - val_loss: 16.0485 - val_mae: 2.9849\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.2447 - mae: 1.9180 - val_loss: 15.9194 - val_mae: 2.9711\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.2159 - mae: 1.9157 - val_loss: 15.9273 - val_mae: 2.9789\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.1780 - mae: 1.9181 - val_loss: 15.9604 - val_mae: 2.9858\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 7.1551 - mae: 1.9056 - val_loss: 15.9019 - val_mae: 2.9552\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.1629 - mae: 1.9140 - val_loss: 15.8222 - val_mae: 2.9874\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.1630 - mae: 1.9122 - val_loss: 16.0194 - val_mae: 2.9748\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.0460 - mae: 1.8802 - val_loss: 15.7548 - val_mae: 2.9548\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6.9494 - mae: 1.8757 - val_loss: 15.8540 - val_mae: 2.9791\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 6.9719 - mae: 1.8901 - val_loss: 15.6609 - val_mae: 2.9694\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.9687 - mae: 1.8777 - val_loss: 15.7344 - val_mae: 2.9585\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.9411 - mae: 1.8810 - val_loss: 15.6339 - val_mae: 2.9691\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6.8565 - mae: 1.8643 - val_loss: 15.7575 - val_mae: 2.9486\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 6.7922 - mae: 1.8678 - val_loss: 15.6118 - val_mae: 2.9613\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 6.7368 - mae: 1.8622 - val_loss: 15.6204 - val_mae: 2.9627\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 6.7794 - mae: 1.8606 - val_loss: 15.6898 - val_mae: 2.9471\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.7326 - mae: 1.8747 - val_loss: 15.5437 - val_mae: 2.9593\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.6715 - mae: 1.8620 - val_loss: 15.5141 - val_mae: 2.9436\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.6938 - mae: 1.8418 - val_loss: 15.5587 - val_mae: 2.9239\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.6560 - mae: 1.8407 - val_loss: 15.4168 - val_mae: 2.9407\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6.5906 - mae: 1.8391 - val_loss: 15.6877 - val_mae: 2.9416\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 6.4938 - mae: 1.8247 - val_loss: 15.6111 - val_mae: 2.9563\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 6.5281 - mae: 1.8312 - val_loss: 15.5067 - val_mae: 2.9382\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6.3946 - mae: 1.8157 - val_loss: 15.5470 - val_mae: 2.9504\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.4144 - mae: 1.8213 - val_loss: 15.4028 - val_mae: 2.9278\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 6.3364 - mae: 1.7987 - val_loss: 15.4349 - val_mae: 2.9201\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6.3565 - mae: 1.8079 - val_loss: 15.3459 - val_mae: 2.9276\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 6.2904 - mae: 1.7914 - val_loss: 15.2957 - val_mae: 2.8971\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6.3244 - mae: 1.7853 - val_loss: 15.4470 - val_mae: 2.9100\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.2346 - mae: 1.8079 - val_loss: 15.3310 - val_mae: 2.9355\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6.2252 - mae: 1.8109 - val_loss: 15.2263 - val_mae: 2.9146\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.2209 - mae: 1.7761 - val_loss: 15.4624 - val_mae: 2.9049\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 6.1566 - mae: 1.7689 - val_loss: 15.2068 - val_mae: 2.8928\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 6.0540 - mae: 1.7706 - val_loss: 15.1418 - val_mae: 2.9063\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 6.0854 - mae: 1.7798 - val_loss: 15.2326 - val_mae: 2.9034\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 6.0463 - mae: 1.7596 - val_loss: 15.3548 - val_mae: 2.9081\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.0676 - mae: 1.7871 - val_loss: 15.0839 - val_mae: 2.9045\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.0127 - mae: 1.7580 - val_loss: 15.3200 - val_mae: 2.9035\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.9544 - mae: 1.7566 - val_loss: 15.2563 - val_mae: 2.9088\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.8895 - mae: 1.7348 - val_loss: 15.1025 - val_mae: 2.8751\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.8520 - mae: 1.7408 - val_loss: 15.1024 - val_mae: 2.8915\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.8126 - mae: 1.7362 - val_loss: 15.1782 - val_mae: 2.8853\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.8058 - mae: 1.7333 - val_loss: 15.1482 - val_mae: 2.8830\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.7761 - mae: 1.7385 - val_loss: 15.2684 - val_mae: 2.9032\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.7412 - mae: 1.7329 - val_loss: 15.0699 - val_mae: 2.8891\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.7609 - mae: 1.7257 - val_loss: 15.0408 - val_mae: 2.8700\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.7683 - mae: 1.7292 - val_loss: 15.1012 - val_mae: 2.8955\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.6704 - mae: 1.7222 - val_loss: 15.2155 - val_mae: 2.8862\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.7116 - mae: 1.7091 - val_loss: 15.2778 - val_mae: 2.8841\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.6271 - mae: 1.7042 - val_loss: 15.0318 - val_mae: 2.8735\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.6292 - mae: 1.7296 - val_loss: 14.9736 - val_mae: 2.8688\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.6073 - mae: 1.7002 - val_loss: 15.0188 - val_mae: 2.8605\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.5553 - mae: 1.6934 - val_loss: 15.0201 - val_mae: 2.8693\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.5469 - mae: 1.6953 - val_loss: 14.9074 - val_mae: 2.8557\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.4862 - mae: 1.6825 - val_loss: 15.0921 - val_mae: 2.8704\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.4619 - mae: 1.6796 - val_loss: 14.9545 - val_mae: 2.8577\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.4373 - mae: 1.6798 - val_loss: 14.8737 - val_mae: 2.8496\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.3742 - mae: 1.6695 - val_loss: 14.9917 - val_mae: 2.8629\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.4064 - mae: 1.6773 - val_loss: 14.9713 - val_mae: 2.8546\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.3275 - mae: 1.6604 - val_loss: 14.9404 - val_mae: 2.8467\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.3741 - mae: 1.6606 - val_loss: 14.8968 - val_mae: 2.8395\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.3768 - mae: 1.6597 - val_loss: 14.7464 - val_mae: 2.8375\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.3355 - mae: 1.6773 - val_loss: 14.9698 - val_mae: 2.8448\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.3135 - mae: 1.6752 - val_loss: 14.7669 - val_mae: 2.8362\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.2524 - mae: 1.6476 - val_loss: 14.9924 - val_mae: 2.8511\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.2275 - mae: 1.6495 - val_loss: 14.9110 - val_mae: 2.8465\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.1954 - mae: 1.6445 - val_loss: 14.7787 - val_mae: 2.8311\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.1737 - mae: 1.6474 - val_loss: 14.7963 - val_mae: 2.8360\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.1488 - mae: 1.6252 - val_loss: 14.8575 - val_mae: 2.8306\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.1275 - mae: 1.6172 - val_loss: 14.7899 - val_mae: 2.8337\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.1130 - mae: 1.6349 - val_loss: 14.7013 - val_mae: 2.8209\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.0642 - mae: 1.6177 - val_loss: 14.7217 - val_mae: 2.8183\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.1387 - mae: 1.6177 - val_loss: 14.9127 - val_mae: 2.8287\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.0726 - mae: 1.6168 - val_loss: 14.5887 - val_mae: 2.8184\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.0300 - mae: 1.6142 - val_loss: 14.7311 - val_mae: 2.8049\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.0757 - mae: 1.6108 - val_loss: 14.6632 - val_mae: 2.8119\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.0090 - mae: 1.5986 - val_loss: 14.9404 - val_mae: 2.8324\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9875 - mae: 1.6070 - val_loss: 14.6662 - val_mae: 2.8167\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 5.1006 - mae: 1.6166 - val_loss: 14.8265 - val_mae: 2.7961\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 4.9309 - mae: 1.5963 - val_loss: 14.6663 - val_mae: 2.8206\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.8944 - mae: 1.5910 - val_loss: 14.7396 - val_mae: 2.8029\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 4.8378 - mae: 1.5796 - val_loss: 14.6885 - val_mae: 2.8169\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.8682 - mae: 1.5904 - val_loss: 14.6197 - val_mae: 2.7997\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.8341 - mae: 1.5686 - val_loss: 14.6928 - val_mae: 2.8073\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.7733 - mae: 1.5663 - val_loss: 14.7660 - val_mae: 2.8147\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.8163 - mae: 1.5868 - val_loss: 14.6667 - val_mae: 2.8172\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.7883 - mae: 1.5786 - val_loss: 14.5558 - val_mae: 2.7898\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.7304 - mae: 1.5595 - val_loss: 14.6927 - val_mae: 2.7858\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.7287 - mae: 1.5581 - val_loss: 14.6385 - val_mae: 2.7956\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.7166 - mae: 1.5690 - val_loss: 14.6315 - val_mae: 2.8109\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.7034 - mae: 1.5616 - val_loss: 14.5049 - val_mae: 2.7845\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.6423 - mae: 1.5466 - val_loss: 14.5915 - val_mae: 2.8009\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.6447 - mae: 1.5494 - val_loss: 14.4560 - val_mae: 2.7848\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.6382 - mae: 1.5452 - val_loss: 14.3462 - val_mae: 2.7622\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.5946 - mae: 1.5346 - val_loss: 14.5026 - val_mae: 2.7716\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.6710 - mae: 1.5627 - val_loss: 14.4826 - val_mae: 2.7832\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.5805 - mae: 1.5319 - val_loss: 14.4569 - val_mae: 2.7608\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.5517 - mae: 1.5325 - val_loss: 14.3826 - val_mae: 2.7648\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.5774 - mae: 1.5516 - val_loss: 14.4015 - val_mae: 2.7677\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.5823 - mae: 1.5372 - val_loss: 14.3826 - val_mae: 2.7531\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.5651 - mae: 1.5448 - val_loss: 14.3248 - val_mae: 2.7785\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4878 - mae: 1.5200 - val_loss: 14.3242 - val_mae: 2.7604\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4884 - mae: 1.5138 - val_loss: 14.2927 - val_mae: 2.7422\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.5169 - mae: 1.5079 - val_loss: 14.3840 - val_mae: 2.7659\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4832 - mae: 1.5331 - val_loss: 14.2938 - val_mae: 2.7728\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.6831 - mae: 1.5433 - val_loss: 14.5245 - val_mae: 2.7437\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.6322 - mae: 1.5426 - val_loss: 14.2507 - val_mae: 2.7722\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.3913 - mae: 1.5186 - val_loss: 14.5397 - val_mae: 2.7771\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.4269 - mae: 1.5052 - val_loss: 14.4861 - val_mae: 2.7718\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.4895 - mae: 1.5364 - val_loss: 14.1640 - val_mae: 2.7453\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.2809 - mae: 1.4721 - val_loss: 14.2356 - val_mae: 2.7254\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3433 - mae: 1.4882 - val_loss: 14.2411 - val_mae: 2.7515\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.2812 - mae: 1.4869 - val_loss: 14.1624 - val_mae: 2.7435\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2572 - mae: 1.4866 - val_loss: 14.2678 - val_mae: 2.7447\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2534 - mae: 1.4904 - val_loss: 14.1413 - val_mae: 2.7321\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2013 - mae: 1.4827 - val_loss: 14.2186 - val_mae: 2.7419\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2159 - mae: 1.4762 - val_loss: 14.2486 - val_mae: 2.7412\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2355 - mae: 1.4719 - val_loss: 14.2863 - val_mae: 2.7446\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2064 - mae: 1.4714 - val_loss: 14.1717 - val_mae: 2.7390\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.2155 - mae: 1.4882 - val_loss: 14.1024 - val_mae: 2.7179\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1705 - mae: 1.4581 - val_loss: 14.1138 - val_mae: 2.7049\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1500 - mae: 1.4482 - val_loss: 14.0522 - val_mae: 2.7206\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.1613 - mae: 1.4711 - val_loss: 14.1909 - val_mae: 2.7241\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.0823 - mae: 1.4499 - val_loss: 13.9662 - val_mae: 2.7176\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.0905 - mae: 1.4543 - val_loss: 14.1760 - val_mae: 2.7250\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0507 - mae: 1.4394 - val_loss: 14.1065 - val_mae: 2.7067\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.1302 - mae: 1.4562 - val_loss: 14.1213 - val_mae: 2.7201\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.0483 - mae: 1.4509 - val_loss: 14.2730 - val_mae: 2.7158\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 4.0084 - mae: 1.4225 - val_loss: 14.0271 - val_mae: 2.6983\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.0154 - mae: 1.4350 - val_loss: 14.0306 - val_mae: 2.7029\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.9561 - mae: 1.4147 - val_loss: 14.0244 - val_mae: 2.6883\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.9669 - mae: 1.4200 - val_loss: 14.1037 - val_mae: 2.7253\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.0281 - mae: 1.4341 - val_loss: 14.1301 - val_mae: 2.6925\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.9488 - mae: 1.4169 - val_loss: 14.1157 - val_mae: 2.7199\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.9298 - mae: 1.4225 - val_loss: 14.0502 - val_mae: 2.6855\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.9296 - mae: 1.4228 - val_loss: 13.7743 - val_mae: 2.6734\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.8713 - mae: 1.4083 - val_loss: 13.9939 - val_mae: 2.6778\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.8895 - mae: 1.4087 - val_loss: 13.7386 - val_mae: 2.6618\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.8381 - mae: 1.3897 - val_loss: 13.8838 - val_mae: 2.6787\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.7834 - mae: 1.3905 - val_loss: 14.0354 - val_mae: 2.6937\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.7764 - mae: 1.3763 - val_loss: 13.9256 - val_mae: 2.6840\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 3.7816 - mae: 1.3855 - val_loss: 13.8028 - val_mae: 2.6665\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 3.7893 - mae: 1.3940 - val_loss: 13.7946 - val_mae: 2.6519\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 3.7371 - mae: 1.3825 - val_loss: 13.8762 - val_mae: 2.6765\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 3.7888 - mae: 1.3910 - val_loss: 13.8221 - val_mae: 2.6665\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 3.7362 - mae: 1.3864 - val_loss: 13.8515 - val_mae: 2.6645\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 3.7152 - mae: 1.3679 - val_loss: 13.7814 - val_mae: 2.6509\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 3.7070 - mae: 1.3813 - val_loss: 13.7054 - val_mae: 2.6395\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.6416 - mae: 1.3593 - val_loss: 13.8427 - val_mae: 2.6482\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.7013 - mae: 1.3736 - val_loss: 13.9317 - val_mae: 2.6894\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.6485 - mae: 1.3683 - val_loss: 13.6819 - val_mae: 2.6374\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 3.6352 - mae: 1.3690 - val_loss: 13.6084 - val_mae: 2.6343\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.6038 - mae: 1.3524 - val_loss: 14.0527 - val_mae: 2.6768\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.5804 - mae: 1.3545 - val_loss: 13.8890 - val_mae: 2.6703\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.5887 - mae: 1.3649 - val_loss: 13.8956 - val_mae: 2.6607\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 3.5878 - mae: 1.3435 - val_loss: 13.8420 - val_mae: 2.6452\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 3.5422 - mae: 1.3485 - val_loss: 13.8069 - val_mae: 2.6508\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.6122 - mae: 1.3574 - val_loss: 13.6747 - val_mae: 2.6177\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.5096 - mae: 1.3318 - val_loss: 13.8629 - val_mae: 2.6657\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.5631 - mae: 1.3592 - val_loss: 13.7403 - val_mae: 2.6319\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.5031 - mae: 1.3359 - val_loss: 13.6206 - val_mae: 2.6390\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.5611 - mae: 1.3295 - val_loss: 13.7940 - val_mae: 2.6334\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.5198 - mae: 1.3554 - val_loss: 13.7439 - val_mae: 2.6564\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.5169 - mae: 1.3267 - val_loss: 13.8885 - val_mae: 2.6416\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.4312 - mae: 1.3306 - val_loss: 13.7730 - val_mae: 2.6637\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.4900 - mae: 1.3341 - val_loss: 13.5986 - val_mae: 2.6153\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.3957 - mae: 1.3100 - val_loss: 13.7189 - val_mae: 2.6354\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.3793 - mae: 1.3134 - val_loss: 13.7347 - val_mae: 2.6358\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.3761 - mae: 1.3200 - val_loss: 13.6771 - val_mae: 2.6298\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.3897 - mae: 1.3192 - val_loss: 13.7616 - val_mae: 2.6404\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.3345 - mae: 1.3012 - val_loss: 13.7343 - val_mae: 2.6300\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.3623 - mae: 1.3045 - val_loss: 13.5961 - val_mae: 2.6295\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.3383 - mae: 1.3147 - val_loss: 13.8492 - val_mae: 2.6373\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.2986 - mae: 1.2916 - val_loss: 13.6034 - val_mae: 2.6344\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.2973 - mae: 1.3013 - val_loss: 13.5660 - val_mae: 2.6110\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3211 - mae: 1.2893 - val_loss: 13.6441 - val_mae: 2.6243\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.2810 - mae: 1.2973 - val_loss: 13.4454 - val_mae: 2.5936\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.2927 - mae: 1.2910 - val_loss: 13.4303 - val_mae: 2.6026\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.2633 - mae: 1.3078 - val_loss: 13.6749 - val_mae: 2.6411\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.2504 - mae: 1.2827 - val_loss: 13.7423 - val_mae: 2.6118\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.2445 - mae: 1.2919 - val_loss: 13.5699 - val_mae: 2.6185\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.1822 - mae: 1.2773 - val_loss: 13.4659 - val_mae: 2.5901\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.2248 - mae: 1.2870 - val_loss: 13.4563 - val_mae: 2.6016\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.2074 - mae: 1.2706 - val_loss: 13.4678 - val_mae: 2.5775\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.1907 - mae: 1.2944 - val_loss: 13.4698 - val_mae: 2.6156\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.1844 - mae: 1.2680 - val_loss: 13.4612 - val_mae: 2.5876\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.1334 - mae: 1.2720 - val_loss: 13.3674 - val_mae: 2.6013\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 9.7363 - mae: 2.1352\n",
            "Epoch 1/300\n",
            "10/10 [==============================] - 1s 22ms/step - loss: 548.7483 - mae: 21.6459 - val_loss: 589.1667 - val_mae: 22.2337\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 522.9865 - mae: 21.0756 - val_loss: 557.5908 - val_mae: 21.5599\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 494.0922 - mae: 20.4127 - val_loss: 519.1460 - val_mae: 20.7186\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 458.9592 - mae: 19.5625 - val_loss: 469.2238 - val_mae: 19.5818\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 411.1650 - mae: 18.3920 - val_loss: 407.2197 - val_mae: 18.0654\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 352.4448 - mae: 16.8381 - val_loss: 332.7587 - val_mae: 16.0630\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 285.3433 - mae: 14.8635 - val_loss: 250.6829 - val_mae: 13.6460\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 213.1304 - mae: 12.5405 - val_loss: 172.8409 - val_mae: 10.8464\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 145.2688 - mae: 9.9443 - val_loss: 111.9525 - val_mae: 8.1241\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 95.4772 - mae: 7.6460 - val_loss: 76.8038 - val_mae: 6.3230\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 67.2277 - mae: 6.2064 - val_loss: 61.3740 - val_mae: 5.6719\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 53.1888 - mae: 5.4318 - val_loss: 52.3105 - val_mae: 5.2834\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 42.7723 - mae: 4.8649 - val_loss: 45.3481 - val_mae: 4.9083\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 36.5265 - mae: 4.4436 - val_loss: 39.4236 - val_mae: 4.5360\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 31.2736 - mae: 4.0720 - val_loss: 35.9745 - val_mae: 4.2551\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 28.2184 - mae: 3.8279 - val_loss: 33.7297 - val_mae: 4.0659\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 26.0413 - mae: 3.6156 - val_loss: 32.5768 - val_mae: 3.9546\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 24.5690 - mae: 3.4904 - val_loss: 31.3875 - val_mae: 3.8780\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 23.3430 - mae: 3.4006 - val_loss: 30.4623 - val_mae: 3.8119\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 22.3951 - mae: 3.3327 - val_loss: 29.6738 - val_mae: 3.7491\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 21.6565 - mae: 3.2727 - val_loss: 29.1096 - val_mae: 3.6858\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 20.8626 - mae: 3.2037 - val_loss: 28.4702 - val_mae: 3.6283\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 20.2530 - mae: 3.1591 - val_loss: 27.8487 - val_mae: 3.5839\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 19.6348 - mae: 3.1111 - val_loss: 27.3686 - val_mae: 3.5515\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 19.0807 - mae: 3.0787 - val_loss: 26.8713 - val_mae: 3.5176\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 18.5310 - mae: 3.0423 - val_loss: 26.3558 - val_mae: 3.4895\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.0192 - mae: 3.0085 - val_loss: 25.9217 - val_mae: 3.4612\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 17.5389 - mae: 2.9561 - val_loss: 25.6655 - val_mae: 3.4141\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 17.1001 - mae: 2.9391 - val_loss: 25.0540 - val_mae: 3.3967\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 16.6299 - mae: 2.9219 - val_loss: 24.7028 - val_mae: 3.3776\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 16.2403 - mae: 2.8821 - val_loss: 24.3981 - val_mae: 3.3318\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 15.8449 - mae: 2.8347 - val_loss: 24.1320 - val_mae: 3.2972\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 15.5326 - mae: 2.7983 - val_loss: 23.6328 - val_mae: 3.2618\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 15.1979 - mae: 2.7663 - val_loss: 23.3521 - val_mae: 3.2293\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 14.9035 - mae: 2.7550 - val_loss: 23.0663 - val_mae: 3.2165\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 14.5378 - mae: 2.7398 - val_loss: 22.9365 - val_mae: 3.1876\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 14.2549 - mae: 2.6972 - val_loss: 22.6846 - val_mae: 3.1531\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 13.9702 - mae: 2.6658 - val_loss: 22.3740 - val_mae: 3.1174\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 13.6581 - mae: 2.6444 - val_loss: 22.0668 - val_mae: 3.0999\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 13.4421 - mae: 2.6342 - val_loss: 21.7818 - val_mae: 3.0651\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 13.1172 - mae: 2.5912 - val_loss: 21.6714 - val_mae: 3.0270\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.8542 - mae: 2.5885 - val_loss: 21.3645 - val_mae: 3.0044\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.6519 - mae: 2.5815 - val_loss: 21.2247 - val_mae: 2.9835\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.3684 - mae: 2.5397 - val_loss: 21.0689 - val_mae: 2.9630\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.2037 - mae: 2.5153 - val_loss: 20.9051 - val_mae: 2.9225\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.0750 - mae: 2.5113 - val_loss: 20.7760 - val_mae: 2.9001\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 11.8058 - mae: 2.4935 - val_loss: 20.6392 - val_mae: 2.8764\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 11.6696 - mae: 2.4717 - val_loss: 20.5134 - val_mae: 2.8523\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 11.5590 - mae: 2.4662 - val_loss: 20.3631 - val_mae: 2.8380\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.3537 - mae: 2.4562 - val_loss: 20.2379 - val_mae: 2.8145\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 11.1844 - mae: 2.4328 - val_loss: 20.1953 - val_mae: 2.7980\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 11.1315 - mae: 2.4286 - val_loss: 20.2127 - val_mae: 2.8002\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.9530 - mae: 2.4108 - val_loss: 20.1359 - val_mae: 2.7801\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 10.8042 - mae: 2.3875 - val_loss: 19.9795 - val_mae: 2.7568\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.6861 - mae: 2.3735 - val_loss: 19.7718 - val_mae: 2.7443\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 10.5879 - mae: 2.3643 - val_loss: 19.7109 - val_mae: 2.7328\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.4842 - mae: 2.3611 - val_loss: 19.7121 - val_mae: 2.7365\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 10.4263 - mae: 2.3662 - val_loss: 19.6784 - val_mae: 2.7233\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.2574 - mae: 2.3451 - val_loss: 19.6014 - val_mae: 2.7113\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 10.1598 - mae: 2.3078 - val_loss: 19.5712 - val_mae: 2.7002\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 10.0926 - mae: 2.3100 - val_loss: 19.4653 - val_mae: 2.6893\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 9.9828 - mae: 2.3086 - val_loss: 19.4395 - val_mae: 2.6859\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 9.8863 - mae: 2.3020 - val_loss: 19.4066 - val_mae: 2.6860\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 9.7891 - mae: 2.2937 - val_loss: 19.3921 - val_mae: 2.6830\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 9.7541 - mae: 2.2724 - val_loss: 19.3505 - val_mae: 2.6643\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 9.6807 - mae: 2.2630 - val_loss: 19.3412 - val_mae: 2.6592\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 9.5664 - mae: 2.2588 - val_loss: 19.3278 - val_mae: 2.6651\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 9.5007 - mae: 2.2478 - val_loss: 19.4259 - val_mae: 2.6631\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 9.5061 - mae: 2.2539 - val_loss: 19.3557 - val_mae: 2.6510\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 9.4590 - mae: 2.2474 - val_loss: 19.2853 - val_mae: 2.6446\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 9.3792 - mae: 2.2367 - val_loss: 19.5551 - val_mae: 2.6843\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 9.2983 - mae: 2.2368 - val_loss: 19.4190 - val_mae: 2.6568\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 9.1796 - mae: 2.2149 - val_loss: 19.4104 - val_mae: 2.6531\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 9.0999 - mae: 2.2037 - val_loss: 19.4087 - val_mae: 2.6627\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 9.0939 - mae: 2.2079 - val_loss: 19.3228 - val_mae: 2.6518\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 9.0079 - mae: 2.1872 - val_loss: 19.1405 - val_mae: 2.6218\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.9623 - mae: 2.1767 - val_loss: 19.1601 - val_mae: 2.6226\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.9312 - mae: 2.1825 - val_loss: 19.2760 - val_mae: 2.6376\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.8078 - mae: 2.1643 - val_loss: 19.2105 - val_mae: 2.6306\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.8012 - mae: 2.1503 - val_loss: 19.2278 - val_mae: 2.6271\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.7880 - mae: 2.1357 - val_loss: 19.1684 - val_mae: 2.6149\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.6807 - mae: 2.1371 - val_loss: 19.2308 - val_mae: 2.6333\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.6884 - mae: 2.1485 - val_loss: 19.3743 - val_mae: 2.6494\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.5877 - mae: 2.1350 - val_loss: 19.2623 - val_mae: 2.6280\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.6040 - mae: 2.1274 - val_loss: 19.3048 - val_mae: 2.6171\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.5184 - mae: 2.1210 - val_loss: 19.2421 - val_mae: 2.6280\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.4837 - mae: 2.1169 - val_loss: 19.3773 - val_mae: 2.6313\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.4493 - mae: 2.1078 - val_loss: 19.3494 - val_mae: 2.6244\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.3960 - mae: 2.0790 - val_loss: 19.3148 - val_mae: 2.6133\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.3508 - mae: 2.0874 - val_loss: 19.4219 - val_mae: 2.6440\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.3582 - mae: 2.1075 - val_loss: 19.2258 - val_mae: 2.6119\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.2753 - mae: 2.0652 - val_loss: 19.1467 - val_mae: 2.5882\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.3484 - mae: 2.0837 - val_loss: 19.2855 - val_mae: 2.6322\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.1782 - mae: 2.0690 - val_loss: 19.2889 - val_mae: 2.6200\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.0929 - mae: 2.0505 - val_loss: 19.2275 - val_mae: 2.6046\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.0845 - mae: 2.0442 - val_loss: 19.1870 - val_mae: 2.6134\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.0380 - mae: 2.0402 - val_loss: 19.2776 - val_mae: 2.6081\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.0189 - mae: 2.0492 - val_loss: 19.3405 - val_mae: 2.6187\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.0421 - mae: 2.0436 - val_loss: 19.4406 - val_mae: 2.6147\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.9727 - mae: 2.0365 - val_loss: 19.3310 - val_mae: 2.6351\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.9214 - mae: 2.0403 - val_loss: 19.2793 - val_mae: 2.6260\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.9534 - mae: 2.0214 - val_loss: 19.3110 - val_mae: 2.6020\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.9983 - mae: 2.0242 - val_loss: 19.0911 - val_mae: 2.6045\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.8662 - mae: 2.0093 - val_loss: 19.2300 - val_mae: 2.6045\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.7922 - mae: 2.0227 - val_loss: 19.3423 - val_mae: 2.6316\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.7301 - mae: 2.0095 - val_loss: 19.2155 - val_mae: 2.6119\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.6772 - mae: 1.9965 - val_loss: 19.3255 - val_mae: 2.6152\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.7589 - mae: 1.9871 - val_loss: 19.2727 - val_mae: 2.5973\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.6509 - mae: 1.9845 - val_loss: 19.2288 - val_mae: 2.6087\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.6123 - mae: 1.9871 - val_loss: 19.3573 - val_mae: 2.6194\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.5938 - mae: 1.9820 - val_loss: 19.3161 - val_mae: 2.6007\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.5095 - mae: 1.9487 - val_loss: 19.2517 - val_mae: 2.5974\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.4805 - mae: 1.9570 - val_loss: 19.2017 - val_mae: 2.6016\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.4498 - mae: 1.9664 - val_loss: 19.3367 - val_mae: 2.6063\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.4536 - mae: 1.9719 - val_loss: 19.2169 - val_mae: 2.6023\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.3691 - mae: 1.9450 - val_loss: 19.2454 - val_mae: 2.5821\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.3683 - mae: 1.9310 - val_loss: 19.2249 - val_mae: 2.5969\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.3299 - mae: 1.9467 - val_loss: 19.1872 - val_mae: 2.5988\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.3149 - mae: 1.9391 - val_loss: 19.3019 - val_mae: 2.5967\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.2345 - mae: 1.9304 - val_loss: 19.1966 - val_mae: 2.6058\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.2535 - mae: 1.9278 - val_loss: 19.2506 - val_mae: 2.5959\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.2637 - mae: 1.9313 - val_loss: 19.3575 - val_mae: 2.6089\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.1637 - mae: 1.9186 - val_loss: 19.1824 - val_mae: 2.5892\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.1706 - mae: 1.9047 - val_loss: 19.2264 - val_mae: 2.6030\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.0896 - mae: 1.9162 - val_loss: 19.4331 - val_mae: 2.6253\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.1142 - mae: 1.9198 - val_loss: 19.3789 - val_mae: 2.6205\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.1019 - mae: 1.9038 - val_loss: 19.2214 - val_mae: 2.6040\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.1449 - mae: 1.9114 - val_loss: 19.5492 - val_mae: 2.6215\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.0174 - mae: 1.8917 - val_loss: 19.3540 - val_mae: 2.6005\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.9914 - mae: 1.8879 - val_loss: 19.2531 - val_mae: 2.6102\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.9635 - mae: 1.8880 - val_loss: 19.2137 - val_mae: 2.6090\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.8951 - mae: 1.8781 - val_loss: 19.3395 - val_mae: 2.6059\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.8886 - mae: 1.8837 - val_loss: 19.5806 - val_mae: 2.6311\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.8314 - mae: 1.8784 - val_loss: 19.5251 - val_mae: 2.6213\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.8326 - mae: 1.8664 - val_loss: 19.4636 - val_mae: 2.6062\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.8204 - mae: 1.8671 - val_loss: 19.4387 - val_mae: 2.6180\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.8274 - mae: 1.8660 - val_loss: 19.4802 - val_mae: 2.6158\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.7992 - mae: 1.8635 - val_loss: 19.3156 - val_mae: 2.6027\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.7126 - mae: 1.8519 - val_loss: 19.4978 - val_mae: 2.6124\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.6913 - mae: 1.8509 - val_loss: 19.4409 - val_mae: 2.6105\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.7146 - mae: 1.8474 - val_loss: 19.4776 - val_mae: 2.6187\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.6787 - mae: 1.8559 - val_loss: 19.3582 - val_mae: 2.6130\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.6168 - mae: 1.8397 - val_loss: 19.5548 - val_mae: 2.6202\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.5756 - mae: 1.8437 - val_loss: 19.4210 - val_mae: 2.6105\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.5673 - mae: 1.8389 - val_loss: 19.4962 - val_mae: 2.6208\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.5590 - mae: 1.8282 - val_loss: 19.3699 - val_mae: 2.6107\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.5412 - mae: 1.8282 - val_loss: 19.2541 - val_mae: 2.6096\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.4671 - mae: 1.8223 - val_loss: 19.4279 - val_mae: 2.6152\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.4528 - mae: 1.8273 - val_loss: 19.5355 - val_mae: 2.6165\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.4399 - mae: 1.8105 - val_loss: 19.4999 - val_mae: 2.6000\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.4149 - mae: 1.8129 - val_loss: 19.5292 - val_mae: 2.6135\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.4418 - mae: 1.8225 - val_loss: 19.4700 - val_mae: 2.6108\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.3880 - mae: 1.8071 - val_loss: 19.4562 - val_mae: 2.6048\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.4110 - mae: 1.8217 - val_loss: 19.8130 - val_mae: 2.6415\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.4527 - mae: 1.8214 - val_loss: 19.5314 - val_mae: 2.6020\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.3220 - mae: 1.7965 - val_loss: 19.5608 - val_mae: 2.6178\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.2835 - mae: 1.8013 - val_loss: 19.5914 - val_mae: 2.6157\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.2582 - mae: 1.7894 - val_loss: 19.6818 - val_mae: 2.6007\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.1997 - mae: 1.7723 - val_loss: 19.4396 - val_mae: 2.6036\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.2488 - mae: 1.7722 - val_loss: 19.4826 - val_mae: 2.5943\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.2650 - mae: 1.7989 - val_loss: 19.6813 - val_mae: 2.6220\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.2252 - mae: 1.7830 - val_loss: 19.5353 - val_mae: 2.5957\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.1214 - mae: 1.7663 - val_loss: 19.5758 - val_mae: 2.5985\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.1294 - mae: 1.7690 - val_loss: 19.5475 - val_mae: 2.6174\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.1339 - mae: 1.7754 - val_loss: 19.7847 - val_mae: 2.6178\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.0956 - mae: 1.7724 - val_loss: 19.7484 - val_mae: 2.6216\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.0915 - mae: 1.7615 - val_loss: 19.5042 - val_mae: 2.5917\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.0111 - mae: 1.7534 - val_loss: 19.6827 - val_mae: 2.6059\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.0044 - mae: 1.7574 - val_loss: 20.1227 - val_mae: 2.6481\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.2096 - mae: 1.7867 - val_loss: 19.8403 - val_mae: 2.6211\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.9629 - mae: 1.7378 - val_loss: 19.6696 - val_mae: 2.6077\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.9182 - mae: 1.7506 - val_loss: 19.9440 - val_mae: 2.6481\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.9317 - mae: 1.7486 - val_loss: 19.8434 - val_mae: 2.6223\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.9567 - mae: 1.7431 - val_loss: 19.6290 - val_mae: 2.6043\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5.9030 - mae: 1.7369 - val_loss: 19.7928 - val_mae: 2.6091\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.8812 - mae: 1.7468 - val_loss: 19.8148 - val_mae: 2.6033\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 5.8542 - mae: 1.7318 - val_loss: 19.8117 - val_mae: 2.6018\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 5.8075 - mae: 1.7243 - val_loss: 19.8752 - val_mae: 2.6135\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5.8216 - mae: 1.7338 - val_loss: 19.7166 - val_mae: 2.6104\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 5.7635 - mae: 1.7077 - val_loss: 19.7373 - val_mae: 2.6110\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5.7744 - mae: 1.7116 - val_loss: 19.9233 - val_mae: 2.6064\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5.8421 - mae: 1.7286 - val_loss: 19.8096 - val_mae: 2.6236\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 5.8489 - mae: 1.7317 - val_loss: 19.8419 - val_mae: 2.6085\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 5.8075 - mae: 1.7238 - val_loss: 20.1545 - val_mae: 2.6649\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 5.7088 - mae: 1.7088 - val_loss: 19.8489 - val_mae: 2.6118\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 5.6825 - mae: 1.6969 - val_loss: 19.9829 - val_mae: 2.6094\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 5.6585 - mae: 1.6922 - val_loss: 19.7997 - val_mae: 2.5894\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 5.6408 - mae: 1.6986 - val_loss: 19.9000 - val_mae: 2.6146\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 5.6654 - mae: 1.6915 - val_loss: 19.7374 - val_mae: 2.5958\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 5.6318 - mae: 1.6762 - val_loss: 19.8035 - val_mae: 2.5960\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.5890 - mae: 1.7004 - val_loss: 20.1630 - val_mae: 2.6465\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.6499 - mae: 1.7252 - val_loss: 20.4948 - val_mae: 2.6549\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.5404 - mae: 1.6857 - val_loss: 19.9567 - val_mae: 2.6041\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 5.5145 - mae: 1.6713 - val_loss: 19.8755 - val_mae: 2.6062\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 5.5325 - mae: 1.6865 - val_loss: 19.9279 - val_mae: 2.6141\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 5.4425 - mae: 1.6575 - val_loss: 19.6960 - val_mae: 2.5902\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 5.5342 - mae: 1.6873 - val_loss: 19.7969 - val_mae: 2.6211\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 5.4219 - mae: 1.6724 - val_loss: 20.1478 - val_mae: 2.6098\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 5.4245 - mae: 1.6604 - val_loss: 19.8613 - val_mae: 2.5874\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 5.4612 - mae: 1.6654 - val_loss: 19.8291 - val_mae: 2.5867\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 5.4640 - mae: 1.6650 - val_loss: 19.8987 - val_mae: 2.6180\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 5.3972 - mae: 1.6454 - val_loss: 19.6326 - val_mae: 2.5769\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5.3185 - mae: 1.6421 - val_loss: 19.6562 - val_mae: 2.5886\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 5.3149 - mae: 1.6499 - val_loss: 20.0110 - val_mae: 2.6079\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5.2276 - mae: 1.6341 - val_loss: 19.9044 - val_mae: 2.6034\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 5.2783 - mae: 1.6421 - val_loss: 20.1647 - val_mae: 2.6167\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.3012 - mae: 1.6242 - val_loss: 19.6492 - val_mae: 2.5660\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 5.1596 - mae: 1.6276 - val_loss: 19.6926 - val_mae: 2.5921\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5.2484 - mae: 1.6385 - val_loss: 19.9461 - val_mae: 2.5967\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 5.1204 - mae: 1.6079 - val_loss: 19.9635 - val_mae: 2.6018\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 5.1240 - mae: 1.6090 - val_loss: 19.5590 - val_mae: 2.5783\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.1274 - mae: 1.6171 - val_loss: 19.7845 - val_mae: 2.6030\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.2757 - mae: 1.6239 - val_loss: 19.6894 - val_mae: 2.5781\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.0399 - mae: 1.6119 - val_loss: 19.7566 - val_mae: 2.6186\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.1349 - mae: 1.6127 - val_loss: 19.9643 - val_mae: 2.5904\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.9580 - mae: 1.6072 - val_loss: 20.3012 - val_mae: 2.6571\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.0154 - mae: 1.6119 - val_loss: 19.9066 - val_mae: 2.5942\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.9679 - mae: 1.5894 - val_loss: 19.7301 - val_mae: 2.5881\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9053 - mae: 1.5863 - val_loss: 19.5957 - val_mae: 2.5970\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9535 - mae: 1.5980 - val_loss: 19.5871 - val_mae: 2.5803\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.9066 - mae: 1.5723 - val_loss: 19.8639 - val_mae: 2.6117\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9338 - mae: 1.6013 - val_loss: 19.8584 - val_mae: 2.6009\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.7669 - mae: 1.5523 - val_loss: 19.5097 - val_mae: 2.5866\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.8085 - mae: 1.5787 - val_loss: 19.8158 - val_mae: 2.6129\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.7554 - mae: 1.5536 - val_loss: 19.7578 - val_mae: 2.5919\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.7613 - mae: 1.5639 - val_loss: 19.8030 - val_mae: 2.6069\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.6780 - mae: 1.5454 - val_loss: 19.6908 - val_mae: 2.5881\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.7081 - mae: 1.5365 - val_loss: 19.5851 - val_mae: 2.5906\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.7002 - mae: 1.5507 - val_loss: 19.6950 - val_mae: 2.6072\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.6774 - mae: 1.5540 - val_loss: 19.7407 - val_mae: 2.6083\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.6701 - mae: 1.5497 - val_loss: 20.1404 - val_mae: 2.6206\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.6221 - mae: 1.5386 - val_loss: 19.6135 - val_mae: 2.6115\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.5372 - mae: 1.5221 - val_loss: 19.6110 - val_mae: 2.5941\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.6475 - mae: 1.5451 - val_loss: 19.7931 - val_mae: 2.6245\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.4706 - mae: 1.5065 - val_loss: 19.6968 - val_mae: 2.5998\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 4.5550 - mae: 1.5215 - val_loss: 19.6161 - val_mae: 2.6014\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.5638 - mae: 1.5324 - val_loss: 19.9230 - val_mae: 2.6566\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 4.4788 - mae: 1.5225 - val_loss: 20.1865 - val_mae: 2.6284\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.5221 - mae: 1.5149 - val_loss: 19.6436 - val_mae: 2.6277\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 4.5360 - mae: 1.5107 - val_loss: 19.5753 - val_mae: 2.5991\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 4.4664 - mae: 1.5142 - val_loss: 19.6355 - val_mae: 2.6173\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.4632 - mae: 1.5061 - val_loss: 19.7508 - val_mae: 2.6111\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.3760 - mae: 1.4994 - val_loss: 19.7844 - val_mae: 2.6311\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.4372 - mae: 1.4963 - val_loss: 19.5600 - val_mae: 2.6011\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.3262 - mae: 1.4916 - val_loss: 19.9829 - val_mae: 2.6465\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.3115 - mae: 1.4958 - val_loss: 20.0224 - val_mae: 2.6345\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 4.2642 - mae: 1.4803 - val_loss: 19.8029 - val_mae: 2.6217\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.2750 - mae: 1.4738 - val_loss: 19.7677 - val_mae: 2.6299\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.2280 - mae: 1.4677 - val_loss: 19.7212 - val_mae: 2.6236\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.3713 - mae: 1.5075 - val_loss: 19.6256 - val_mae: 2.6196\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3044 - mae: 1.4737 - val_loss: 19.4850 - val_mae: 2.6130\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.2651 - mae: 1.4906 - val_loss: 19.8093 - val_mae: 2.6397\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.1052 - mae: 1.4477 - val_loss: 19.4196 - val_mae: 2.6012\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.1824 - mae: 1.4508 - val_loss: 19.4011 - val_mae: 2.6109\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.2074 - mae: 1.4774 - val_loss: 20.1751 - val_mae: 2.6476\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.1515 - mae: 1.4426 - val_loss: 19.9282 - val_mae: 2.6211\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.0759 - mae: 1.4515 - val_loss: 20.1259 - val_mae: 2.6635\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 4.0356 - mae: 1.4340 - val_loss: 19.7128 - val_mae: 2.6238\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 4.0659 - mae: 1.4288 - val_loss: 19.6151 - val_mae: 2.6231\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 4.0667 - mae: 1.4396 - val_loss: 19.8479 - val_mae: 2.6419\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.0493 - mae: 1.4333 - val_loss: 19.5669 - val_mae: 2.6241\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 3.9493 - mae: 1.4131 - val_loss: 19.6156 - val_mae: 2.6200\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 4.0633 - mae: 1.4538 - val_loss: 19.8228 - val_mae: 2.6329\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4.0282 - mae: 1.4287 - val_loss: 19.5089 - val_mae: 2.6175\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.8987 - mae: 1.4103 - val_loss: 19.6822 - val_mae: 2.6394\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 3.9241 - mae: 1.4115 - val_loss: 19.8324 - val_mae: 2.6412\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.9403 - mae: 1.4071 - val_loss: 19.3579 - val_mae: 2.6019\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.8508 - mae: 1.3957 - val_loss: 20.0061 - val_mae: 2.6515\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 3.8584 - mae: 1.4096 - val_loss: 20.0197 - val_mae: 2.6345\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.7823 - mae: 1.3747 - val_loss: 19.5795 - val_mae: 2.6227\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.7748 - mae: 1.3790 - val_loss: 19.5292 - val_mae: 2.6235\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.7599 - mae: 1.3855 - val_loss: 19.7551 - val_mae: 2.6374\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.7704 - mae: 1.3788 - val_loss: 19.5747 - val_mae: 2.6214\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.6971 - mae: 1.3637 - val_loss: 19.5851 - val_mae: 2.6312\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.7323 - mae: 1.3703 - val_loss: 19.6063 - val_mae: 2.6414\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.7703 - mae: 1.3682 - val_loss: 19.5868 - val_mae: 2.6225\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.7787 - mae: 1.3909 - val_loss: 19.8146 - val_mae: 2.6641\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.7349 - mae: 1.3879 - val_loss: 19.7022 - val_mae: 2.6589\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.6332 - mae: 1.3619 - val_loss: 19.9709 - val_mae: 2.6549\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.6754 - mae: 1.3748 - val_loss: 19.6491 - val_mae: 2.6430\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.5854 - mae: 1.3427 - val_loss: 19.7390 - val_mae: 2.6398\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.6102 - mae: 1.3570 - val_loss: 19.9418 - val_mae: 2.6513\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.5276 - mae: 1.3316 - val_loss: 19.3890 - val_mae: 2.6063\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.6857 - mae: 1.3720 - val_loss: 19.4510 - val_mae: 2.6422\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.5881 - mae: 1.3582 - val_loss: 19.5319 - val_mae: 2.6351\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.5119 - mae: 1.3202 - val_loss: 19.7501 - val_mae: 2.6461\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.5751 - mae: 1.3562 - val_loss: 19.7520 - val_mae: 2.6611\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.5355 - mae: 1.3259 - val_loss: 19.3557 - val_mae: 2.6243\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.4538 - mae: 1.3210 - val_loss: 19.2324 - val_mae: 2.6359\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.4586 - mae: 1.3273 - val_loss: 19.5266 - val_mae: 2.6312\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.5078 - mae: 1.3381 - val_loss: 19.8697 - val_mae: 2.6612\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.4299 - mae: 1.3033 - val_loss: 19.0184 - val_mae: 2.6095\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.4052 - mae: 1.3025 - val_loss: 19.2652 - val_mae: 2.6312\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.4381 - mae: 1.3303 - val_loss: 19.4898 - val_mae: 2.6476\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 3.4443 - mae: 1.3188 - val_loss: 19.4848 - val_mae: 2.6387\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.3392 - mae: 1.2906 - val_loss: 19.6704 - val_mae: 2.6564\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.2932 - mae: 1.2937 - val_loss: 19.3627 - val_mae: 2.6480\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.3162 - mae: 1.2882 - val_loss: 19.2304 - val_mae: 2.6367\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.4300 - mae: 1.3301 - val_loss: 19.5822 - val_mae: 2.6584\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.3777 - mae: 1.3202 - val_loss: 19.4740 - val_mae: 2.6459\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 7.7441 - mae: 2.0627\n",
            "Epoch 1/300\n",
            "10/10 [==============================] - 2s 43ms/step - loss: 545.7386 - mae: 21.5492 - val_loss: 587.5784 - val_mae: 22.3721\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 517.3281 - mae: 20.8870 - val_loss: 556.3415 - val_mae: 21.6496\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 485.2399 - mae: 20.0762 - val_loss: 518.3544 - val_mae: 20.7583\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 445.8210 - mae: 19.0973 - val_loss: 471.9478 - val_mae: 19.6657\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 400.4032 - mae: 17.8809 - val_loss: 416.1657 - val_mae: 18.3055\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 345.3299 - mae: 16.3969 - val_loss: 354.5194 - val_mae: 16.6571\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 286.1644 - mae: 14.6423 - val_loss: 287.2919 - val_mae: 14.6442\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 224.0941 - mae: 12.6656 - val_loss: 221.3733 - val_mae: 12.3424\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 166.7203 - mae: 10.6391 - val_loss: 164.1398 - val_mae: 10.0227\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 119.6450 - mae: 8.7116 - val_loss: 123.5260 - val_mae: 8.5578\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 91.2455 - mae: 7.4846 - val_loss: 97.5287 - val_mae: 7.6275\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 72.4223 - mae: 6.6317 - val_loss: 80.7467 - val_mae: 6.8638\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 60.4514 - mae: 6.0664 - val_loss: 66.6631 - val_mae: 6.2031\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 50.5565 - mae: 5.5370 - val_loss: 55.4524 - val_mae: 5.6446\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 42.7164 - mae: 5.0361 - val_loss: 46.9060 - val_mae: 5.1872\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 37.1255 - mae: 4.6154 - val_loss: 40.1168 - val_mae: 4.7435\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 32.9140 - mae: 4.3043 - val_loss: 35.3095 - val_mae: 4.3724\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 30.0829 - mae: 4.0638 - val_loss: 32.0171 - val_mae: 4.0638\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 28.0802 - mae: 3.8908 - val_loss: 29.4114 - val_mae: 3.8152\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 26.4012 - mae: 3.7334 - val_loss: 27.6122 - val_mae: 3.6539\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 25.3365 - mae: 3.6450 - val_loss: 26.1375 - val_mae: 3.5375\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 24.3515 - mae: 3.5655 - val_loss: 24.8465 - val_mae: 3.4322\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 23.4852 - mae: 3.4909 - val_loss: 23.7333 - val_mae: 3.3352\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 22.7144 - mae: 3.4242 - val_loss: 22.7654 - val_mae: 3.2385\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 22.0704 - mae: 3.3530 - val_loss: 21.9846 - val_mae: 3.1543\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 21.4688 - mae: 3.2949 - val_loss: 21.2475 - val_mae: 3.1145\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 20.9101 - mae: 3.2502 - val_loss: 20.6244 - val_mae: 3.0543\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 20.3590 - mae: 3.1977 - val_loss: 20.0565 - val_mae: 2.9989\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 19.8598 - mae: 3.1507 - val_loss: 19.5303 - val_mae: 2.9597\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 19.4513 - mae: 3.1110 - val_loss: 19.0187 - val_mae: 2.9274\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 19.0060 - mae: 3.0627 - val_loss: 18.7795 - val_mae: 2.8920\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.6202 - mae: 3.0379 - val_loss: 18.2988 - val_mae: 2.9175\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 18.2313 - mae: 3.0195 - val_loss: 17.9269 - val_mae: 2.9019\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 17.8053 - mae: 2.9712 - val_loss: 17.5852 - val_mae: 2.8590\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 17.3954 - mae: 2.9247 - val_loss: 17.2848 - val_mae: 2.8382\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 17.1090 - mae: 2.8949 - val_loss: 16.9313 - val_mae: 2.8271\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 16.7292 - mae: 2.8577 - val_loss: 16.7722 - val_mae: 2.8121\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 16.4855 - mae: 2.8332 - val_loss: 16.6349 - val_mae: 2.8083\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 16.2043 - mae: 2.8154 - val_loss: 16.3680 - val_mae: 2.8328\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 15.9074 - mae: 2.7912 - val_loss: 16.1513 - val_mae: 2.8164\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 15.6395 - mae: 2.7580 - val_loss: 15.9012 - val_mae: 2.7931\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 15.4814 - mae: 2.7342 - val_loss: 15.7847 - val_mae: 2.7663\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 15.1636 - mae: 2.7106 - val_loss: 15.5471 - val_mae: 2.7860\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 14.9436 - mae: 2.6945 - val_loss: 15.4036 - val_mae: 2.7938\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 14.8051 - mae: 2.6801 - val_loss: 15.2332 - val_mae: 2.7785\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 14.5281 - mae: 2.6536 - val_loss: 15.0308 - val_mae: 2.7559\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 14.3142 - mae: 2.6393 - val_loss: 14.9092 - val_mae: 2.7662\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 14.1460 - mae: 2.6176 - val_loss: 14.8203 - val_mae: 2.7483\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 13.9429 - mae: 2.5960 - val_loss: 14.7479 - val_mae: 2.7545\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 13.7587 - mae: 2.5909 - val_loss: 14.6935 - val_mae: 2.7767\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 13.6274 - mae: 2.5781 - val_loss: 14.5246 - val_mae: 2.7659\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 13.4644 - mae: 2.5560 - val_loss: 14.3938 - val_mae: 2.7376\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 13.3046 - mae: 2.5379 - val_loss: 14.3574 - val_mae: 2.7387\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 13.1677 - mae: 2.5278 - val_loss: 14.2136 - val_mae: 2.7362\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 13.0494 - mae: 2.5196 - val_loss: 14.1497 - val_mae: 2.7358\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 13.0241 - mae: 2.5138 - val_loss: 14.1287 - val_mae: 2.7198\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.8673 - mae: 2.5012 - val_loss: 14.0438 - val_mae: 2.7439\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 12.6950 - mae: 2.4917 - val_loss: 13.9740 - val_mae: 2.7406\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 12.5665 - mae: 2.4712 - val_loss: 13.9703 - val_mae: 2.7360\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 12.4389 - mae: 2.4471 - val_loss: 13.9010 - val_mae: 2.7298\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.3668 - mae: 2.4397 - val_loss: 13.7955 - val_mae: 2.7334\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 12.2880 - mae: 2.4319 - val_loss: 13.7341 - val_mae: 2.7278\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 12.1453 - mae: 2.4316 - val_loss: 13.6145 - val_mae: 2.7191\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.0538 - mae: 2.4218 - val_loss: 13.5988 - val_mae: 2.7203\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 11.9849 - mae: 2.4164 - val_loss: 13.5035 - val_mae: 2.7084\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 11.8463 - mae: 2.4037 - val_loss: 13.5411 - val_mae: 2.7285\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.8775 - mae: 2.3900 - val_loss: 13.5326 - val_mae: 2.7189\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 11.6723 - mae: 2.3738 - val_loss: 13.4580 - val_mae: 2.7226\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11.6408 - mae: 2.3838 - val_loss: 13.3871 - val_mae: 2.7276\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 11.5469 - mae: 2.3672 - val_loss: 13.3637 - val_mae: 2.7153\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 11.4695 - mae: 2.3502 - val_loss: 13.3678 - val_mae: 2.7082\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11.3988 - mae: 2.3489 - val_loss: 13.1975 - val_mae: 2.6883\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.3424 - mae: 2.3569 - val_loss: 13.1790 - val_mae: 2.7143\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 11.1360 - mae: 2.3335 - val_loss: 13.1917 - val_mae: 2.7108\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 11.0900 - mae: 2.3166 - val_loss: 13.1005 - val_mae: 2.7027\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 11.0292 - mae: 2.3233 - val_loss: 13.1161 - val_mae: 2.7038\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 11.0015 - mae: 2.3175 - val_loss: 13.0245 - val_mae: 2.6886\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 10.8637 - mae: 2.2976 - val_loss: 12.9975 - val_mae: 2.6909\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 10.8865 - mae: 2.3110 - val_loss: 13.0388 - val_mae: 2.7007\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 10.7997 - mae: 2.2902 - val_loss: 12.8842 - val_mae: 2.6772\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 10.7314 - mae: 2.2780 - val_loss: 12.8263 - val_mae: 2.6724\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 10.5918 - mae: 2.2710 - val_loss: 12.8272 - val_mae: 2.6807\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 10.5841 - mae: 2.2748 - val_loss: 12.7565 - val_mae: 2.6749\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 10.4466 - mae: 2.2548 - val_loss: 12.7712 - val_mae: 2.6738\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 10.4094 - mae: 2.2440 - val_loss: 12.8054 - val_mae: 2.6790\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 10.3517 - mae: 2.2484 - val_loss: 12.7803 - val_mae: 2.6784\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 10.2430 - mae: 2.2381 - val_loss: 12.6697 - val_mae: 2.6676\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 10.2647 - mae: 2.2321 - val_loss: 12.5957 - val_mae: 2.6587\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 10.3600 - mae: 2.2350 - val_loss: 12.6532 - val_mae: 2.6580\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.9814 - mae: 2.2126 - val_loss: 12.4682 - val_mae: 2.6450\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 10.0741 - mae: 2.2507 - val_loss: 12.4075 - val_mae: 2.6406\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 9.9924 - mae: 2.2038 - val_loss: 12.4929 - val_mae: 2.6484\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 9.8990 - mae: 2.1831 - val_loss: 12.4701 - val_mae: 2.6544\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 9.8452 - mae: 2.1882 - val_loss: 12.4091 - val_mae: 2.6496\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 9.8095 - mae: 2.2027 - val_loss: 12.3945 - val_mae: 2.6355\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 9.7220 - mae: 2.1778 - val_loss: 12.4386 - val_mae: 2.6453\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 9.6513 - mae: 2.1614 - val_loss: 12.3357 - val_mae: 2.6339\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 9.6306 - mae: 2.1623 - val_loss: 12.3138 - val_mae: 2.6377\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9.5552 - mae: 2.1561 - val_loss: 12.3401 - val_mae: 2.6292\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.4719 - mae: 2.1501 - val_loss: 12.2655 - val_mae: 2.6193\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.3909 - mae: 2.1337 - val_loss: 12.2352 - val_mae: 2.6201\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 9.3848 - mae: 2.1288 - val_loss: 12.2276 - val_mae: 2.6278\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.3171 - mae: 2.1314 - val_loss: 12.2710 - val_mae: 2.6278\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 9.2643 - mae: 2.1365 - val_loss: 12.2506 - val_mae: 2.6200\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 9.3222 - mae: 2.1224 - val_loss: 12.2421 - val_mae: 2.6201\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 9.3280 - mae: 2.1610 - val_loss: 12.2042 - val_mae: 2.6216\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.2218 - mae: 2.1254 - val_loss: 12.1982 - val_mae: 2.6228\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.0268 - mae: 2.0921 - val_loss: 12.1241 - val_mae: 2.6114\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.0442 - mae: 2.1148 - val_loss: 12.0908 - val_mae: 2.6029\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 8.9485 - mae: 2.0976 - val_loss: 12.0327 - val_mae: 2.5944\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.8723 - mae: 2.0815 - val_loss: 11.9389 - val_mae: 2.5865\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 8.9575 - mae: 2.0913 - val_loss: 11.9733 - val_mae: 2.5824\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.8121 - mae: 2.0813 - val_loss: 12.0236 - val_mae: 2.5994\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.8139 - mae: 2.0803 - val_loss: 12.1303 - val_mae: 2.6169\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.8313 - mae: 2.0805 - val_loss: 12.1556 - val_mae: 2.6104\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.6795 - mae: 2.0652 - val_loss: 11.9398 - val_mae: 2.5905\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.6525 - mae: 2.0731 - val_loss: 11.9025 - val_mae: 2.5859\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.5660 - mae: 2.0521 - val_loss: 11.9246 - val_mae: 2.5853\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.5342 - mae: 2.0530 - val_loss: 12.0264 - val_mae: 2.5993\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.5421 - mae: 2.0561 - val_loss: 11.9247 - val_mae: 2.5930\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.4695 - mae: 2.0376 - val_loss: 11.6923 - val_mae: 2.5545\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.4543 - mae: 2.0442 - val_loss: 11.6698 - val_mae: 2.5536\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.4070 - mae: 2.0371 - val_loss: 11.5660 - val_mae: 2.5426\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.2901 - mae: 2.0176 - val_loss: 11.5633 - val_mae: 2.5373\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 8.2829 - mae: 2.0296 - val_loss: 11.6586 - val_mae: 2.5477\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 8.2293 - mae: 2.0228 - val_loss: 11.6394 - val_mae: 2.5600\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 8.2340 - mae: 2.0368 - val_loss: 11.7473 - val_mae: 2.5705\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 8.1775 - mae: 2.0131 - val_loss: 11.6348 - val_mae: 2.5551\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 8.0784 - mae: 2.0174 - val_loss: 11.7683 - val_mae: 2.5635\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 8.1094 - mae: 2.0193 - val_loss: 11.7782 - val_mae: 2.5550\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 8.3593 - mae: 2.0058 - val_loss: 11.6512 - val_mae: 2.5581\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 7.9781 - mae: 1.9949 - val_loss: 11.7852 - val_mae: 2.5855\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 8.0374 - mae: 2.0195 - val_loss: 11.5739 - val_mae: 2.5514\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 8.0411 - mae: 1.9794 - val_loss: 11.5757 - val_mae: 2.5420\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 7.8443 - mae: 1.9625 - val_loss: 11.5752 - val_mae: 2.5530\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 7.8313 - mae: 1.9811 - val_loss: 11.5629 - val_mae: 2.5506\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7.7982 - mae: 1.9659 - val_loss: 11.4983 - val_mae: 2.5344\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 7.7260 - mae: 1.9521 - val_loss: 11.3567 - val_mae: 2.5310\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 7.6796 - mae: 1.9567 - val_loss: 11.3421 - val_mae: 2.5255\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 7.6501 - mae: 1.9550 - val_loss: 11.4212 - val_mae: 2.5326\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 7.6004 - mae: 1.9444 - val_loss: 11.3929 - val_mae: 2.5149\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 7.6161 - mae: 1.9468 - val_loss: 11.4625 - val_mae: 2.5389\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 7.5134 - mae: 1.9168 - val_loss: 11.4708 - val_mae: 2.5263\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 7.5498 - mae: 1.9417 - val_loss: 11.5241 - val_mae: 2.5427\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7.4154 - mae: 1.9125 - val_loss: 11.4872 - val_mae: 2.5384\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.4189 - mae: 1.9212 - val_loss: 11.3738 - val_mae: 2.5214\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7.4208 - mae: 1.9116 - val_loss: 11.3909 - val_mae: 2.5273\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 7.5594 - mae: 1.9533 - val_loss: 11.5356 - val_mae: 2.5409\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 7.6277 - mae: 1.9284 - val_loss: 11.3815 - val_mae: 2.5131\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 7.3922 - mae: 1.9359 - val_loss: 11.5818 - val_mae: 2.5638\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 7.2601 - mae: 1.9137 - val_loss: 11.3403 - val_mae: 2.5078\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 7.1425 - mae: 1.8750 - val_loss: 11.3865 - val_mae: 2.5149\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 7.1084 - mae: 1.8799 - val_loss: 11.3719 - val_mae: 2.5202\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.1177 - mae: 1.8747 - val_loss: 11.2759 - val_mae: 2.5220\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 7.1008 - mae: 1.8957 - val_loss: 11.3625 - val_mae: 2.5263\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7.0772 - mae: 1.8818 - val_loss: 11.3714 - val_mae: 2.5121\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.9844 - mae: 1.8579 - val_loss: 11.2587 - val_mae: 2.5043\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.9518 - mae: 1.8616 - val_loss: 11.4193 - val_mae: 2.5405\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6.9305 - mae: 1.8667 - val_loss: 11.4372 - val_mae: 2.5298\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6.8071 - mae: 1.8398 - val_loss: 11.2215 - val_mae: 2.5087\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 6.8255 - mae: 1.8430 - val_loss: 11.2345 - val_mae: 2.5162\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 6.7583 - mae: 1.8303 - val_loss: 11.2836 - val_mae: 2.5135\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 6.7892 - mae: 1.8210 - val_loss: 11.4978 - val_mae: 2.5355\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.6564 - mae: 1.8230 - val_loss: 11.5177 - val_mae: 2.5419\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6.6951 - mae: 1.8447 - val_loss: 11.5203 - val_mae: 2.5266\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.5928 - mae: 1.8143 - val_loss: 11.3991 - val_mae: 2.5117\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.5621 - mae: 1.8042 - val_loss: 11.4570 - val_mae: 2.5301\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 6.5287 - mae: 1.7896 - val_loss: 11.2757 - val_mae: 2.5108\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 6.4963 - mae: 1.8004 - val_loss: 11.2804 - val_mae: 2.5172\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6.5458 - mae: 1.7981 - val_loss: 11.2192 - val_mae: 2.5107\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 6.3500 - mae: 1.7727 - val_loss: 11.2861 - val_mae: 2.5177\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 6.3936 - mae: 1.7756 - val_loss: 11.2635 - val_mae: 2.5135\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 6.2548 - mae: 1.7590 - val_loss: 11.2461 - val_mae: 2.5219\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 6.2690 - mae: 1.7765 - val_loss: 11.1825 - val_mae: 2.5111\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 6.2962 - mae: 1.7505 - val_loss: 11.1640 - val_mae: 2.5085\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 6.2679 - mae: 1.7630 - val_loss: 11.3928 - val_mae: 2.5251\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.1894 - mae: 1.7604 - val_loss: 11.1916 - val_mae: 2.5008\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 6.1009 - mae: 1.7281 - val_loss: 11.2604 - val_mae: 2.5169\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.1133 - mae: 1.7610 - val_loss: 11.1276 - val_mae: 2.4993\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.0829 - mae: 1.7090 - val_loss: 11.0880 - val_mae: 2.5012\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.1329 - mae: 1.7357 - val_loss: 11.3767 - val_mae: 2.5312\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.9676 - mae: 1.7313 - val_loss: 11.1363 - val_mae: 2.4899\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.0164 - mae: 1.7137 - val_loss: 11.1205 - val_mae: 2.4971\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.9893 - mae: 1.7376 - val_loss: 11.3130 - val_mae: 2.5239\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.7992 - mae: 1.6877 - val_loss: 11.1611 - val_mae: 2.5016\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.8295 - mae: 1.6817 - val_loss: 11.0012 - val_mae: 2.4875\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.7725 - mae: 1.6984 - val_loss: 11.1436 - val_mae: 2.5099\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.8137 - mae: 1.7101 - val_loss: 10.9252 - val_mae: 2.4697\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.7671 - mae: 1.6713 - val_loss: 11.0261 - val_mae: 2.4861\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.6623 - mae: 1.6747 - val_loss: 10.9994 - val_mae: 2.4831\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5.6934 - mae: 1.6911 - val_loss: 11.1626 - val_mae: 2.5040\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 5.6762 - mae: 1.6598 - val_loss: 10.8917 - val_mae: 2.4716\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 5.5917 - mae: 1.6681 - val_loss: 11.2510 - val_mae: 2.5186\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 5.6286 - mae: 1.6924 - val_loss: 10.9568 - val_mae: 2.4694\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 5.5580 - mae: 1.6441 - val_loss: 11.0056 - val_mae: 2.4736\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 5.4736 - mae: 1.6288 - val_loss: 11.1753 - val_mae: 2.4965\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 5.4656 - mae: 1.6498 - val_loss: 11.1891 - val_mae: 2.4959\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 5.4227 - mae: 1.6325 - val_loss: 11.0704 - val_mae: 2.4866\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 5.3785 - mae: 1.6312 - val_loss: 11.2716 - val_mae: 2.5149\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 5.3442 - mae: 1.6142 - val_loss: 11.0239 - val_mae: 2.4777\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 5.2827 - mae: 1.6095 - val_loss: 11.0532 - val_mae: 2.4688\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 5.3010 - mae: 1.6172 - val_loss: 10.8789 - val_mae: 2.4602\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 5.2719 - mae: 1.6161 - val_loss: 11.1084 - val_mae: 2.4830\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 5.1925 - mae: 1.5962 - val_loss: 11.0330 - val_mae: 2.4677\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 5.3323 - mae: 1.6214 - val_loss: 10.9633 - val_mae: 2.4657\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.2256 - mae: 1.5903 - val_loss: 11.0224 - val_mae: 2.4744\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 5.3737 - mae: 1.6503 - val_loss: 11.1047 - val_mae: 2.4875\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 5.3066 - mae: 1.6260 - val_loss: 10.8520 - val_mae: 2.4432\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 5.1652 - mae: 1.5986 - val_loss: 11.0722 - val_mae: 2.4767\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.0225 - mae: 1.5681 - val_loss: 11.0148 - val_mae: 2.4594\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.1028 - mae: 1.5814 - val_loss: 11.0609 - val_mae: 2.4703\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.1517 - mae: 1.6135 - val_loss: 11.1262 - val_mae: 2.4742\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.9124 - mae: 1.5635 - val_loss: 11.0106 - val_mae: 2.4562\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.9246 - mae: 1.5533 - val_loss: 11.1785 - val_mae: 2.4832\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.0537 - mae: 1.5759 - val_loss: 11.2774 - val_mae: 2.4946\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 5.0021 - mae: 1.5696 - val_loss: 10.8226 - val_mae: 2.4370\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.9153 - mae: 1.5578 - val_loss: 10.9155 - val_mae: 2.4423\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 4.8850 - mae: 1.5587 - val_loss: 10.9680 - val_mae: 2.4457\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.8358 - mae: 1.5477 - val_loss: 11.1589 - val_mae: 2.4746\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.7241 - mae: 1.5333 - val_loss: 11.0326 - val_mae: 2.4485\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.7531 - mae: 1.5268 - val_loss: 11.0093 - val_mae: 2.4496\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 4.7246 - mae: 1.5416 - val_loss: 11.1227 - val_mae: 2.4637\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 4.6738 - mae: 1.5094 - val_loss: 10.9944 - val_mae: 2.4476\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.6377 - mae: 1.5063 - val_loss: 11.1299 - val_mae: 2.4673\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.6740 - mae: 1.5304 - val_loss: 11.2262 - val_mae: 2.4678\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 4.6290 - mae: 1.5022 - val_loss: 11.2027 - val_mae: 2.4678\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 4.5703 - mae: 1.5031 - val_loss: 11.0527 - val_mae: 2.4501\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.5499 - mae: 1.5122 - val_loss: 10.9702 - val_mae: 2.4357\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.5038 - mae: 1.4880 - val_loss: 10.8665 - val_mae: 2.4279\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.5728 - mae: 1.5168 - val_loss: 11.2424 - val_mae: 2.4627\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 4.5292 - mae: 1.4899 - val_loss: 10.9981 - val_mae: 2.4427\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.4370 - mae: 1.4768 - val_loss: 11.2046 - val_mae: 2.4553\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.4432 - mae: 1.4851 - val_loss: 11.0054 - val_mae: 2.4334\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3739 - mae: 1.4680 - val_loss: 10.9367 - val_mae: 2.4219\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.3736 - mae: 1.4677 - val_loss: 10.9721 - val_mae: 2.4205\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.3460 - mae: 1.4811 - val_loss: 11.1620 - val_mae: 2.4299\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.3144 - mae: 1.4664 - val_loss: 11.0890 - val_mae: 2.4245\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.2917 - mae: 1.4686 - val_loss: 11.0686 - val_mae: 2.4218\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2487 - mae: 1.4542 - val_loss: 11.0137 - val_mae: 2.4222\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.2473 - mae: 1.4500 - val_loss: 11.3531 - val_mae: 2.4593\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.2598 - mae: 1.4495 - val_loss: 11.2642 - val_mae: 2.4425\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.1647 - mae: 1.4402 - val_loss: 11.1009 - val_mae: 2.4227\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1841 - mae: 1.4678 - val_loss: 11.3139 - val_mae: 2.4405\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1292 - mae: 1.4368 - val_loss: 11.0862 - val_mae: 2.4166\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.1736 - mae: 1.4427 - val_loss: 11.1316 - val_mae: 2.4144\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1316 - mae: 1.4254 - val_loss: 11.1457 - val_mae: 2.4219\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.0396 - mae: 1.4129 - val_loss: 11.1398 - val_mae: 2.4095\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0598 - mae: 1.4361 - val_loss: 11.0809 - val_mae: 2.4101\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1014 - mae: 1.4192 - val_loss: 11.0914 - val_mae: 2.4045\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.0046 - mae: 1.4337 - val_loss: 11.3131 - val_mae: 2.4175\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.9963 - mae: 1.4243 - val_loss: 11.0823 - val_mae: 2.4010\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.1040 - mae: 1.4128 - val_loss: 11.3472 - val_mae: 2.4301\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.0205 - mae: 1.4398 - val_loss: 11.1754 - val_mae: 2.4033\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.9069 - mae: 1.4026 - val_loss: 10.8984 - val_mae: 2.3753\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.8670 - mae: 1.3933 - val_loss: 11.2760 - val_mae: 2.4055\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.8799 - mae: 1.4076 - val_loss: 11.0053 - val_mae: 2.3901\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.8997 - mae: 1.4129 - val_loss: 10.9714 - val_mae: 2.3712\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.7971 - mae: 1.3772 - val_loss: 10.9628 - val_mae: 2.3858\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 3.8375 - mae: 1.3828 - val_loss: 11.2196 - val_mae: 2.3892\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.8868 - mae: 1.4210 - val_loss: 11.3436 - val_mae: 2.4015\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.7625 - mae: 1.3703 - val_loss: 11.0838 - val_mae: 2.3856\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 3.7710 - mae: 1.3733 - val_loss: 11.1319 - val_mae: 2.3760\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.7069 - mae: 1.3709 - val_loss: 11.1914 - val_mae: 2.3990\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.7973 - mae: 1.3735 - val_loss: 11.0175 - val_mae: 2.3891\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.7023 - mae: 1.3736 - val_loss: 11.1591 - val_mae: 2.3764\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.6790 - mae: 1.3616 - val_loss: 10.8961 - val_mae: 2.3709\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 3.6077 - mae: 1.3516 - val_loss: 11.2044 - val_mae: 2.3892\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.6151 - mae: 1.3610 - val_loss: 11.1425 - val_mae: 2.3886\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.6192 - mae: 1.3525 - val_loss: 10.9773 - val_mae: 2.3604\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 3.5879 - mae: 1.3492 - val_loss: 11.0470 - val_mae: 2.3870\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.6289 - mae: 1.3608 - val_loss: 11.2164 - val_mae: 2.3989\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.5049 - mae: 1.3330 - val_loss: 10.9368 - val_mae: 2.3664\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.4956 - mae: 1.3210 - val_loss: 11.2696 - val_mae: 2.4020\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 3.4970 - mae: 1.3472 - val_loss: 11.1473 - val_mae: 2.3780\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 3.4815 - mae: 1.3197 - val_loss: 11.0758 - val_mae: 2.3824\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 3.4470 - mae: 1.3318 - val_loss: 11.1409 - val_mae: 2.3767\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.4366 - mae: 1.3166 - val_loss: 11.0424 - val_mae: 2.3780\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.4301 - mae: 1.3253 - val_loss: 10.9530 - val_mae: 2.3588\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.4065 - mae: 1.3013 - val_loss: 11.1006 - val_mae: 2.3811\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.4558 - mae: 1.3324 - val_loss: 10.9418 - val_mae: 2.3502\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.3333 - mae: 1.3083 - val_loss: 11.0738 - val_mae: 2.3570\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.3281 - mae: 1.3023 - val_loss: 11.1034 - val_mae: 2.3706\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 3.3463 - mae: 1.2872 - val_loss: 11.0204 - val_mae: 2.3817\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.3167 - mae: 1.2987 - val_loss: 11.0119 - val_mae: 2.3689\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.2864 - mae: 1.2967 - val_loss: 11.1478 - val_mae: 2.3615\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.2772 - mae: 1.2916 - val_loss: 11.1427 - val_mae: 2.3752\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.2762 - mae: 1.2951 - val_loss: 11.1890 - val_mae: 2.3933\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.3302 - mae: 1.2755 - val_loss: 11.0733 - val_mae: 2.3656\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 3.2141 - mae: 1.2809 - val_loss: 10.8649 - val_mae: 2.3435\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.1956 - mae: 1.2817 - val_loss: 11.0932 - val_mae: 2.3653\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.1560 - mae: 1.2707 - val_loss: 11.2434 - val_mae: 2.3903\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.1777 - mae: 1.2813 - val_loss: 11.2035 - val_mae: 2.3708\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3.2727 - mae: 1.2913 - val_loss: 10.9579 - val_mae: 2.3610\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.1657 - mae: 1.2548 - val_loss: 10.9259 - val_mae: 2.3661\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3.1256 - mae: 1.2628 - val_loss: 11.1674 - val_mae: 2.3744\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.1054 - mae: 1.2665 - val_loss: 11.0198 - val_mae: 2.3695\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 3.0936 - mae: 1.2488 - val_loss: 11.2212 - val_mae: 2.3773\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 3.0919 - mae: 1.2572 - val_loss: 11.1923 - val_mae: 2.3660\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3.1110 - mae: 1.2464 - val_loss: 11.2102 - val_mae: 2.3744\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 3.0726 - mae: 1.2788 - val_loss: 11.0368 - val_mae: 2.3610\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 8.8316 - mae: 2.1348\n",
            "Epoch 1/300\n",
            "10/10 [==============================] - 1s 26ms/step - loss: 590.2038 - mae: 22.3654 - val_loss: 486.5766 - val_mae: 20.2635\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 566.2327 - mae: 21.7930 - val_loss: 464.2395 - val_mae: 19.6877\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 540.2212 - mae: 21.1669 - val_loss: 437.6468 - val_mae: 18.9918\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 508.3594 - mae: 20.3754 - val_loss: 404.4206 - val_mae: 18.0955\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 466.9524 - mae: 19.3400 - val_loss: 361.1376 - val_mae: 16.8818\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 414.1326 - mae: 17.9839 - val_loss: 307.2571 - val_mae: 15.4100\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 347.1049 - mae: 16.2290 - val_loss: 245.6109 - val_mae: 13.6590\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 273.5733 - mae: 14.0697 - val_loss: 183.0014 - val_mae: 11.6813\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 202.2890 - mae: 11.6929 - val_loss: 127.2178 - val_mae: 9.5170\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 141.7525 - mae: 9.3789 - val_loss: 86.8484 - val_mae: 7.7217\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 103.6010 - mae: 7.5945 - val_loss: 62.6212 - val_mae: 6.3696\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 78.1621 - mae: 6.5543 - val_loss: 50.7496 - val_mae: 5.7227\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 65.9679 - mae: 5.9590 - val_loss: 42.5923 - val_mae: 5.2803\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 56.1938 - mae: 5.4675 - val_loss: 36.1939 - val_mae: 4.8584\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 48.5071 - mae: 5.0222 - val_loss: 31.1938 - val_mae: 4.4745\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 43.1524 - mae: 4.6781 - val_loss: 27.5923 - val_mae: 4.2104\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 38.7839 - mae: 4.4014 - val_loss: 25.2358 - val_mae: 4.0038\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 35.7500 - mae: 4.2125 - val_loss: 23.3437 - val_mae: 3.8314\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 33.3840 - mae: 4.0855 - val_loss: 22.0147 - val_mae: 3.6955\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 31.3974 - mae: 3.9415 - val_loss: 20.9038 - val_mae: 3.5885\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 29.8823 - mae: 3.8312 - val_loss: 20.0837 - val_mae: 3.4956\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 28.7352 - mae: 3.7400 - val_loss: 19.4096 - val_mae: 3.4216\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 27.6297 - mae: 3.6850 - val_loss: 18.9747 - val_mae: 3.3906\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 26.5906 - mae: 3.6220 - val_loss: 18.4855 - val_mae: 3.3470\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 25.8042 - mae: 3.5631 - val_loss: 17.9649 - val_mae: 3.2891\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 25.0413 - mae: 3.5024 - val_loss: 17.5419 - val_mae: 3.2383\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 24.3900 - mae: 3.4616 - val_loss: 17.4071 - val_mae: 3.2312\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 23.6014 - mae: 3.4101 - val_loss: 17.0235 - val_mae: 3.1804\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 23.0893 - mae: 3.3502 - val_loss: 16.5563 - val_mae: 3.1109\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 22.4787 - mae: 3.2988 - val_loss: 16.2060 - val_mae: 3.0724\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 21.9427 - mae: 3.2698 - val_loss: 16.1998 - val_mae: 3.0747\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 21.3853 - mae: 3.2492 - val_loss: 15.9015 - val_mae: 3.0372\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 20.8992 - mae: 3.2091 - val_loss: 15.6527 - val_mae: 3.0010\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 20.4777 - mae: 3.1772 - val_loss: 15.5414 - val_mae: 2.9731\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 20.0720 - mae: 3.1411 - val_loss: 15.2634 - val_mae: 2.9316\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 19.6404 - mae: 3.0998 - val_loss: 15.0464 - val_mae: 2.8944\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 19.3416 - mae: 3.0910 - val_loss: 15.2037 - val_mae: 2.8974\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 18.9087 - mae: 3.0647 - val_loss: 15.0044 - val_mae: 2.8649\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 18.5623 - mae: 3.0166 - val_loss: 14.6826 - val_mae: 2.8187\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 18.2754 - mae: 2.9960 - val_loss: 14.6605 - val_mae: 2.8153\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 17.8994 - mae: 2.9691 - val_loss: 14.4602 - val_mae: 2.7890\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 17.6125 - mae: 2.9446 - val_loss: 14.3652 - val_mae: 2.7659\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 17.3226 - mae: 2.9180 - val_loss: 14.4929 - val_mae: 2.7729\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 16.9671 - mae: 2.9007 - val_loss: 14.3185 - val_mae: 2.7457\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 16.7176 - mae: 2.8706 - val_loss: 14.0684 - val_mae: 2.7014\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 16.4775 - mae: 2.8468 - val_loss: 14.2033 - val_mae: 2.7127\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 16.2304 - mae: 2.8397 - val_loss: 14.0356 - val_mae: 2.6859\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 15.9954 - mae: 2.8201 - val_loss: 13.9223 - val_mae: 2.6691\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 15.7624 - mae: 2.8020 - val_loss: 13.9498 - val_mae: 2.6688\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 15.5605 - mae: 2.7894 - val_loss: 13.8130 - val_mae: 2.6487\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 15.3372 - mae: 2.7728 - val_loss: 13.8248 - val_mae: 2.6516\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 15.1348 - mae: 2.7610 - val_loss: 13.8701 - val_mae: 2.6629\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 14.9763 - mae: 2.7492 - val_loss: 13.7569 - val_mae: 2.6464\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 14.8383 - mae: 2.7265 - val_loss: 13.5878 - val_mae: 2.6220\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 14.5737 - mae: 2.7128 - val_loss: 13.6445 - val_mae: 2.6410\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 14.4331 - mae: 2.7133 - val_loss: 13.7774 - val_mae: 2.6627\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 14.4228 - mae: 2.6968 - val_loss: 13.3306 - val_mae: 2.5889\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 14.1434 - mae: 2.6889 - val_loss: 13.6917 - val_mae: 2.6424\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 13.9105 - mae: 2.6716 - val_loss: 13.4924 - val_mae: 2.6169\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 13.7525 - mae: 2.6437 - val_loss: 13.1895 - val_mae: 2.5831\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 13.6467 - mae: 2.6374 - val_loss: 13.4211 - val_mae: 2.6158\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 13.4493 - mae: 2.6276 - val_loss: 13.3450 - val_mae: 2.6075\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 13.3278 - mae: 2.6261 - val_loss: 13.7335 - val_mae: 2.6560\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 13.1972 - mae: 2.6171 - val_loss: 13.3232 - val_mae: 2.5935\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 13.0658 - mae: 2.5899 - val_loss: 13.2252 - val_mae: 2.5817\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.9804 - mae: 2.5793 - val_loss: 13.1813 - val_mae: 2.5946\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 12.8334 - mae: 2.5792 - val_loss: 13.3020 - val_mae: 2.6100\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.6609 - mae: 2.5629 - val_loss: 13.0428 - val_mae: 2.5726\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 12.5876 - mae: 2.5403 - val_loss: 12.8399 - val_mae: 2.5395\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 12.4676 - mae: 2.5302 - val_loss: 13.2445 - val_mae: 2.6062\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.4294 - mae: 2.5488 - val_loss: 13.3775 - val_mae: 2.6273\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.2309 - mae: 2.5325 - val_loss: 13.0069 - val_mae: 2.5613\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 12.1749 - mae: 2.5118 - val_loss: 13.0518 - val_mae: 2.5636\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.0258 - mae: 2.4980 - val_loss: 13.1302 - val_mae: 2.5849\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.9407 - mae: 2.4943 - val_loss: 13.0756 - val_mae: 2.5938\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 11.8570 - mae: 2.4889 - val_loss: 13.1501 - val_mae: 2.6018\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.7828 - mae: 2.4910 - val_loss: 13.1880 - val_mae: 2.5991\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 11.6338 - mae: 2.4669 - val_loss: 12.9493 - val_mae: 2.5587\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 11.6967 - mae: 2.4601 - val_loss: 12.9748 - val_mae: 2.5658\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.5564 - mae: 2.4436 - val_loss: 13.0445 - val_mae: 2.5790\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 11.4841 - mae: 2.4575 - val_loss: 13.3042 - val_mae: 2.6213\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.4838 - mae: 2.4459 - val_loss: 12.8807 - val_mae: 2.5579\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 11.2765 - mae: 2.4313 - val_loss: 13.4966 - val_mae: 2.6534\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 11.2561 - mae: 2.4428 - val_loss: 13.3171 - val_mae: 2.6230\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.0794 - mae: 2.4165 - val_loss: 13.0307 - val_mae: 2.5813\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11.0263 - mae: 2.3981 - val_loss: 13.0922 - val_mae: 2.5852\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 10.9420 - mae: 2.3893 - val_loss: 13.0070 - val_mae: 2.5805\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.8429 - mae: 2.3873 - val_loss: 13.1093 - val_mae: 2.6058\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 10.8690 - mae: 2.4008 - val_loss: 13.1431 - val_mae: 2.6021\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.8416 - mae: 2.3868 - val_loss: 12.9644 - val_mae: 2.5725\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.6771 - mae: 2.3698 - val_loss: 13.2764 - val_mae: 2.6246\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.6227 - mae: 2.3753 - val_loss: 13.0966 - val_mae: 2.6128\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.5862 - mae: 2.3619 - val_loss: 13.0451 - val_mae: 2.6010\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 10.4387 - mae: 2.3396 - val_loss: 12.9493 - val_mae: 2.5941\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 10.4501 - mae: 2.3567 - val_loss: 13.0766 - val_mae: 2.6188\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 10.3065 - mae: 2.3400 - val_loss: 12.9441 - val_mae: 2.5946\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 10.2546 - mae: 2.3214 - val_loss: 13.0280 - val_mae: 2.5973\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 10.1707 - mae: 2.3116 - val_loss: 12.9568 - val_mae: 2.5882\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 10.1196 - mae: 2.3145 - val_loss: 12.8774 - val_mae: 2.5893\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 10.1051 - mae: 2.3063 - val_loss: 12.9790 - val_mae: 2.6063\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 10.0165 - mae: 2.2875 - val_loss: 12.6602 - val_mae: 2.5669\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 9.9034 - mae: 2.2868 - val_loss: 12.9587 - val_mae: 2.6107\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 9.8798 - mae: 2.2870 - val_loss: 12.7408 - val_mae: 2.5850\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 9.7937 - mae: 2.2867 - val_loss: 13.4163 - val_mae: 2.6609\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.7310 - mae: 2.2782 - val_loss: 13.0200 - val_mae: 2.5998\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.6436 - mae: 2.2567 - val_loss: 12.6049 - val_mae: 2.5487\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 9.6779 - mae: 2.2695 - val_loss: 12.8905 - val_mae: 2.6099\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 9.5968 - mae: 2.2602 - val_loss: 12.9006 - val_mae: 2.6007\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 9.4925 - mae: 2.2441 - val_loss: 12.7647 - val_mae: 2.5863\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.3908 - mae: 2.2275 - val_loss: 12.6392 - val_mae: 2.5702\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.3751 - mae: 2.2201 - val_loss: 12.6402 - val_mae: 2.5680\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 9.2850 - mae: 2.2192 - val_loss: 12.8427 - val_mae: 2.5988\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 9.3420 - mae: 2.2417 - val_loss: 13.2020 - val_mae: 2.6425\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 9.3151 - mae: 2.2358 - val_loss: 12.5031 - val_mae: 2.5366\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 9.1570 - mae: 2.2143 - val_loss: 12.7420 - val_mae: 2.5731\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 9.1089 - mae: 2.2147 - val_loss: 13.2831 - val_mae: 2.6432\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 9.0045 - mae: 2.2035 - val_loss: 12.6948 - val_mae: 2.5619\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 8.9594 - mae: 2.2020 - val_loss: 12.6648 - val_mae: 2.5652\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 8.9042 - mae: 2.1858 - val_loss: 12.8388 - val_mae: 2.5699\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 8.8501 - mae: 2.1875 - val_loss: 12.6749 - val_mae: 2.5733\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 8.8254 - mae: 2.1870 - val_loss: 12.5877 - val_mae: 2.5641\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 8.7575 - mae: 2.1769 - val_loss: 12.5506 - val_mae: 2.5363\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 8.6931 - mae: 2.1556 - val_loss: 12.2089 - val_mae: 2.5189\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 8.7331 - mae: 2.1558 - val_loss: 12.4681 - val_mae: 2.5520\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 8.5947 - mae: 2.1436 - val_loss: 12.5337 - val_mae: 2.5672\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.5883 - mae: 2.1692 - val_loss: 12.8550 - val_mae: 2.6042\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 8.4976 - mae: 2.1501 - val_loss: 12.3092 - val_mae: 2.5263\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.4111 - mae: 2.1320 - val_loss: 12.6262 - val_mae: 2.5543\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.4516 - mae: 2.1336 - val_loss: 12.3048 - val_mae: 2.5442\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.2874 - mae: 2.1198 - val_loss: 12.6311 - val_mae: 2.5676\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.3289 - mae: 2.1323 - val_loss: 12.5595 - val_mae: 2.5689\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.2321 - mae: 2.1193 - val_loss: 12.5396 - val_mae: 2.5530\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.2062 - mae: 2.1240 - val_loss: 12.8046 - val_mae: 2.5834\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.1769 - mae: 2.1019 - val_loss: 12.2883 - val_mae: 2.5067\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.0825 - mae: 2.0929 - val_loss: 12.4516 - val_mae: 2.5407\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 8.0078 - mae: 2.0876 - val_loss: 12.2190 - val_mae: 2.5287\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.9970 - mae: 2.0824 - val_loss: 12.5408 - val_mae: 2.5512\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.8817 - mae: 2.0747 - val_loss: 12.4187 - val_mae: 2.5447\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.8531 - mae: 2.0713 - val_loss: 12.3780 - val_mae: 2.5382\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.8474 - mae: 2.0634 - val_loss: 12.0959 - val_mae: 2.5056\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.7881 - mae: 2.0494 - val_loss: 12.4659 - val_mae: 2.5521\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.7806 - mae: 2.0729 - val_loss: 12.3421 - val_mae: 2.5421\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.7011 - mae: 2.0421 - val_loss: 11.9543 - val_mae: 2.4967\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.6156 - mae: 2.0335 - val_loss: 12.2141 - val_mae: 2.5181\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.5905 - mae: 2.0354 - val_loss: 12.1727 - val_mae: 2.5030\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7.6386 - mae: 2.0435 - val_loss: 11.9542 - val_mae: 2.4927\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.4954 - mae: 2.0266 - val_loss: 12.4630 - val_mae: 2.5445\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.4998 - mae: 2.0245 - val_loss: 11.8610 - val_mae: 2.4663\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.4542 - mae: 2.0156 - val_loss: 12.2578 - val_mae: 2.5124\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.3518 - mae: 2.0161 - val_loss: 12.0268 - val_mae: 2.4836\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.3401 - mae: 2.0002 - val_loss: 11.8763 - val_mae: 2.4589\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.3041 - mae: 1.9852 - val_loss: 12.1018 - val_mae: 2.5040\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.2926 - mae: 2.0003 - val_loss: 11.9779 - val_mae: 2.4879\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.3568 - mae: 2.0197 - val_loss: 12.2429 - val_mae: 2.5233\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.2133 - mae: 1.9943 - val_loss: 11.4325 - val_mae: 2.4067\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.2149 - mae: 1.9874 - val_loss: 11.7391 - val_mae: 2.4687\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.1302 - mae: 1.9715 - val_loss: 11.7665 - val_mae: 2.4490\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.0643 - mae: 1.9589 - val_loss: 11.7274 - val_mae: 2.4534\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.0876 - mae: 1.9797 - val_loss: 11.8260 - val_mae: 2.4640\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.9888 - mae: 1.9506 - val_loss: 12.1120 - val_mae: 2.4853\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.9629 - mae: 1.9539 - val_loss: 11.8039 - val_mae: 2.4646\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.9050 - mae: 1.9428 - val_loss: 11.8265 - val_mae: 2.4423\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.8898 - mae: 1.9373 - val_loss: 11.5698 - val_mae: 2.4169\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.8508 - mae: 1.9394 - val_loss: 11.6174 - val_mae: 2.4469\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.8409 - mae: 1.9492 - val_loss: 12.0278 - val_mae: 2.4829\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.7099 - mae: 1.9133 - val_loss: 11.6707 - val_mae: 2.4274\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.8144 - mae: 1.9199 - val_loss: 11.6005 - val_mae: 2.4281\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.6432 - mae: 1.9002 - val_loss: 11.9212 - val_mae: 2.4541\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.7659 - mae: 1.9242 - val_loss: 12.1475 - val_mae: 2.4865\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.5957 - mae: 1.9043 - val_loss: 11.6189 - val_mae: 2.3959\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.6005 - mae: 1.9040 - val_loss: 11.9937 - val_mae: 2.4654\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.5392 - mae: 1.9010 - val_loss: 11.6377 - val_mae: 2.4141\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.4889 - mae: 1.9029 - val_loss: 12.0498 - val_mae: 2.4642\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.4436 - mae: 1.8832 - val_loss: 11.5639 - val_mae: 2.3926\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.4236 - mae: 1.8677 - val_loss: 11.6713 - val_mae: 2.4160\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.4167 - mae: 1.8856 - val_loss: 12.1497 - val_mae: 2.4756\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.3485 - mae: 1.8753 - val_loss: 11.6207 - val_mae: 2.3913\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.3175 - mae: 1.8680 - val_loss: 11.8248 - val_mae: 2.4231\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.2180 - mae: 1.8536 - val_loss: 11.5628 - val_mae: 2.3916\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6.2285 - mae: 1.8446 - val_loss: 11.5582 - val_mae: 2.4022\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.2862 - mae: 1.8519 - val_loss: 11.5167 - val_mae: 2.3823\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.2398 - mae: 1.8405 - val_loss: 11.9850 - val_mae: 2.4471\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.1434 - mae: 1.8392 - val_loss: 11.4878 - val_mae: 2.3808\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.1713 - mae: 1.8343 - val_loss: 11.4874 - val_mae: 2.3918\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.2097 - mae: 1.8344 - val_loss: 11.6299 - val_mae: 2.3986\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6.0589 - mae: 1.8332 - val_loss: 11.9468 - val_mae: 2.4375\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 6.0472 - mae: 1.8197 - val_loss: 11.6069 - val_mae: 2.3668\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.9564 - mae: 1.8045 - val_loss: 12.0021 - val_mae: 2.4416\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 5.9731 - mae: 1.8300 - val_loss: 11.7325 - val_mae: 2.4177\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.9193 - mae: 1.8011 - val_loss: 11.6937 - val_mae: 2.3858\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.9194 - mae: 1.7989 - val_loss: 11.5834 - val_mae: 2.3779\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.8680 - mae: 1.7880 - val_loss: 11.7793 - val_mae: 2.3906\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.8200 - mae: 1.7834 - val_loss: 11.7893 - val_mae: 2.4033\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 5.8808 - mae: 1.8079 - val_loss: 11.5624 - val_mae: 2.3999\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.8637 - mae: 1.7998 - val_loss: 12.0180 - val_mae: 2.4373\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.8528 - mae: 1.7705 - val_loss: 11.2428 - val_mae: 2.3230\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.7014 - mae: 1.7735 - val_loss: 11.8311 - val_mae: 2.4141\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.7395 - mae: 1.7910 - val_loss: 11.8144 - val_mae: 2.3940\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.6882 - mae: 1.7733 - val_loss: 11.5046 - val_mae: 2.3586\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.7471 - mae: 1.7742 - val_loss: 11.8930 - val_mae: 2.4121\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.7825 - mae: 1.7775 - val_loss: 11.2239 - val_mae: 2.3238\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.5922 - mae: 1.7531 - val_loss: 12.0605 - val_mae: 2.4430\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.5939 - mae: 1.7630 - val_loss: 11.3467 - val_mae: 2.3435\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.5492 - mae: 1.7279 - val_loss: 11.3511 - val_mae: 2.3243\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.4993 - mae: 1.7298 - val_loss: 11.8651 - val_mae: 2.4064\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.4822 - mae: 1.7494 - val_loss: 11.5523 - val_mae: 2.3649\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.4327 - mae: 1.7288 - val_loss: 11.5155 - val_mae: 2.3459\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.3983 - mae: 1.7153 - val_loss: 11.7513 - val_mae: 2.3802\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.3732 - mae: 1.7250 - val_loss: 11.6300 - val_mae: 2.3581\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.3377 - mae: 1.7095 - val_loss: 11.6319 - val_mae: 2.3604\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.3285 - mae: 1.7165 - val_loss: 11.7807 - val_mae: 2.3905\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.2772 - mae: 1.7074 - val_loss: 11.4110 - val_mae: 2.3263\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.3211 - mae: 1.7077 - val_loss: 11.6200 - val_mae: 2.3640\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.2943 - mae: 1.6940 - val_loss: 11.5082 - val_mae: 2.3380\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.2353 - mae: 1.6959 - val_loss: 11.6384 - val_mae: 2.3677\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.2130 - mae: 1.6847 - val_loss: 11.6329 - val_mae: 2.3561\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.1814 - mae: 1.6786 - val_loss: 11.5737 - val_mae: 2.3526\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.1935 - mae: 1.7061 - val_loss: 11.9169 - val_mae: 2.3881\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.1588 - mae: 1.6899 - val_loss: 11.6854 - val_mae: 2.3391\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.1256 - mae: 1.6713 - val_loss: 11.6298 - val_mae: 2.3431\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.1135 - mae: 1.6709 - val_loss: 11.6000 - val_mae: 2.3473\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 5.0689 - mae: 1.6639 - val_loss: 11.7005 - val_mae: 2.3548\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 5.0590 - mae: 1.6651 - val_loss: 11.8289 - val_mae: 2.3826\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.0307 - mae: 1.6707 - val_loss: 11.7509 - val_mae: 2.3526\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.0310 - mae: 1.6476 - val_loss: 11.7494 - val_mae: 2.3534\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.0147 - mae: 1.6631 - val_loss: 11.4305 - val_mae: 2.3313\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.9974 - mae: 1.6604 - val_loss: 11.8440 - val_mae: 2.3674\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.0258 - mae: 1.6728 - val_loss: 11.6268 - val_mae: 2.3287\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.0213 - mae: 1.6425 - val_loss: 11.5098 - val_mae: 2.3201\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.0241 - mae: 1.6788 - val_loss: 11.8688 - val_mae: 2.3729\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.8600 - mae: 1.6331 - val_loss: 11.5702 - val_mae: 2.3297\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.8841 - mae: 1.6270 - val_loss: 11.7832 - val_mae: 2.3461\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.8334 - mae: 1.6362 - val_loss: 11.6447 - val_mae: 2.3380\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.8227 - mae: 1.6192 - val_loss: 11.4727 - val_mae: 2.3140\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 4.8633 - mae: 1.6277 - val_loss: 12.0328 - val_mae: 2.3821\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 4.8319 - mae: 1.6311 - val_loss: 11.4597 - val_mae: 2.3000\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.7504 - mae: 1.6058 - val_loss: 11.5992 - val_mae: 2.3150\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 4.7697 - mae: 1.6098 - val_loss: 11.9132 - val_mae: 2.3575\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.7793 - mae: 1.6261 - val_loss: 11.5722 - val_mae: 2.3247\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.7151 - mae: 1.6032 - val_loss: 11.8224 - val_mae: 2.3525\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.6963 - mae: 1.5936 - val_loss: 11.7441 - val_mae: 2.3338\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.6954 - mae: 1.5938 - val_loss: 11.7162 - val_mae: 2.3305\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.6470 - mae: 1.5872 - val_loss: 11.8340 - val_mae: 2.3422\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.6921 - mae: 1.6020 - val_loss: 11.6487 - val_mae: 2.3122\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.6297 - mae: 1.5861 - val_loss: 11.6018 - val_mae: 2.3101\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 4.6232 - mae: 1.5879 - val_loss: 11.8714 - val_mae: 2.3247\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.5689 - mae: 1.5821 - val_loss: 11.9628 - val_mae: 2.3466\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.5613 - mae: 1.5947 - val_loss: 11.9285 - val_mae: 2.3465\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.5484 - mae: 1.5776 - val_loss: 11.7224 - val_mae: 2.3148\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 4.5973 - mae: 1.5755 - val_loss: 11.9056 - val_mae: 2.3404\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.5035 - mae: 1.5612 - val_loss: 11.8493 - val_mae: 2.3435\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.6153 - mae: 1.6140 - val_loss: 11.9797 - val_mae: 2.3416\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 4.4910 - mae: 1.5755 - val_loss: 11.8960 - val_mae: 2.3118\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 4.4398 - mae: 1.5590 - val_loss: 12.1652 - val_mae: 2.3786\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.6271 - mae: 1.6060 - val_loss: 11.6500 - val_mae: 2.3102\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 4.6183 - mae: 1.5962 - val_loss: 12.2958 - val_mae: 2.3617\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.5418 - mae: 1.5995 - val_loss: 12.0086 - val_mae: 2.3411\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.4423 - mae: 1.5619 - val_loss: 12.2017 - val_mae: 2.3552\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.3919 - mae: 1.5343 - val_loss: 11.6718 - val_mae: 2.3125\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 4.4117 - mae: 1.5395 - val_loss: 12.0865 - val_mae: 2.3641\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.3713 - mae: 1.5553 - val_loss: 11.9418 - val_mae: 2.3298\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.3553 - mae: 1.5410 - val_loss: 11.9278 - val_mae: 2.3136\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.3747 - mae: 1.5652 - val_loss: 11.9184 - val_mae: 2.3187\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4.3193 - mae: 1.5431 - val_loss: 12.2213 - val_mae: 2.3300\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 4.3255 - mae: 1.5331 - val_loss: 11.9275 - val_mae: 2.3187\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 4.3646 - mae: 1.5500 - val_loss: 12.2161 - val_mae: 2.3510\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.2866 - mae: 1.5415 - val_loss: 11.9601 - val_mae: 2.3033\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.2262 - mae: 1.5221 - val_loss: 12.0333 - val_mae: 2.3202\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.2167 - mae: 1.5081 - val_loss: 11.9248 - val_mae: 2.3166\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.2364 - mae: 1.5120 - val_loss: 12.0935 - val_mae: 2.3353\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.2160 - mae: 1.5170 - val_loss: 12.0667 - val_mae: 2.3276\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.1547 - mae: 1.5050 - val_loss: 11.8318 - val_mae: 2.2991\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.2453 - mae: 1.5345 - val_loss: 11.9520 - val_mae: 2.3334\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.1409 - mae: 1.5013 - val_loss: 11.8076 - val_mae: 2.2976\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.2052 - mae: 1.4998 - val_loss: 11.9633 - val_mae: 2.3217\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.2402 - mae: 1.5527 - val_loss: 11.6460 - val_mae: 2.3066\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.1007 - mae: 1.4942 - val_loss: 11.9112 - val_mae: 2.3117\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0545 - mae: 1.4891 - val_loss: 11.8231 - val_mae: 2.3065\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.1901 - mae: 1.5008 - val_loss: 11.9049 - val_mae: 2.3107\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.1481 - mae: 1.5200 - val_loss: 11.7922 - val_mae: 2.2903\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.0725 - mae: 1.4716 - val_loss: 11.4166 - val_mae: 2.2786\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.9953 - mae: 1.4662 - val_loss: 11.9281 - val_mae: 2.3168\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.1124 - mae: 1.5068 - val_loss: 11.7284 - val_mae: 2.2965\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.0429 - mae: 1.4958 - val_loss: 11.8284 - val_mae: 2.2969\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.9698 - mae: 1.4696 - val_loss: 11.9164 - val_mae: 2.3078\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0485 - mae: 1.4672 - val_loss: 11.5994 - val_mae: 2.2907\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.9165 - mae: 1.4654 - val_loss: 11.8781 - val_mae: 2.3185\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.9749 - mae: 1.4719 - val_loss: 11.6372 - val_mae: 2.2640\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.9151 - mae: 1.4502 - val_loss: 11.8687 - val_mae: 2.3132\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.9460 - mae: 1.4758 - val_loss: 11.9270 - val_mae: 2.3267\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.8734 - mae: 1.4518 - val_loss: 11.3547 - val_mae: 2.2494\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.9127 - mae: 1.4521 - val_loss: 11.5410 - val_mae: 2.2785\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8538 - mae: 1.4407 - val_loss: 11.5496 - val_mae: 2.2801\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.8280 - mae: 1.4305 - val_loss: 11.6154 - val_mae: 2.2804\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.8522 - mae: 1.4407 - val_loss: 11.8014 - val_mae: 2.3110\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.8358 - mae: 1.4541 - val_loss: 11.7716 - val_mae: 2.2887\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.9227 - mae: 1.4376 - val_loss: 11.5742 - val_mae: 2.2763\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.1948 - mae: 1.5436 - val_loss: 11.8983 - val_mae: 2.3048\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4.0570 - mae: 1.4940 - val_loss: 11.5190 - val_mae: 2.2713\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.8748 - mae: 1.4560 - val_loss: 12.1494 - val_mae: 2.3451\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 11.1336 - mae: 2.3436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(mae_list) # 2.16 → 실제 집값과 2,160달러 차이"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIMEopOdT_0J",
        "outputId": "1d57ed5e-0aff-4835-f4cc-e820b7c0a9b8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.1690933108329773"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5-Fold 사용한 모델의 성능 평가"
      ],
      "metadata": {
        "id": "gJIz8TdXUEk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets.boston_housing import load_data\n",
        "import numpy as np\n",
        "\n",
        "# 데이터 다운로드 (훈련셋 80 : 테스트셋 20)\n",
        "(X_train, y_train), (X_test, y_test) = load_data(path = 'boston_housing.npz',\n",
        "                                                 test_split = 0.2,\n",
        "                                                 seed = 777)\n",
        "\n",
        "# 표준화 : (데이터 - 전체 평균) / 표준편차\n",
        "mean = np.mean(X_train, axis = 0) # 모든 데이터의 평균을 구해야 하기 때문에, axis는 0\n",
        "std = np.std(X_train, axis = 0)\n",
        "\n",
        "# X_train을 전처리했기 때문에, X_test도 전처리해 줘야 함\n",
        "# 전처리에서는 X_train과 X_test 둘 다 처리\n",
        "# 만약 처음부터 데이터가 합쳐진 상태에서 받아왔다면, 전처리 이후에 X_train과 X_test로 분리하는 게 더 편리함\n",
        "\n",
        "X_train = (X_train - mean) / std\n",
        "X_test = (X_test - mean) / std\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# 몇 번에 나눠서 학습할 것인지 k를 지정해 줘야 함\n",
        "# 5-Fold로 나눠서 검증 데이터셋 사용하여 학습\n",
        "k = 5\n",
        "\n",
        "kfold = KFold(n_splits = k) # n_splits : 몇 개로 나눠서 학습할지\n",
        "\n",
        "# 재사용을 위해 모델 구성 및 설정 함수로 선언\n",
        "\n",
        "def get_model() :\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(64, activation = 'relu', input_shape = (13, )))\n",
        "  model.add(Dense(32, activation = 'relu'))\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# 각 모델(5개의 KFold)의 평가 정보 담는 리스트 선언\n",
        "mae_list = []\n",
        "\n",
        "# k번 학습 및 평가\n",
        "for train_idx, val_idx in kfold.split(X_train) :\n",
        "  # 각각의 fold를 만드는 과정 : 학습 데이터와 검증 데이터 분리\n",
        "  X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
        "  y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "  # 모델 불러오기\n",
        "  model = get_model()\n",
        "\n",
        "  # 모델 학습하기 → 총 5번(1500) 학습될 것\n",
        "  model.fit(X_train_fold, y_train_fold,\n",
        "            epochs = 300, validation_data = (X_val_fold, y_val_fold))\n",
        "\n",
        "  # 모델 평가하기\n",
        "  _, test_mae = model.evaluate(X_test, y_test) # _, : 첫 번째 평가 결과인 loss는 사용 안 한다는 의미\n",
        "  mae_list.append(test_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T9zS4afUE5d",
        "outputId": "ea4dbafd-60cb-4ce1-dc99-bdf77d239fe5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "11/11 [==============================] - 1s 31ms/step - loss: 557.8240 - mae: 21.7721 - val_loss: 508.4019 - val_mae: 20.9598\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 527.2465 - mae: 21.0775 - val_loss: 478.2325 - val_mae: 20.2474\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 491.8167 - mae: 20.2669 - val_loss: 441.5884 - val_mae: 19.3512\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 447.6986 - mae: 19.2201 - val_loss: 395.6785 - val_mae: 18.1604\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 394.2391 - mae: 17.8320 - val_loss: 337.9319 - val_mae: 16.5697\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 325.9955 - mae: 15.9942 - val_loss: 269.6306 - val_mae: 14.4645\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 247.4502 - mae: 13.6406 - val_loss: 200.0167 - val_mae: 11.9047\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 174.7334 - mae: 10.9039 - val_loss: 139.1249 - val_mae: 9.4342\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 118.8184 - mae: 8.6278 - val_loss: 101.4704 - val_mae: 7.7260\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 87.7687 - mae: 7.2419 - val_loss: 79.7693 - val_mae: 6.6439\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 69.8248 - mae: 6.4513 - val_loss: 65.4153 - val_mae: 5.8663\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 56.3898 - mae: 5.7669 - val_loss: 55.1282 - val_mae: 5.3011\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 46.7546 - mae: 5.2177 - val_loss: 46.9706 - val_mae: 4.7748\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 39.6167 - mae: 4.7160 - val_loss: 40.6485 - val_mae: 4.2759\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 34.3470 - mae: 4.3445 - val_loss: 36.3897 - val_mae: 4.0638\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 30.3698 - mae: 4.0905 - val_loss: 33.2881 - val_mae: 3.9597\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 27.9314 - mae: 3.8960 - val_loss: 31.1697 - val_mae: 3.8193\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 26.0760 - mae: 3.7177 - val_loss: 29.7653 - val_mae: 3.7189\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 24.5551 - mae: 3.5623 - val_loss: 28.8829 - val_mae: 3.6617\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 23.3292 - mae: 3.4340 - val_loss: 28.4477 - val_mae: 3.6051\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 22.4532 - mae: 3.3419 - val_loss: 28.2180 - val_mae: 3.6128\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 21.6755 - mae: 3.2735 - val_loss: 27.8562 - val_mae: 3.5864\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 21.0895 - mae: 3.2026 - val_loss: 27.5995 - val_mae: 3.5811\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 20.3541 - mae: 3.1483 - val_loss: 27.2055 - val_mae: 3.5847\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 19.8782 - mae: 3.1059 - val_loss: 27.0162 - val_mae: 3.5896\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 19.3960 - mae: 3.0612 - val_loss: 26.3964 - val_mae: 3.5687\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 18.8356 - mae: 3.0190 - val_loss: 26.0814 - val_mae: 3.5625\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 18.3905 - mae: 2.9819 - val_loss: 25.8268 - val_mae: 3.5493\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 18.1096 - mae: 2.9728 - val_loss: 25.9877 - val_mae: 3.5710\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 17.6741 - mae: 2.9128 - val_loss: 25.4978 - val_mae: 3.5260\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 17.1836 - mae: 2.8457 - val_loss: 24.7803 - val_mae: 3.4604\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.9974 - mae: 2.8292 - val_loss: 24.4111 - val_mae: 3.4601\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 16.5967 - mae: 2.7912 - val_loss: 24.5387 - val_mae: 3.4864\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 16.2725 - mae: 2.7628 - val_loss: 24.6405 - val_mae: 3.4709\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 15.9113 - mae: 2.7043 - val_loss: 24.1468 - val_mae: 3.4334\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 15.6063 - mae: 2.6792 - val_loss: 23.9175 - val_mae: 3.4402\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 15.2905 - mae: 2.6497 - val_loss: 23.9043 - val_mae: 3.4526\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 14.9318 - mae: 2.6213 - val_loss: 23.6185 - val_mae: 3.4569\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 14.8089 - mae: 2.6174 - val_loss: 23.1341 - val_mae: 3.4486\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.4839 - mae: 2.5875 - val_loss: 22.8404 - val_mae: 3.3843\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.3211 - mae: 2.5628 - val_loss: 22.8498 - val_mae: 3.3973\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.0410 - mae: 2.5156 - val_loss: 23.3054 - val_mae: 3.4159\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.8649 - mae: 2.4978 - val_loss: 22.9592 - val_mae: 3.4035\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 13.5851 - mae: 2.4738 - val_loss: 22.3814 - val_mae: 3.3733\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.5184 - mae: 2.4722 - val_loss: 22.0774 - val_mae: 3.3852\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.2076 - mae: 2.4531 - val_loss: 22.0669 - val_mae: 3.3747\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.0150 - mae: 2.4242 - val_loss: 22.1073 - val_mae: 3.3538\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.8609 - mae: 2.4002 - val_loss: 22.1775 - val_mae: 3.3740\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.7311 - mae: 2.4097 - val_loss: 21.9304 - val_mae: 3.3726\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.6017 - mae: 2.4001 - val_loss: 21.6976 - val_mae: 3.3468\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.4737 - mae: 2.3815 - val_loss: 21.8192 - val_mae: 3.3420\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.2983 - mae: 2.3557 - val_loss: 21.6605 - val_mae: 3.3339\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.1721 - mae: 2.3438 - val_loss: 21.5420 - val_mae: 3.3300\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.0112 - mae: 2.3271 - val_loss: 21.4356 - val_mae: 3.3291\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.9280 - mae: 2.3372 - val_loss: 21.3675 - val_mae: 3.3356\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.7849 - mae: 2.3282 - val_loss: 21.0951 - val_mae: 3.3211\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.7422 - mae: 2.3266 - val_loss: 21.3099 - val_mae: 3.3370\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.6374 - mae: 2.3164 - val_loss: 20.9432 - val_mae: 3.3116\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.4542 - mae: 2.2868 - val_loss: 20.8663 - val_mae: 3.2939\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.3908 - mae: 2.2908 - val_loss: 20.8503 - val_mae: 3.3068\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.2425 - mae: 2.2738 - val_loss: 20.5618 - val_mae: 3.2672\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.1675 - mae: 2.2592 - val_loss: 20.6007 - val_mae: 3.2766\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.0568 - mae: 2.2529 - val_loss: 20.4740 - val_mae: 3.2729\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.9881 - mae: 2.2560 - val_loss: 20.2074 - val_mae: 3.2528\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.9174 - mae: 2.2496 - val_loss: 20.2627 - val_mae: 3.2452\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.8084 - mae: 2.2262 - val_loss: 20.3259 - val_mae: 3.2485\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.8060 - mae: 2.2265 - val_loss: 20.1726 - val_mae: 3.2625\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.6602 - mae: 2.2150 - val_loss: 19.9685 - val_mae: 3.2262\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.6006 - mae: 2.2050 - val_loss: 20.3057 - val_mae: 3.2746\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.4974 - mae: 2.2204 - val_loss: 20.0113 - val_mae: 3.2670\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.4994 - mae: 2.2254 - val_loss: 19.6308 - val_mae: 3.2373\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.3034 - mae: 2.1829 - val_loss: 20.0503 - val_mae: 3.2089\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.5502 - mae: 2.1871 - val_loss: 20.0439 - val_mae: 3.2009\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.2348 - mae: 2.1484 - val_loss: 19.2528 - val_mae: 3.1671\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.2968 - mae: 2.1952 - val_loss: 19.1475 - val_mae: 3.1939\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.1018 - mae: 2.1767 - val_loss: 19.4268 - val_mae: 3.1873\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.0808 - mae: 2.1707 - val_loss: 19.3909 - val_mae: 3.2028\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.0179 - mae: 2.1765 - val_loss: 19.9475 - val_mae: 3.2436\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.9555 - mae: 2.1732 - val_loss: 19.2603 - val_mae: 3.1732\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.8508 - mae: 2.1454 - val_loss: 19.1685 - val_mae: 3.1600\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.7297 - mae: 2.1318 - val_loss: 19.4835 - val_mae: 3.1975\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.6843 - mae: 2.1345 - val_loss: 19.3107 - val_mae: 3.1741\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.6130 - mae: 2.1234 - val_loss: 19.0244 - val_mae: 3.1525\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.6130 - mae: 2.1222 - val_loss: 18.9952 - val_mae: 3.1654\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.6637 - mae: 2.1318 - val_loss: 19.6172 - val_mae: 3.2339\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.5646 - mae: 2.1141 - val_loss: 18.9502 - val_mae: 3.1613\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.4534 - mae: 2.1076 - val_loss: 19.2204 - val_mae: 3.1592\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.4286 - mae: 2.0951 - val_loss: 18.9573 - val_mae: 3.1030\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.3353 - mae: 2.0907 - val_loss: 18.8481 - val_mae: 3.1248\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.2644 - mae: 2.0945 - val_loss: 18.7662 - val_mae: 3.1533\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.2909 - mae: 2.1230 - val_loss: 18.9373 - val_mae: 3.1765\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.1187 - mae: 2.0765 - val_loss: 18.6221 - val_mae: 3.1255\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.0802 - mae: 2.0728 - val_loss: 18.8425 - val_mae: 3.1531\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.0554 - mae: 2.0649 - val_loss: 18.7481 - val_mae: 3.1500\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.0703 - mae: 2.0787 - val_loss: 18.8725 - val_mae: 3.1974\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.1759 - mae: 2.1074 - val_loss: 19.1814 - val_mae: 3.2091\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.0600 - mae: 2.0743 - val_loss: 18.7537 - val_mae: 3.1163\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.9778 - mae: 2.0537 - val_loss: 18.6920 - val_mae: 3.1485\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.0251 - mae: 2.0951 - val_loss: 18.5208 - val_mae: 3.1748\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.2852 - mae: 2.1383 - val_loss: 17.7405 - val_mae: 3.1048\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.9904 - mae: 2.0965 - val_loss: 18.2509 - val_mae: 3.1188\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.8396 - mae: 2.0693 - val_loss: 18.0580 - val_mae: 3.1431\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.8899 - mae: 2.0711 - val_loss: 18.2542 - val_mae: 3.1151\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.7149 - mae: 2.0522 - val_loss: 18.3997 - val_mae: 3.1276\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.6026 - mae: 2.0279 - val_loss: 18.0788 - val_mae: 3.0870\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.4779 - mae: 2.0241 - val_loss: 18.3316 - val_mae: 3.1688\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.3926 - mae: 2.0112 - val_loss: 18.0515 - val_mae: 3.0843\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.3733 - mae: 2.0171 - val_loss: 18.1872 - val_mae: 3.1118\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.2866 - mae: 2.0113 - val_loss: 17.9949 - val_mae: 3.0940\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.2382 - mae: 1.9962 - val_loss: 17.9462 - val_mae: 3.0842\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.1942 - mae: 1.9870 - val_loss: 18.2142 - val_mae: 3.1057\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.1591 - mae: 1.9872 - val_loss: 18.0740 - val_mae: 3.0761\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.1648 - mae: 1.9914 - val_loss: 18.0024 - val_mae: 3.0959\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.1182 - mae: 1.9942 - val_loss: 18.1168 - val_mae: 3.1009\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.0447 - mae: 1.9784 - val_loss: 18.1646 - val_mae: 3.0966\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.0866 - mae: 1.9669 - val_loss: 17.7135 - val_mae: 3.0566\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.1779 - mae: 1.9767 - val_loss: 17.5162 - val_mae: 3.0130\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.9334 - mae: 1.9579 - val_loss: 17.8449 - val_mae: 3.0707\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.8942 - mae: 1.9719 - val_loss: 17.4545 - val_mae: 3.0520\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.0908 - mae: 2.0125 - val_loss: 16.8109 - val_mae: 3.0265\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.2219 - mae: 2.0070 - val_loss: 17.1270 - val_mae: 3.0209\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.9163 - mae: 1.9630 - val_loss: 17.9285 - val_mae: 3.0634\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8288 - mae: 1.9713 - val_loss: 17.5244 - val_mae: 3.0499\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.7099 - mae: 1.9546 - val_loss: 17.2952 - val_mae: 3.0431\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.7023 - mae: 1.9458 - val_loss: 17.7151 - val_mae: 3.0255\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6979 - mae: 1.9274 - val_loss: 17.5360 - val_mae: 3.0262\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.5267 - mae: 1.9277 - val_loss: 17.2912 - val_mae: 3.0338\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.5605 - mae: 1.9383 - val_loss: 17.4342 - val_mae: 3.0732\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.4493 - mae: 1.9204 - val_loss: 17.4617 - val_mae: 3.0459\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.4418 - mae: 1.9036 - val_loss: 17.2468 - val_mae: 2.9892\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.4046 - mae: 1.9033 - val_loss: 17.3263 - val_mae: 3.0215\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.2810 - mae: 1.8964 - val_loss: 17.0931 - val_mae: 3.0069\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.5013 - mae: 1.9277 - val_loss: 16.9172 - val_mae: 2.9870\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.2720 - mae: 1.8880 - val_loss: 17.3210 - val_mae: 3.0061\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.2737 - mae: 1.8928 - val_loss: 17.4081 - val_mae: 3.0247\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.2452 - mae: 1.9104 - val_loss: 16.9489 - val_mae: 3.0100\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.1158 - mae: 1.8753 - val_loss: 16.7263 - val_mae: 2.9853\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.1225 - mae: 1.8718 - val_loss: 16.8101 - val_mae: 3.0034\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.1657 - mae: 1.8978 - val_loss: 17.0910 - val_mae: 3.0423\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.0327 - mae: 1.8647 - val_loss: 16.2562 - val_mae: 2.9500\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.1544 - mae: 1.8763 - val_loss: 16.5532 - val_mae: 2.9731\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.1115 - mae: 1.8871 - val_loss: 16.9254 - val_mae: 2.9986\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.9515 - mae: 1.8660 - val_loss: 16.6340 - val_mae: 2.9556\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.8469 - mae: 1.8436 - val_loss: 16.3295 - val_mae: 2.9832\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.0357 - mae: 1.8978 - val_loss: 16.4855 - val_mae: 2.9970\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.8662 - mae: 1.8569 - val_loss: 16.3774 - val_mae: 2.9523\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.8562 - mae: 1.8505 - val_loss: 16.0567 - val_mae: 2.9430\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7804 - mae: 1.8433 - val_loss: 16.4057 - val_mae: 2.9652\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7483 - mae: 1.8565 - val_loss: 16.4728 - val_mae: 2.9771\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7024 - mae: 1.8485 - val_loss: 16.3359 - val_mae: 2.9392\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6343 - mae: 1.8272 - val_loss: 16.3283 - val_mae: 2.9578\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7259 - mae: 1.8823 - val_loss: 15.7844 - val_mae: 2.9432\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.1264 - mae: 1.9148 - val_loss: 15.9682 - val_mae: 2.9296\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7541 - mae: 1.8479 - val_loss: 16.3944 - val_mae: 2.9401\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7940 - mae: 1.8438 - val_loss: 17.0024 - val_mae: 2.9560\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7005 - mae: 1.8631 - val_loss: 16.4945 - val_mae: 2.9391\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5504 - mae: 1.8455 - val_loss: 16.1819 - val_mae: 2.9049\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.5374 - mae: 1.8482 - val_loss: 16.2575 - val_mae: 2.9468\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.4008 - mae: 1.8134 - val_loss: 15.9816 - val_mae: 2.8965\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.3638 - mae: 1.7976 - val_loss: 16.2309 - val_mae: 2.9385\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.6427 - mae: 1.9027 - val_loss: 16.7662 - val_mae: 3.0348\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.3576 - mae: 1.8211 - val_loss: 16.3310 - val_mae: 2.9118\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.2996 - mae: 1.7999 - val_loss: 16.1847 - val_mae: 2.9303\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.2940 - mae: 1.8172 - val_loss: 16.0188 - val_mae: 2.9253\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.2116 - mae: 1.7970 - val_loss: 15.9946 - val_mae: 2.9052\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.2225 - mae: 1.8130 - val_loss: 16.3910 - val_mae: 2.9852\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.2584 - mae: 1.8157 - val_loss: 16.1527 - val_mae: 2.9389\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.1739 - mae: 1.8034 - val_loss: 15.9826 - val_mae: 2.9089\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.0687 - mae: 1.7716 - val_loss: 16.2535 - val_mae: 2.9146\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.2148 - mae: 1.7884 - val_loss: 16.0395 - val_mae: 2.8897\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.3116 - mae: 1.8495 - val_loss: 15.6331 - val_mae: 2.8704\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.2795 - mae: 1.8339 - val_loss: 16.1010 - val_mae: 2.9220\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.1193 - mae: 1.8173 - val_loss: 16.2326 - val_mae: 2.9261\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.0060 - mae: 1.7725 - val_loss: 15.7102 - val_mae: 2.8552\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.9729 - mae: 1.7618 - val_loss: 15.6355 - val_mae: 2.8572\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.9487 - mae: 1.7866 - val_loss: 15.7113 - val_mae: 2.9013\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.8965 - mae: 1.7837 - val_loss: 15.4859 - val_mae: 2.8392\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.9167 - mae: 1.7645 - val_loss: 15.6901 - val_mae: 2.8506\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.8110 - mae: 1.7545 - val_loss: 15.8802 - val_mae: 2.8911\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.9304 - mae: 1.7877 - val_loss: 15.4334 - val_mae: 2.8542\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.8015 - mae: 1.7518 - val_loss: 15.8424 - val_mae: 2.8788\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.8559 - mae: 1.7531 - val_loss: 15.8442 - val_mae: 2.8683\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.7375 - mae: 1.7316 - val_loss: 15.5069 - val_mae: 2.8345\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.8376 - mae: 1.7778 - val_loss: 15.6579 - val_mae: 2.8717\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.8627 - mae: 1.7794 - val_loss: 15.6079 - val_mae: 2.8259\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.8342 - mae: 1.7600 - val_loss: 15.5821 - val_mae: 2.8378\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.6278 - mae: 1.7373 - val_loss: 15.5349 - val_mae: 2.8132\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.6592 - mae: 1.7213 - val_loss: 15.5006 - val_mae: 2.7996\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.7404 - mae: 1.7428 - val_loss: 15.2881 - val_mae: 2.8041\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.9183 - mae: 1.7446 - val_loss: 16.1584 - val_mae: 2.8275\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7576 - mae: 1.7529 - val_loss: 15.7390 - val_mae: 2.8979\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.3825 - mae: 1.9486 - val_loss: 15.9252 - val_mae: 2.9532\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.8052 - mae: 1.7822 - val_loss: 15.3806 - val_mae: 2.7956\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7655 - mae: 1.7529 - val_loss: 15.5210 - val_mae: 2.8158\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.5095 - mae: 1.7490 - val_loss: 15.5779 - val_mae: 2.8602\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.4518 - mae: 1.7438 - val_loss: 15.4880 - val_mae: 2.8126\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.4260 - mae: 1.6953 - val_loss: 15.8040 - val_mae: 2.8092\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.5231 - mae: 1.7208 - val_loss: 15.5596 - val_mae: 2.8598\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.6211 - mae: 1.7625 - val_loss: 15.1226 - val_mae: 2.7793\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.3836 - mae: 1.7039 - val_loss: 15.9560 - val_mae: 2.8404\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.3694 - mae: 1.7290 - val_loss: 15.2846 - val_mae: 2.7840\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.3430 - mae: 1.7099 - val_loss: 15.1131 - val_mae: 2.7740\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2602 - mae: 1.6779 - val_loss: 15.5387 - val_mae: 2.8339\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2428 - mae: 1.6760 - val_loss: 15.1973 - val_mae: 2.7882\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.2516 - mae: 1.6798 - val_loss: 14.9679 - val_mae: 2.7682\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1804 - mae: 1.6733 - val_loss: 15.4176 - val_mae: 2.8151\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1710 - mae: 1.6576 - val_loss: 15.3913 - val_mae: 2.7768\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.0833 - mae: 1.6610 - val_loss: 15.2793 - val_mae: 2.7967\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.2285 - mae: 1.6903 - val_loss: 15.4099 - val_mae: 2.7878\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.1530 - mae: 1.6773 - val_loss: 15.3170 - val_mae: 2.8113\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2340 - mae: 1.6980 - val_loss: 15.0483 - val_mae: 2.7474\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1352 - mae: 1.6924 - val_loss: 15.4585 - val_mae: 2.8477\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0351 - mae: 1.6692 - val_loss: 14.9931 - val_mae: 2.7547\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9973 - mae: 1.6438 - val_loss: 15.2036 - val_mae: 2.7681\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.9617 - mae: 1.6314 - val_loss: 15.2145 - val_mae: 2.7708\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.9175 - mae: 1.6316 - val_loss: 14.9560 - val_mae: 2.7354\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.9140 - mae: 1.6350 - val_loss: 15.0312 - val_mae: 2.7692\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8843 - mae: 1.6375 - val_loss: 15.1517 - val_mae: 2.7889\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8618 - mae: 1.6384 - val_loss: 14.9245 - val_mae: 2.7389\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8274 - mae: 1.6230 - val_loss: 14.8380 - val_mae: 2.7293\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.8114 - mae: 1.6167 - val_loss: 14.8963 - val_mae: 2.7306\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.8591 - mae: 1.6361 - val_loss: 14.7775 - val_mae: 2.7294\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9068 - mae: 1.6319 - val_loss: 14.7921 - val_mae: 2.7145\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8835 - mae: 1.6475 - val_loss: 15.0965 - val_mae: 2.8003\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.7677 - mae: 1.6113 - val_loss: 14.5382 - val_mae: 2.7208\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.7935 - mae: 1.6005 - val_loss: 14.8631 - val_mae: 2.7322\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7832 - mae: 1.5912 - val_loss: 14.9925 - val_mae: 2.7483\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.7412 - mae: 1.6071 - val_loss: 14.3794 - val_mae: 2.7038\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7304 - mae: 1.6052 - val_loss: 14.5913 - val_mae: 2.6688\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.7649 - mae: 1.6132 - val_loss: 14.5161 - val_mae: 2.6608\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7292 - mae: 1.6163 - val_loss: 14.0893 - val_mae: 2.6308\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6629 - mae: 1.5946 - val_loss: 14.1985 - val_mae: 2.6400\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6601 - mae: 1.5940 - val_loss: 14.4134 - val_mae: 2.6824\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6225 - mae: 1.6205 - val_loss: 14.6294 - val_mae: 2.7219\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.5299 - mae: 1.5748 - val_loss: 14.4205 - val_mae: 2.6619\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5829 - mae: 1.5713 - val_loss: 14.4804 - val_mae: 2.6848\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.5544 - mae: 1.5653 - val_loss: 14.5612 - val_mae: 2.6847\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.5162 - mae: 1.5728 - val_loss: 14.2518 - val_mae: 2.6641\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7048 - mae: 1.5935 - val_loss: 14.5111 - val_mae: 2.6609\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5085 - mae: 1.5896 - val_loss: 14.6682 - val_mae: 2.7375\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4755 - mae: 1.5522 - val_loss: 14.4053 - val_mae: 2.6469\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.4403 - mae: 1.5522 - val_loss: 14.4503 - val_mae: 2.6982\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3665 - mae: 1.5510 - val_loss: 14.2265 - val_mae: 2.6757\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3634 - mae: 1.5581 - val_loss: 14.1327 - val_mae: 2.6638\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.4444 - mae: 1.5647 - val_loss: 14.5641 - val_mae: 2.7042\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.4049 - mae: 1.5740 - val_loss: 14.3367 - val_mae: 2.7120\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2898 - mae: 1.5396 - val_loss: 14.6024 - val_mae: 2.6987\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3096 - mae: 1.5418 - val_loss: 14.4676 - val_mae: 2.6793\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.2612 - mae: 1.5364 - val_loss: 14.3991 - val_mae: 2.6993\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2648 - mae: 1.5230 - val_loss: 13.9902 - val_mae: 2.6317\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2247 - mae: 1.5208 - val_loss: 14.3857 - val_mae: 2.7102\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.3076 - mae: 1.5369 - val_loss: 14.3108 - val_mae: 2.6626\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2115 - mae: 1.5192 - val_loss: 14.2345 - val_mae: 2.6802\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.2654 - mae: 1.5276 - val_loss: 14.0500 - val_mae: 2.6329\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.1732 - mae: 1.5191 - val_loss: 14.3387 - val_mae: 2.7274\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.4578 - mae: 1.5891 - val_loss: 14.1410 - val_mae: 2.7020\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3425 - mae: 1.5424 - val_loss: 14.6314 - val_mae: 2.6523\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.3770 - mae: 1.5674 - val_loss: 14.3680 - val_mae: 2.7223\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4833 - mae: 1.5554 - val_loss: 14.5441 - val_mae: 2.6489\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1840 - mae: 1.5299 - val_loss: 14.2703 - val_mae: 2.7035\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7326 - mae: 1.6402 - val_loss: 13.6568 - val_mae: 2.6229\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.4394 - mae: 1.5533 - val_loss: 14.8309 - val_mae: 2.6625\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3227 - mae: 1.5509 - val_loss: 14.7021 - val_mae: 2.7042\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0559 - mae: 1.4960 - val_loss: 14.3159 - val_mae: 2.6541\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9953 - mae: 1.4839 - val_loss: 14.5086 - val_mae: 2.6738\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9819 - mae: 1.4807 - val_loss: 14.5777 - val_mae: 2.6982\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.0032 - mae: 1.4741 - val_loss: 14.3145 - val_mae: 2.6583\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9629 - mae: 1.4695 - val_loss: 14.4480 - val_mae: 2.6838\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9680 - mae: 1.4706 - val_loss: 14.2465 - val_mae: 2.6787\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8790 - mae: 1.4598 - val_loss: 13.9742 - val_mae: 2.6314\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9043 - mae: 1.4667 - val_loss: 14.2826 - val_mae: 2.6539\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.9537 - mae: 1.4654 - val_loss: 14.2334 - val_mae: 2.6124\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.9001 - mae: 1.4590 - val_loss: 13.9991 - val_mae: 2.6309\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8588 - mae: 1.4676 - val_loss: 14.3699 - val_mae: 2.6656\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.9547 - mae: 1.4576 - val_loss: 14.4806 - val_mae: 2.6103\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9081 - mae: 1.4660 - val_loss: 14.1294 - val_mae: 2.6073\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.8648 - mae: 1.4633 - val_loss: 14.2845 - val_mae: 2.6383\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.8192 - mae: 1.4511 - val_loss: 14.2592 - val_mae: 2.6435\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.8003 - mae: 1.4383 - val_loss: 14.1470 - val_mae: 2.6536\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.8419 - mae: 1.4721 - val_loss: 14.1693 - val_mae: 2.6532\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8898 - mae: 1.4504 - val_loss: 14.1415 - val_mae: 2.5994\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.7307 - mae: 1.4177 - val_loss: 14.0475 - val_mae: 2.6321\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7498 - mae: 1.4481 - val_loss: 13.8100 - val_mae: 2.6157\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.6900 - mae: 1.4307 - val_loss: 14.0731 - val_mae: 2.6563\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.7161 - mae: 1.4239 - val_loss: 14.0123 - val_mae: 2.6114\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7824 - mae: 1.4543 - val_loss: 13.8534 - val_mae: 2.6348\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.7794 - mae: 1.4599 - val_loss: 14.4075 - val_mae: 2.7151\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.7138 - mae: 1.4286 - val_loss: 13.7226 - val_mae: 2.5962\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.6507 - mae: 1.4213 - val_loss: 14.2488 - val_mae: 2.6781\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.6654 - mae: 1.4235 - val_loss: 13.9089 - val_mae: 2.6390\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.5989 - mae: 1.4192 - val_loss: 14.0827 - val_mae: 2.7027\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8304 - mae: 1.4798 - val_loss: 14.1248 - val_mae: 2.7174\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.7373 - mae: 1.4307 - val_loss: 13.9018 - val_mae: 2.6445\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.6287 - mae: 1.4213 - val_loss: 14.1876 - val_mae: 2.6965\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.5959 - mae: 1.4194 - val_loss: 14.0061 - val_mae: 2.6453\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.5474 - mae: 1.3964 - val_loss: 13.9821 - val_mae: 2.6424\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.5360 - mae: 1.3996 - val_loss: 13.6801 - val_mae: 2.5726\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.5723 - mae: 1.4013 - val_loss: 13.6316 - val_mae: 2.5915\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.5259 - mae: 1.3878 - val_loss: 13.7529 - val_mae: 2.6001\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.5076 - mae: 1.3940 - val_loss: 13.9664 - val_mae: 2.6423\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.2494 - mae: 2.0825\n",
            "Epoch 1/300\n",
            "11/11 [==============================] - 1s 22ms/step - loss: 537.0628 - mae: 21.3651 - val_loss: 607.4370 - val_mae: 22.4115\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 502.8681 - mae: 20.5378 - val_loss: 566.6036 - val_mae: 21.4918\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 466.5146 - mae: 19.6246 - val_loss: 519.0409 - val_mae: 20.3912\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 422.2570 - mae: 18.4858 - val_loss: 462.2833 - val_mae: 18.9926\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 369.1256 - mae: 17.0841 - val_loss: 392.0049 - val_mae: 17.1941\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 303.5674 - mae: 15.2799 - val_loss: 309.7764 - val_mae: 14.9266\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 232.5089 - mae: 13.1379 - val_loss: 223.1216 - val_mae: 12.1741\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 164.9749 - mae: 10.6978 - val_loss: 149.7315 - val_mae: 9.4024\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 113.2953 - mae: 8.5218 - val_loss: 104.4852 - val_mae: 7.5334\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 85.6923 - mae: 7.1466 - val_loss: 78.2795 - val_mae: 6.4393\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 69.5697 - mae: 6.2769 - val_loss: 64.6289 - val_mae: 5.7573\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 59.2823 - mae: 5.7414 - val_loss: 55.4888 - val_mae: 5.3429\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 50.7621 - mae: 5.2435 - val_loss: 48.0924 - val_mae: 4.9496\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 43.4898 - mae: 4.8010 - val_loss: 41.7178 - val_mae: 4.5565\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 38.3189 - mae: 4.4335 - val_loss: 39.0097 - val_mae: 4.2865\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 34.6394 - mae: 4.1447 - val_loss: 36.8348 - val_mae: 4.0874\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 32.0309 - mae: 3.9564 - val_loss: 34.8263 - val_mae: 3.9536\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 30.1007 - mae: 3.8499 - val_loss: 32.1446 - val_mae: 3.8083\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.1089 - mae: 3.7384 - val_loss: 31.2484 - val_mae: 3.7169\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 26.6245 - mae: 3.5959 - val_loss: 30.8094 - val_mae: 3.6458\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 25.4393 - mae: 3.4880 - val_loss: 30.2008 - val_mae: 3.5751\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 24.4378 - mae: 3.4201 - val_loss: 28.8615 - val_mae: 3.4932\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 23.7501 - mae: 3.4324 - val_loss: 27.3384 - val_mae: 3.4595\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 22.8365 - mae: 3.3669 - val_loss: 27.4546 - val_mae: 3.3885\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 21.8624 - mae: 3.2330 - val_loss: 27.6371 - val_mae: 3.3608\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 21.2218 - mae: 3.1467 - val_loss: 27.1376 - val_mae: 3.3311\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 20.7651 - mae: 3.1782 - val_loss: 24.8152 - val_mae: 3.2640\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 19.8861 - mae: 3.1630 - val_loss: 24.6983 - val_mae: 3.2265\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 18.9700 - mae: 3.0481 - val_loss: 25.3244 - val_mae: 3.2289\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 18.4263 - mae: 2.9519 - val_loss: 26.3185 - val_mae: 3.2593\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 18.0758 - mae: 2.8881 - val_loss: 25.8919 - val_mae: 3.2261\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.6544 - mae: 2.8768 - val_loss: 24.1315 - val_mae: 3.1344\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 17.1075 - mae: 2.8624 - val_loss: 23.7388 - val_mae: 3.1008\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 16.6386 - mae: 2.8200 - val_loss: 23.7350 - val_mae: 3.0862\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.3410 - mae: 2.7554 - val_loss: 23.9682 - val_mae: 3.0848\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 16.1987 - mae: 2.7616 - val_loss: 22.6440 - val_mae: 3.0181\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 15.9468 - mae: 2.7642 - val_loss: 22.6779 - val_mae: 2.9811\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.3466 - mae: 2.7090 - val_loss: 22.2577 - val_mae: 2.9598\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.9856 - mae: 2.6760 - val_loss: 22.1394 - val_mae: 2.9598\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 14.7512 - mae: 2.6369 - val_loss: 22.8026 - val_mae: 2.9682\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.3933 - mae: 2.5978 - val_loss: 22.6306 - val_mae: 2.9546\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.1469 - mae: 2.5734 - val_loss: 22.6559 - val_mae: 2.9563\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 13.9859 - mae: 2.5677 - val_loss: 21.7851 - val_mae: 2.9169\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.7192 - mae: 2.5686 - val_loss: 20.8410 - val_mae: 2.8708\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.4667 - mae: 2.5497 - val_loss: 20.7896 - val_mae: 2.8623\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 13.2618 - mae: 2.5195 - val_loss: 20.6088 - val_mae: 2.8443\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.0618 - mae: 2.4996 - val_loss: 20.7774 - val_mae: 2.8515\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.9453 - mae: 2.4831 - val_loss: 20.4931 - val_mae: 2.8407\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.7488 - mae: 2.4823 - val_loss: 19.8668 - val_mae: 2.8132\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.5714 - mae: 2.4662 - val_loss: 20.3543 - val_mae: 2.8308\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.4381 - mae: 2.4555 - val_loss: 19.5809 - val_mae: 2.8069\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.1729 - mae: 2.4499 - val_loss: 19.3755 - val_mae: 2.8024\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.1302 - mae: 2.4337 - val_loss: 19.5664 - val_mae: 2.7949\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.9423 - mae: 2.4169 - val_loss: 19.4043 - val_mae: 2.7868\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.8574 - mae: 2.4233 - val_loss: 18.5662 - val_mae: 2.7613\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.7268 - mae: 2.4380 - val_loss: 18.3000 - val_mae: 2.7496\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.5197 - mae: 2.4163 - val_loss: 19.1873 - val_mae: 2.7780\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.4834 - mae: 2.3915 - val_loss: 19.4289 - val_mae: 2.7839\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.5620 - mae: 2.4028 - val_loss: 18.2356 - val_mae: 2.7216\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.1951 - mae: 2.3810 - val_loss: 18.5844 - val_mae: 2.7479\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.3132 - mae: 2.3592 - val_loss: 18.8987 - val_mae: 2.7601\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.1704 - mae: 2.3573 - val_loss: 17.9958 - val_mae: 2.7059\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.0575 - mae: 2.3430 - val_loss: 18.1497 - val_mae: 2.7136\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.1416 - mae: 2.3672 - val_loss: 17.2995 - val_mae: 2.6946\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.8326 - mae: 2.3434 - val_loss: 17.7636 - val_mae: 2.7040\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.7488 - mae: 2.3237 - val_loss: 17.7666 - val_mae: 2.6979\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.6244 - mae: 2.3209 - val_loss: 17.1136 - val_mae: 2.6555\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.5401 - mae: 2.3260 - val_loss: 17.2492 - val_mae: 2.6564\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.4853 - mae: 2.3138 - val_loss: 17.4398 - val_mae: 2.6767\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.4738 - mae: 2.3193 - val_loss: 16.8864 - val_mae: 2.6610\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.3404 - mae: 2.3036 - val_loss: 17.1794 - val_mae: 2.6677\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.3528 - mae: 2.2912 - val_loss: 17.9671 - val_mae: 2.7008\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.2456 - mae: 2.2898 - val_loss: 17.5066 - val_mae: 2.6753\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.3564 - mae: 2.3046 - val_loss: 16.5835 - val_mae: 2.6534\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.1458 - mae: 2.2661 - val_loss: 16.8358 - val_mae: 2.6614\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.1129 - mae: 2.2646 - val_loss: 17.3775 - val_mae: 2.7007\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.9990 - mae: 2.2580 - val_loss: 17.0367 - val_mae: 2.6660\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.0811 - mae: 2.2621 - val_loss: 17.2112 - val_mae: 2.6397\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.9594 - mae: 2.2410 - val_loss: 16.8149 - val_mae: 2.6509\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.7904 - mae: 2.2227 - val_loss: 16.7685 - val_mae: 2.6380\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.0519 - mae: 2.2942 - val_loss: 16.8306 - val_mae: 2.6716\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.6436 - mae: 2.2227 - val_loss: 17.1467 - val_mae: 2.6791\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.6919 - mae: 2.2218 - val_loss: 16.7361 - val_mae: 2.6458\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.6040 - mae: 2.2113 - val_loss: 16.6601 - val_mae: 2.6551\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.5545 - mae: 2.2065 - val_loss: 15.9285 - val_mae: 2.5943\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9.7218 - mae: 2.2465 - val_loss: 15.7863 - val_mae: 2.5949\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.4477 - mae: 2.2046 - val_loss: 16.1897 - val_mae: 2.6112\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.3367 - mae: 2.1802 - val_loss: 16.3181 - val_mae: 2.6286\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.2717 - mae: 2.1795 - val_loss: 16.1851 - val_mae: 2.6294\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.2011 - mae: 2.1676 - val_loss: 16.3760 - val_mae: 2.6325\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.2761 - mae: 2.1790 - val_loss: 16.2342 - val_mae: 2.6386\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 9.2567 - mae: 2.1713 - val_loss: 16.6052 - val_mae: 2.6439\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9.2089 - mae: 2.1686 - val_loss: 15.9505 - val_mae: 2.6168\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.0617 - mae: 2.1462 - val_loss: 15.8700 - val_mae: 2.6095\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.1250 - mae: 2.1608 - val_loss: 15.4735 - val_mae: 2.5995\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.0770 - mae: 2.1499 - val_loss: 16.2175 - val_mae: 2.6088\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.1763 - mae: 2.1413 - val_loss: 15.8500 - val_mae: 2.5725\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.0734 - mae: 2.1418 - val_loss: 15.3474 - val_mae: 2.6023\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.8828 - mae: 2.1231 - val_loss: 15.4769 - val_mae: 2.5847\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.8404 - mae: 2.1245 - val_loss: 15.4121 - val_mae: 2.5933\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.8073 - mae: 2.1333 - val_loss: 15.2965 - val_mae: 2.5789\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.8904 - mae: 2.1362 - val_loss: 15.4644 - val_mae: 2.5566\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.8710 - mae: 2.1588 - val_loss: 15.5719 - val_mae: 2.6613\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.9071 - mae: 2.1620 - val_loss: 15.7576 - val_mae: 2.6366\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.7285 - mae: 2.1327 - val_loss: 16.2884 - val_mae: 2.6212\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.6449 - mae: 2.1069 - val_loss: 15.2905 - val_mae: 2.5922\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.0111 - mae: 2.1875 - val_loss: 13.8494 - val_mae: 2.5940\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.9834 - mae: 2.1651 - val_loss: 14.1854 - val_mae: 2.5506\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.8473 - mae: 2.1366 - val_loss: 14.2939 - val_mae: 2.5735\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.5871 - mae: 2.1176 - val_loss: 14.5895 - val_mae: 2.5768\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.4042 - mae: 2.0952 - val_loss: 14.5832 - val_mae: 2.5584\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.6054 - mae: 2.1330 - val_loss: 14.6334 - val_mae: 2.5754\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.3220 - mae: 2.0837 - val_loss: 15.2032 - val_mae: 2.5854\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.2789 - mae: 2.0783 - val_loss: 14.7533 - val_mae: 2.5656\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.2179 - mae: 2.0711 - val_loss: 14.8723 - val_mae: 2.5702\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8.2099 - mae: 2.0671 - val_loss: 14.6178 - val_mae: 2.5505\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.2255 - mae: 2.0948 - val_loss: 14.4057 - val_mae: 2.5705\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.1494 - mae: 2.0602 - val_loss: 14.8496 - val_mae: 2.5913\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.0891 - mae: 2.0560 - val_loss: 14.8886 - val_mae: 2.5826\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.1744 - mae: 2.0803 - val_loss: 14.5968 - val_mae: 2.5633\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.9929 - mae: 2.0500 - val_loss: 14.8112 - val_mae: 2.5740\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.0184 - mae: 2.0461 - val_loss: 15.0860 - val_mae: 2.5783\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.9821 - mae: 2.0422 - val_loss: 14.9151 - val_mae: 2.5724\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.9080 - mae: 2.0423 - val_loss: 14.9097 - val_mae: 2.5837\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.8635 - mae: 2.0322 - val_loss: 15.0256 - val_mae: 2.5637\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.8687 - mae: 2.0220 - val_loss: 15.1025 - val_mae: 2.5686\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.8453 - mae: 2.0253 - val_loss: 14.8003 - val_mae: 2.5767\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.8304 - mae: 2.0403 - val_loss: 14.7848 - val_mae: 2.5909\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.7915 - mae: 2.0191 - val_loss: 15.1193 - val_mae: 2.5808\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.7896 - mae: 2.0298 - val_loss: 14.6498 - val_mae: 2.5642\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.7222 - mae: 2.0005 - val_loss: 15.2169 - val_mae: 2.5709\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.8739 - mae: 2.0366 - val_loss: 14.8120 - val_mae: 2.5778\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.8776 - mae: 2.0519 - val_loss: 14.6037 - val_mae: 2.6066\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.7027 - mae: 2.0150 - val_loss: 15.4090 - val_mae: 2.5775\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.8634 - mae: 2.0385 - val_loss: 15.4403 - val_mae: 2.6078\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.6913 - mae: 2.0054 - val_loss: 14.6008 - val_mae: 2.5519\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.5232 - mae: 1.9806 - val_loss: 14.7163 - val_mae: 2.5536\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.5202 - mae: 1.9878 - val_loss: 14.7348 - val_mae: 2.5551\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.4408 - mae: 1.9738 - val_loss: 14.9571 - val_mae: 2.5837\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.4085 - mae: 1.9742 - val_loss: 14.7643 - val_mae: 2.6104\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.4078 - mae: 1.9699 - val_loss: 15.1044 - val_mae: 2.6177\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.6593 - mae: 1.9870 - val_loss: 14.9696 - val_mae: 2.5507\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.4466 - mae: 1.9746 - val_loss: 14.0499 - val_mae: 2.5630\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.4531 - mae: 1.9625 - val_loss: 14.5467 - val_mae: 2.5658\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.5147 - mae: 1.9778 - val_loss: 14.4053 - val_mae: 2.5261\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.2939 - mae: 1.9418 - val_loss: 14.3039 - val_mae: 2.5748\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.2608 - mae: 1.9438 - val_loss: 14.5342 - val_mae: 2.5729\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.2608 - mae: 1.9482 - val_loss: 14.4271 - val_mae: 2.5696\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.1428 - mae: 1.9319 - val_loss: 14.4570 - val_mae: 2.5908\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.2225 - mae: 1.9545 - val_loss: 14.5048 - val_mae: 2.6135\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.1361 - mae: 1.9427 - val_loss: 14.6311 - val_mae: 2.6098\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.1123 - mae: 1.9309 - val_loss: 14.6380 - val_mae: 2.5824\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.2591 - mae: 1.9368 - val_loss: 14.7748 - val_mae: 2.5820\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.1331 - mae: 1.9249 - val_loss: 14.3371 - val_mae: 2.6151\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.0953 - mae: 1.9295 - val_loss: 14.4703 - val_mae: 2.5983\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9656 - mae: 1.9106 - val_loss: 14.6842 - val_mae: 2.6087\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.1043 - mae: 1.9183 - val_loss: 14.7661 - val_mae: 2.6136\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.9479 - mae: 1.9100 - val_loss: 14.4044 - val_mae: 2.6019\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9882 - mae: 1.9180 - val_loss: 14.4075 - val_mae: 2.6173\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9051 - mae: 1.9054 - val_loss: 14.6206 - val_mae: 2.6129\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.8424 - mae: 1.8898 - val_loss: 14.3365 - val_mae: 2.5902\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.8529 - mae: 1.8995 - val_loss: 14.3312 - val_mae: 2.5934\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.8579 - mae: 1.8916 - val_loss: 14.4425 - val_mae: 2.5885\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.7900 - mae: 1.8879 - val_loss: 14.3623 - val_mae: 2.6188\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9870 - mae: 1.9168 - val_loss: 14.0590 - val_mae: 2.5947\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.8033 - mae: 1.8922 - val_loss: 14.2901 - val_mae: 2.6001\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7516 - mae: 1.8848 - val_loss: 14.3685 - val_mae: 2.6300\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7779 - mae: 1.8905 - val_loss: 14.4230 - val_mae: 2.6204\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.6576 - mae: 1.8756 - val_loss: 14.3328 - val_mae: 2.6226\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7812 - mae: 1.9040 - val_loss: 14.3216 - val_mae: 2.6207\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.6591 - mae: 1.8752 - val_loss: 14.7321 - val_mae: 2.6345\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.8488 - mae: 1.8935 - val_loss: 14.6090 - val_mae: 2.5854\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.8284 - mae: 1.9207 - val_loss: 14.2010 - val_mae: 2.6546\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.8309 - mae: 1.9335 - val_loss: 14.3649 - val_mae: 2.6057\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7069 - mae: 1.9028 - val_loss: 14.6178 - val_mae: 2.6165\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.5826 - mae: 1.8735 - val_loss: 14.1312 - val_mae: 2.5984\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5959 - mae: 1.8913 - val_loss: 14.0064 - val_mae: 2.6124\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.5459 - mae: 1.8673 - val_loss: 14.2968 - val_mae: 2.6257\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.5544 - mae: 1.8744 - val_loss: 14.0445 - val_mae: 2.6045\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.5007 - mae: 1.8486 - val_loss: 14.1898 - val_mae: 2.5652\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5129 - mae: 1.8574 - val_loss: 14.0031 - val_mae: 2.5964\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.4183 - mae: 1.8423 - val_loss: 14.1678 - val_mae: 2.5714\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.4525 - mae: 1.8405 - val_loss: 14.4065 - val_mae: 2.5373\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5110 - mae: 1.8433 - val_loss: 14.0585 - val_mae: 2.5844\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.5614 - mae: 2.0448 - val_loss: 14.2700 - val_mae: 2.7117\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.6521 - mae: 1.9245 - val_loss: 15.4332 - val_mae: 2.6384\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.6847 - mae: 1.8969 - val_loss: 13.8983 - val_mae: 2.5855\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.5629 - mae: 1.8942 - val_loss: 14.1295 - val_mae: 2.6248\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.3985 - mae: 1.8445 - val_loss: 14.5022 - val_mae: 2.6260\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.2743 - mae: 1.8327 - val_loss: 14.0606 - val_mae: 2.6233\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.2868 - mae: 1.8305 - val_loss: 14.0992 - val_mae: 2.5991\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.2481 - mae: 1.8215 - val_loss: 13.8835 - val_mae: 2.5831\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.2773 - mae: 1.8388 - val_loss: 13.9036 - val_mae: 2.5663\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.3316 - mae: 1.8215 - val_loss: 14.2594 - val_mae: 2.5429\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.1870 - mae: 1.8163 - val_loss: 13.8559 - val_mae: 2.6098\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.2924 - mae: 1.8481 - val_loss: 14.1750 - val_mae: 2.6259\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.0829 - mae: 1.8080 - val_loss: 13.8142 - val_mae: 2.5986\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.1053 - mae: 1.8055 - val_loss: 14.1219 - val_mae: 2.6342\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.1893 - mae: 1.8155 - val_loss: 13.6631 - val_mae: 2.6007\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.8070 - mae: 1.9344 - val_loss: 14.3566 - val_mae: 2.7746\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.4572 - mae: 1.8808 - val_loss: 14.4017 - val_mae: 2.6364\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.3130 - mae: 1.8619 - val_loss: 13.9131 - val_mae: 2.6411\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.0634 - mae: 1.8098 - val_loss: 13.8333 - val_mae: 2.6294\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.1009 - mae: 1.8141 - val_loss: 13.7894 - val_mae: 2.6046\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.0760 - mae: 1.8050 - val_loss: 13.9792 - val_mae: 2.5885\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.0803 - mae: 1.8243 - val_loss: 13.7988 - val_mae: 2.6430\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.9204 - mae: 1.7827 - val_loss: 14.2520 - val_mae: 2.6565\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.9675 - mae: 1.7917 - val_loss: 14.1495 - val_mae: 2.6187\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.8834 - mae: 1.7730 - val_loss: 13.7126 - val_mae: 2.5992\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.0809 - mae: 1.8299 - val_loss: 13.6571 - val_mae: 2.6081\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.8535 - mae: 1.7696 - val_loss: 13.8291 - val_mae: 2.5878\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.8557 - mae: 1.7608 - val_loss: 13.7243 - val_mae: 2.5951\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.9150 - mae: 1.7996 - val_loss: 13.5791 - val_mae: 2.5956\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.9074 - mae: 1.7634 - val_loss: 13.6763 - val_mae: 2.5854\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.7890 - mae: 1.7597 - val_loss: 13.4539 - val_mae: 2.5707\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.8549 - mae: 1.7940 - val_loss: 13.5485 - val_mae: 2.5870\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.7706 - mae: 1.7764 - val_loss: 13.2573 - val_mae: 2.5736\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.6846 - mae: 1.7685 - val_loss: 13.2698 - val_mae: 2.5708\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.6524 - mae: 1.7448 - val_loss: 13.2991 - val_mae: 2.5288\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.6909 - mae: 1.7523 - val_loss: 13.0523 - val_mae: 2.5326\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.6779 - mae: 1.7561 - val_loss: 12.4381 - val_mae: 2.5037\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.7987 - mae: 1.7627 - val_loss: 12.7182 - val_mae: 2.5301\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.6584 - mae: 1.7277 - val_loss: 12.7245 - val_mae: 2.5154\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.6557 - mae: 1.7399 - val_loss: 12.7929 - val_mae: 2.5156\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.5332 - mae: 1.7184 - val_loss: 13.0563 - val_mae: 2.5524\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.5675 - mae: 1.7254 - val_loss: 13.1126 - val_mae: 2.5560\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.5059 - mae: 1.7288 - val_loss: 13.0217 - val_mae: 2.5705\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.5488 - mae: 1.7155 - val_loss: 13.2333 - val_mae: 2.5510\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.5014 - mae: 1.7226 - val_loss: 13.2427 - val_mae: 2.5889\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4642 - mae: 1.7104 - val_loss: 12.9199 - val_mae: 2.5347\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4549 - mae: 1.7021 - val_loss: 13.0093 - val_mae: 2.5371\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4130 - mae: 1.6994 - val_loss: 12.9643 - val_mae: 2.5497\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.3489 - mae: 1.6956 - val_loss: 13.0879 - val_mae: 2.5425\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.3803 - mae: 1.6815 - val_loss: 13.1015 - val_mae: 2.5385\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.3185 - mae: 1.6714 - val_loss: 13.0700 - val_mae: 2.5570\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.5108 - mae: 1.7351 - val_loss: 12.9035 - val_mae: 2.5414\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.4037 - mae: 1.6898 - val_loss: 13.1832 - val_mae: 2.5529\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.6259 - mae: 1.7410 - val_loss: 13.3204 - val_mae: 2.5990\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.3134 - mae: 1.6934 - val_loss: 13.2473 - val_mae: 2.5779\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.3027 - mae: 1.6616 - val_loss: 13.3006 - val_mae: 2.5742\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 5.2741 - mae: 1.6939 - val_loss: 13.0181 - val_mae: 2.5683\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.1790 - mae: 1.6602 - val_loss: 12.9990 - val_mae: 2.5342\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.3526 - mae: 1.6655 - val_loss: 12.9328 - val_mae: 2.4962\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 5.2347 - mae: 1.6572 - val_loss: 12.8160 - val_mae: 2.5232\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.2133 - mae: 1.6629 - val_loss: 12.8780 - val_mae: 2.5127\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.1442 - mae: 1.6512 - val_loss: 13.1652 - val_mae: 2.5509\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.2909 - mae: 1.6994 - val_loss: 13.3954 - val_mae: 2.6012\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.2540 - mae: 1.6905 - val_loss: 13.4014 - val_mae: 2.5679\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.4146 - mae: 1.6850 - val_loss: 13.5055 - val_mae: 2.5367\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.3195 - mae: 1.7109 - val_loss: 12.9996 - val_mae: 2.5588\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.1134 - mae: 1.6390 - val_loss: 13.4267 - val_mae: 2.5349\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.1709 - mae: 1.6576 - val_loss: 13.1368 - val_mae: 2.5201\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.0387 - mae: 1.6263 - val_loss: 12.8575 - val_mae: 2.4798\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.0318 - mae: 1.6255 - val_loss: 12.7454 - val_mae: 2.4749\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.1092 - mae: 1.6688 - val_loss: 12.5899 - val_mae: 2.4654\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.1787 - mae: 1.6551 - val_loss: 13.0281 - val_mae: 2.4996\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 5.0895 - mae: 1.6491 - val_loss: 12.8640 - val_mae: 2.5302\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 5.0723 - mae: 1.6556 - val_loss: 12.9204 - val_mae: 2.5213\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.1802 - mae: 1.6355 - val_loss: 12.8365 - val_mae: 2.4865\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 5.0335 - mae: 1.6636 - val_loss: 12.7616 - val_mae: 2.5554\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.9485 - mae: 1.6393 - val_loss: 13.0332 - val_mae: 2.5124\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.9463 - mae: 1.6225 - val_loss: 12.6371 - val_mae: 2.4929\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.8867 - mae: 1.6109 - val_loss: 12.7594 - val_mae: 2.4881\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.9912 - mae: 1.6110 - val_loss: 13.4370 - val_mae: 2.5327\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.0242 - mae: 1.6356 - val_loss: 13.2015 - val_mae: 2.5684\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0792 - mae: 1.6663 - val_loss: 13.0067 - val_mae: 2.5067\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8666 - mae: 1.6019 - val_loss: 12.9099 - val_mae: 2.4914\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7969 - mae: 1.5939 - val_loss: 12.8101 - val_mae: 2.5174\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7347 - mae: 1.5894 - val_loss: 12.9475 - val_mae: 2.5158\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.7876 - mae: 1.5794 - val_loss: 12.8129 - val_mae: 2.5085\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.8160 - mae: 1.6058 - val_loss: 12.7815 - val_mae: 2.5239\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.6875 - mae: 1.5773 - val_loss: 12.7277 - val_mae: 2.5076\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7262 - mae: 1.5778 - val_loss: 12.7341 - val_mae: 2.5145\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.8351 - mae: 1.6282 - val_loss: 12.9236 - val_mae: 2.5301\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8363 - mae: 1.6259 - val_loss: 13.1503 - val_mae: 2.5374\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1023 - mae: 1.6753 - val_loss: 13.0874 - val_mae: 2.5571\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6826 - mae: 1.5961 - val_loss: 13.0834 - val_mae: 2.5374\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.9323 - mae: 1.6532 - val_loss: 12.7339 - val_mae: 2.5556\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8328 - mae: 1.6340 - val_loss: 12.6843 - val_mae: 2.4839\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6958 - mae: 1.5916 - val_loss: 12.7130 - val_mae: 2.5112\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8498 - mae: 1.6426 - val_loss: 12.2135 - val_mae: 2.4827\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.9654 - mae: 1.6290 - val_loss: 12.2014 - val_mae: 2.4500\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7424 - mae: 1.5712 - val_loss: 12.0718 - val_mae: 2.4853\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7805 - mae: 1.5974 - val_loss: 12.1949 - val_mae: 2.4484\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.6816 - mae: 1.6066 - val_loss: 12.2326 - val_mae: 2.4887\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6431 - mae: 1.5990 - val_loss: 12.7249 - val_mae: 2.5087\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7511 - mae: 1.6403 - val_loss: 12.5463 - val_mae: 2.5007\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.6653 - mae: 1.5822 - val_loss: 12.2533 - val_mae: 2.4511\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5545 - mae: 1.5541 - val_loss: 12.2104 - val_mae: 2.4437\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.4468 - mae: 1.5450 - val_loss: 12.2558 - val_mae: 2.4580\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4628 - mae: 1.5588 - val_loss: 12.4142 - val_mae: 2.4879\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.4139 - mae: 1.5385 - val_loss: 12.3106 - val_mae: 2.4973\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.4413 - mae: 1.5526 - val_loss: 12.2826 - val_mae: 2.4846\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3750 - mae: 1.5395 - val_loss: 12.2866 - val_mae: 2.4958\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.3553 - mae: 1.5443 - val_loss: 12.2509 - val_mae: 2.5064\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3915 - mae: 1.5311 - val_loss: 12.5993 - val_mae: 2.5017\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4677 - mae: 1.5449 - val_loss: 12.2622 - val_mae: 2.4861\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4949 - mae: 1.5514 - val_loss: 12.7566 - val_mae: 2.5039\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3715 - mae: 1.5213 - val_loss: 12.7109 - val_mae: 2.5146\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3374 - mae: 1.5375 - val_loss: 12.5995 - val_mae: 2.4928\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 8.4620 - mae: 2.0875\n",
            "Epoch 1/300\n",
            "11/11 [==============================] - 2s 23ms/step - loss: 567.2272 - mae: 21.9651 - val_loss: 610.7763 - val_mae: 22.5280\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 530.9828 - mae: 21.1368 - val_loss: 573.1187 - val_mae: 21.6822\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 494.5608 - mae: 20.2723 - val_loss: 532.3148 - val_mae: 20.7486\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 452.8110 - mae: 19.2283 - val_loss: 480.5898 - val_mae: 19.5617\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 400.9150 - mae: 17.9214 - val_loss: 416.7957 - val_mae: 18.0452\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 340.0408 - mae: 16.3010 - val_loss: 345.6000 - val_mae: 16.2203\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 272.1873 - mae: 14.3621 - val_loss: 267.3177 - val_mae: 13.9924\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 200.0806 - mae: 12.0196 - val_loss: 189.5029 - val_mae: 11.3994\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 135.4269 - mae: 9.5765 - val_loss: 129.3184 - val_mae: 8.9102\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 88.8183 - mae: 7.2913 - val_loss: 90.1602 - val_mae: 6.9806\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 60.7871 - mae: 5.7906 - val_loss: 70.9981 - val_mae: 6.1261\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 48.2200 - mae: 5.1724 - val_loss: 62.2681 - val_mae: 5.8405\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 41.1908 - mae: 4.8094 - val_loss: 56.0980 - val_mae: 5.5552\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 35.9955 - mae: 4.4869 - val_loss: 51.1952 - val_mae: 5.1757\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 32.3450 - mae: 4.2385 - val_loss: 47.8739 - val_mae: 4.9296\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 29.8938 - mae: 4.0550 - val_loss: 45.6169 - val_mae: 4.7757\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 27.8040 - mae: 3.8960 - val_loss: 43.2811 - val_mae: 4.5980\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 26.4459 - mae: 3.8010 - val_loss: 41.8135 - val_mae: 4.4883\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 25.1603 - mae: 3.7034 - val_loss: 40.3671 - val_mae: 4.3689\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 24.1170 - mae: 3.6146 - val_loss: 38.9205 - val_mae: 4.2403\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 23.3211 - mae: 3.5320 - val_loss: 37.5627 - val_mae: 4.1248\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 22.6360 - mae: 3.4819 - val_loss: 37.0744 - val_mae: 4.0893\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 21.7965 - mae: 3.4096 - val_loss: 35.8474 - val_mae: 3.9749\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 21.1760 - mae: 3.3656 - val_loss: 35.0385 - val_mae: 3.9042\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 20.6260 - mae: 3.3207 - val_loss: 34.5252 - val_mae: 3.8487\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 20.0788 - mae: 3.2766 - val_loss: 33.9741 - val_mae: 3.8078\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 19.5881 - mae: 3.2210 - val_loss: 33.2088 - val_mae: 3.7409\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 19.0934 - mae: 3.1739 - val_loss: 32.6218 - val_mae: 3.6900\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 18.6971 - mae: 3.1362 - val_loss: 32.4157 - val_mae: 3.6548\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 18.2477 - mae: 3.0993 - val_loss: 31.8860 - val_mae: 3.6299\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.9033 - mae: 3.0667 - val_loss: 30.6764 - val_mae: 3.5338\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.5666 - mae: 3.0485 - val_loss: 30.3731 - val_mae: 3.5110\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 17.0820 - mae: 3.0055 - val_loss: 29.6878 - val_mae: 3.4756\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 16.7935 - mae: 2.9672 - val_loss: 29.1399 - val_mae: 3.3981\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 16.5261 - mae: 2.9254 - val_loss: 28.1040 - val_mae: 3.2976\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 16.3190 - mae: 2.8971 - val_loss: 27.8072 - val_mae: 3.2577\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.0152 - mae: 2.8710 - val_loss: 27.8478 - val_mae: 3.2534\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 15.7206 - mae: 2.8600 - val_loss: 27.9917 - val_mae: 3.2712\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 15.4188 - mae: 2.8412 - val_loss: 28.2875 - val_mae: 3.2792\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 15.1734 - mae: 2.8212 - val_loss: 28.8650 - val_mae: 3.3339\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 14.9442 - mae: 2.8259 - val_loss: 30.1349 - val_mae: 3.3784\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 14.6325 - mae: 2.8053 - val_loss: 29.6218 - val_mae: 3.2708\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 14.4265 - mae: 2.7845 - val_loss: 28.9535 - val_mae: 3.1814\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 14.1837 - mae: 2.7354 - val_loss: 27.5367 - val_mae: 3.1267\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 14.0518 - mae: 2.7025 - val_loss: 27.1852 - val_mae: 3.1114\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.8277 - mae: 2.6826 - val_loss: 27.1079 - val_mae: 3.1091\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.6760 - mae: 2.6748 - val_loss: 26.9221 - val_mae: 3.0600\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.3566 - mae: 2.6367 - val_loss: 27.3423 - val_mae: 3.1578\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.2898 - mae: 2.6386 - val_loss: 27.4560 - val_mae: 3.1675\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.1509 - mae: 2.6311 - val_loss: 27.4503 - val_mae: 3.1778\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.9779 - mae: 2.6094 - val_loss: 26.9911 - val_mae: 3.1043\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.7448 - mae: 2.5900 - val_loss: 26.8170 - val_mae: 3.0793\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.6079 - mae: 2.5829 - val_loss: 26.6287 - val_mae: 3.0536\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.4880 - mae: 2.5681 - val_loss: 26.4171 - val_mae: 3.0367\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.3998 - mae: 2.5501 - val_loss: 26.1878 - val_mae: 3.0087\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.2760 - mae: 2.5337 - val_loss: 26.2395 - val_mae: 3.0311\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 12.1520 - mae: 2.5177 - val_loss: 25.9570 - val_mae: 3.0161\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 12.0279 - mae: 2.4997 - val_loss: 26.5150 - val_mae: 3.0706\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.9003 - mae: 2.4916 - val_loss: 25.9914 - val_mae: 2.9898\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.7906 - mae: 2.4781 - val_loss: 25.8237 - val_mae: 2.9422\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 11.6823 - mae: 2.4770 - val_loss: 25.8983 - val_mae: 2.9617\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 11.5378 - mae: 2.4577 - val_loss: 25.9680 - val_mae: 2.9875\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 11.4450 - mae: 2.4495 - val_loss: 26.2228 - val_mae: 3.0101\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 11.3534 - mae: 2.4409 - val_loss: 25.9691 - val_mae: 2.9845\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 11.2665 - mae: 2.4342 - val_loss: 25.7917 - val_mae: 2.9665\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 11.2543 - mae: 2.4515 - val_loss: 25.6416 - val_mae: 2.9380\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 11.0780 - mae: 2.4045 - val_loss: 25.9101 - val_mae: 3.0301\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 11.1595 - mae: 2.3940 - val_loss: 25.3349 - val_mae: 2.9407\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 11.0005 - mae: 2.4083 - val_loss: 25.4108 - val_mae: 2.8987\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 10.9237 - mae: 2.3975 - val_loss: 25.0002 - val_mae: 2.9066\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 10.7937 - mae: 2.3672 - val_loss: 25.2668 - val_mae: 2.9164\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 10.7315 - mae: 2.3620 - val_loss: 25.3961 - val_mae: 2.9110\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 10.6809 - mae: 2.3475 - val_loss: 25.3547 - val_mae: 2.9245\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 10.5935 - mae: 2.3381 - val_loss: 25.4015 - val_mae: 2.9224\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.5103 - mae: 2.3447 - val_loss: 25.3983 - val_mae: 2.9120\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 10.4616 - mae: 2.3348 - val_loss: 25.2761 - val_mae: 2.9432\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 10.5439 - mae: 2.3144 - val_loss: 25.7225 - val_mae: 3.0017\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.4153 - mae: 2.3031 - val_loss: 25.2792 - val_mae: 2.8912\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 10.3814 - mae: 2.3188 - val_loss: 25.1776 - val_mae: 2.8596\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.2190 - mae: 2.3087 - val_loss: 25.5517 - val_mae: 2.9538\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 10.2329 - mae: 2.2967 - val_loss: 25.7889 - val_mae: 2.9757\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 10.1655 - mae: 2.2823 - val_loss: 24.7401 - val_mae: 2.8274\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 10.2357 - mae: 2.3098 - val_loss: 24.5267 - val_mae: 2.8108\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 10.2051 - mae: 2.3174 - val_loss: 25.1511 - val_mae: 2.9549\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.0966 - mae: 2.2839 - val_loss: 25.2168 - val_mae: 2.9775\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9.9190 - mae: 2.2622 - val_loss: 24.7348 - val_mae: 2.8853\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9.8532 - mae: 2.2593 - val_loss: 24.6450 - val_mae: 2.8813\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 9.8741 - mae: 2.2429 - val_loss: 24.4225 - val_mae: 2.8603\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.8236 - mae: 2.2453 - val_loss: 24.5363 - val_mae: 2.8570\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.6940 - mae: 2.2295 - val_loss: 24.5955 - val_mae: 2.8891\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.7614 - mae: 2.2150 - val_loss: 24.4180 - val_mae: 2.8677\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.6968 - mae: 2.2140 - val_loss: 24.7289 - val_mae: 2.9095\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.6039 - mae: 2.2002 - val_loss: 24.8382 - val_mae: 2.9187\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.5633 - mae: 2.1956 - val_loss: 24.4839 - val_mae: 2.8797\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.6813 - mae: 2.1902 - val_loss: 23.9383 - val_mae: 2.8661\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.5376 - mae: 2.1972 - val_loss: 24.6858 - val_mae: 2.9338\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.5343 - mae: 2.1917 - val_loss: 24.2062 - val_mae: 2.8836\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.4356 - mae: 2.1800 - val_loss: 24.4624 - val_mae: 2.8950\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9.3439 - mae: 2.1798 - val_loss: 24.1912 - val_mae: 2.8556\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.2807 - mae: 2.1551 - val_loss: 24.1772 - val_mae: 2.8651\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.4605 - mae: 2.1481 - val_loss: 23.9730 - val_mae: 2.8281\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.3098 - mae: 2.1369 - val_loss: 24.7048 - val_mae: 2.9024\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.2448 - mae: 2.1666 - val_loss: 24.2816 - val_mae: 2.8570\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.1674 - mae: 2.1383 - val_loss: 23.8841 - val_mae: 2.8324\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.2117 - mae: 2.1194 - val_loss: 24.3031 - val_mae: 2.9079\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.0957 - mae: 2.1223 - val_loss: 24.2329 - val_mae: 2.9200\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.0626 - mae: 2.1262 - val_loss: 23.8444 - val_mae: 2.8341\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.0171 - mae: 2.1239 - val_loss: 24.1892 - val_mae: 2.8706\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.9768 - mae: 2.1227 - val_loss: 24.3767 - val_mae: 2.8751\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.9446 - mae: 2.1217 - val_loss: 24.5659 - val_mae: 2.9514\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.9305 - mae: 2.1163 - val_loss: 24.3558 - val_mae: 2.9400\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.8707 - mae: 2.1060 - val_loss: 24.1559 - val_mae: 2.9071\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.8112 - mae: 2.0883 - val_loss: 23.7058 - val_mae: 2.8483\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.9284 - mae: 2.1202 - val_loss: 23.8371 - val_mae: 2.8505\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.7792 - mae: 2.0905 - val_loss: 23.8436 - val_mae: 2.8841\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.7911 - mae: 2.0753 - val_loss: 23.7485 - val_mae: 2.8585\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.7678 - mae: 2.0705 - val_loss: 24.1185 - val_mae: 2.9232\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.6798 - mae: 2.0768 - val_loss: 23.7783 - val_mae: 2.8679\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.6456 - mae: 2.0638 - val_loss: 23.7997 - val_mae: 2.8642\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.5561 - mae: 2.0698 - val_loss: 24.7043 - val_mae: 2.9738\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.9020 - mae: 2.1067 - val_loss: 25.1171 - val_mae: 3.0023\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.7005 - mae: 2.0873 - val_loss: 23.5280 - val_mae: 2.8120\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.5568 - mae: 2.0723 - val_loss: 23.8531 - val_mae: 2.8743\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.5069 - mae: 2.0485 - val_loss: 23.7434 - val_mae: 2.8565\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.4624 - mae: 2.0565 - val_loss: 24.4943 - val_mae: 2.9319\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.5299 - mae: 2.0631 - val_loss: 24.5245 - val_mae: 3.0129\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.4551 - mae: 2.0198 - val_loss: 23.2645 - val_mae: 2.8237\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.4628 - mae: 2.0376 - val_loss: 23.5321 - val_mae: 2.8246\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.3001 - mae: 2.0218 - val_loss: 23.9220 - val_mae: 2.8809\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.3296 - mae: 2.0346 - val_loss: 24.0669 - val_mae: 2.9286\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.2193 - mae: 2.0023 - val_loss: 23.4756 - val_mae: 2.8638\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.2136 - mae: 2.0018 - val_loss: 23.3119 - val_mae: 2.8431\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.1691 - mae: 1.9988 - val_loss: 22.9765 - val_mae: 2.7999\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.1965 - mae: 2.0136 - val_loss: 23.0890 - val_mae: 2.8057\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.1269 - mae: 1.9996 - val_loss: 23.3443 - val_mae: 2.9009\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.1401 - mae: 1.9935 - val_loss: 23.2957 - val_mae: 2.9004\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.1401 - mae: 1.9852 - val_loss: 22.7920 - val_mae: 2.8233\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.0562 - mae: 1.9816 - val_loss: 23.1624 - val_mae: 2.8373\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.0473 - mae: 1.9877 - val_loss: 24.1122 - val_mae: 2.8745\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.0524 - mae: 2.0046 - val_loss: 23.8044 - val_mae: 2.8394\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.9891 - mae: 1.9683 - val_loss: 23.5995 - val_mae: 2.8968\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.9929 - mae: 1.9714 - val_loss: 23.0785 - val_mae: 2.8047\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.9295 - mae: 1.9644 - val_loss: 23.3552 - val_mae: 2.8504\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.9183 - mae: 1.9575 - val_loss: 22.7420 - val_mae: 2.8086\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.9375 - mae: 1.9499 - val_loss: 22.8256 - val_mae: 2.8219\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.8865 - mae: 1.9768 - val_loss: 23.8161 - val_mae: 2.9666\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.8365 - mae: 1.9536 - val_loss: 22.9764 - val_mae: 2.8471\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.7840 - mae: 1.9435 - val_loss: 22.9234 - val_mae: 2.8003\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.7027 - mae: 1.9385 - val_loss: 22.8836 - val_mae: 2.8185\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.6366 - mae: 1.9358 - val_loss: 22.7196 - val_mae: 2.7826\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.6489 - mae: 1.9456 - val_loss: 22.9211 - val_mae: 2.7939\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.6491 - mae: 1.9353 - val_loss: 22.6800 - val_mae: 2.8446\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.6444 - mae: 1.9244 - val_loss: 22.7851 - val_mae: 2.8352\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.5861 - mae: 1.9182 - val_loss: 22.5251 - val_mae: 2.7642\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.5773 - mae: 1.9130 - val_loss: 22.8120 - val_mae: 2.7957\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.5837 - mae: 1.9073 - val_loss: 22.9348 - val_mae: 2.7937\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.5035 - mae: 1.8980 - val_loss: 22.6344 - val_mae: 2.7960\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.4377 - mae: 1.8935 - val_loss: 22.2212 - val_mae: 2.7497\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.4776 - mae: 1.9073 - val_loss: 22.3718 - val_mae: 2.7734\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.3793 - mae: 1.8948 - val_loss: 22.6371 - val_mae: 2.8272\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.4591 - mae: 1.9102 - val_loss: 22.5831 - val_mae: 2.8711\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.3946 - mae: 1.8899 - val_loss: 22.6677 - val_mae: 2.7967\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.3171 - mae: 1.9041 - val_loss: 23.3501 - val_mae: 2.8694\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.3153 - mae: 1.8933 - val_loss: 22.6358 - val_mae: 2.8346\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.3175 - mae: 1.8717 - val_loss: 21.8742 - val_mae: 2.7287\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.2847 - mae: 1.8745 - val_loss: 22.1070 - val_mae: 2.7688\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.2312 - mae: 1.8824 - val_loss: 22.5152 - val_mae: 2.7959\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.1602 - mae: 1.8544 - val_loss: 22.3894 - val_mae: 2.7829\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.4282 - mae: 1.8906 - val_loss: 23.4468 - val_mae: 2.9461\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.1503 - mae: 1.8630 - val_loss: 22.0696 - val_mae: 2.7384\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.2285 - mae: 1.8706 - val_loss: 21.9625 - val_mae: 2.7681\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.3088 - mae: 1.8988 - val_loss: 23.3746 - val_mae: 3.0400\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.3821 - mae: 1.9224 - val_loss: 22.7878 - val_mae: 2.8124\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.2201 - mae: 1.8904 - val_loss: 22.0366 - val_mae: 2.7634\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.0610 - mae: 1.8634 - val_loss: 22.4455 - val_mae: 2.7749\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9545 - mae: 1.8457 - val_loss: 22.3274 - val_mae: 2.8263\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.9264 - mae: 1.8449 - val_loss: 22.3178 - val_mae: 2.8077\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.8879 - mae: 1.8465 - val_loss: 22.4202 - val_mae: 2.7814\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.8844 - mae: 1.8359 - val_loss: 22.3366 - val_mae: 2.8072\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.9333 - mae: 1.8197 - val_loss: 21.5570 - val_mae: 2.7207\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.3082 - mae: 1.9023 - val_loss: 23.6463 - val_mae: 2.8375\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.0987 - mae: 1.8191 - val_loss: 21.6766 - val_mae: 2.7947\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.0883 - mae: 1.8038 - val_loss: 21.8516 - val_mae: 2.7654\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.7967 - mae: 1.7922 - val_loss: 21.7177 - val_mae: 2.7212\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.7155 - mae: 1.7903 - val_loss: 21.8590 - val_mae: 2.7787\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.8157 - mae: 1.8132 - val_loss: 19.9063 - val_mae: 2.6266\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.9248 - mae: 1.8239 - val_loss: 19.8914 - val_mae: 2.6274\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.0947 - mae: 1.8848 - val_loss: 21.6534 - val_mae: 2.8374\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.6873 - mae: 1.8026 - val_loss: 20.8775 - val_mae: 2.6864\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.7180 - mae: 1.7844 - val_loss: 21.0726 - val_mae: 2.6819\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.5487 - mae: 1.7907 - val_loss: 21.8104 - val_mae: 2.7572\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.5269 - mae: 1.7740 - val_loss: 21.8328 - val_mae: 2.7616\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.4724 - mae: 1.7606 - val_loss: 21.4315 - val_mae: 2.7303\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.4963 - mae: 1.7555 - val_loss: 21.4335 - val_mae: 2.7660\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.5019 - mae: 1.7525 - val_loss: 20.5636 - val_mae: 2.6852\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.5547 - mae: 1.7529 - val_loss: 19.2579 - val_mae: 2.6359\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.6042 - mae: 1.7692 - val_loss: 20.2515 - val_mae: 2.7002\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.4246 - mae: 1.7644 - val_loss: 20.5448 - val_mae: 2.6806\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.5303 - mae: 1.7898 - val_loss: 20.7059 - val_mae: 2.7010\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.3921 - mae: 1.7400 - val_loss: 20.8402 - val_mae: 2.7203\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 6.4218 - mae: 1.7803 - val_loss: 22.2658 - val_mae: 2.7670\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 6.6731 - mae: 1.8478 - val_loss: 21.9939 - val_mae: 2.8741\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.3828 - mae: 1.7610 - val_loss: 20.6901 - val_mae: 2.7199\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.4312 - mae: 1.7546 - val_loss: 20.4021 - val_mae: 2.6558\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6.2517 - mae: 1.7431 - val_loss: 21.2327 - val_mae: 2.7727\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.2348 - mae: 1.7305 - val_loss: 20.8773 - val_mae: 2.7461\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.1328 - mae: 1.7229 - val_loss: 20.7069 - val_mae: 2.6537\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.1748 - mae: 1.7344 - val_loss: 20.6589 - val_mae: 2.7232\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.2270 - mae: 1.7286 - val_loss: 20.4395 - val_mae: 2.7085\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.1274 - mae: 1.7155 - val_loss: 21.2222 - val_mae: 2.7097\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6.2300 - mae: 1.7027 - val_loss: 20.9053 - val_mae: 2.7098\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.0647 - mae: 1.6927 - val_loss: 21.2196 - val_mae: 2.7132\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6.1047 - mae: 1.7299 - val_loss: 21.5151 - val_mae: 2.7364\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 6.0568 - mae: 1.7229 - val_loss: 20.9663 - val_mae: 2.6939\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.9887 - mae: 1.6970 - val_loss: 20.5997 - val_mae: 2.6998\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 6.5396 - mae: 1.8488 - val_loss: 23.0747 - val_mae: 2.8969\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 6.7392 - mae: 1.8396 - val_loss: 20.7311 - val_mae: 2.7351\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.2440 - mae: 1.7558 - val_loss: 19.6450 - val_mae: 2.6554\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 6.0898 - mae: 1.7291 - val_loss: 19.7852 - val_mae: 2.6466\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.9706 - mae: 1.7105 - val_loss: 19.7256 - val_mae: 2.6934\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 5.8679 - mae: 1.6801 - val_loss: 20.0885 - val_mae: 2.6964\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.8691 - mae: 1.6861 - val_loss: 20.2576 - val_mae: 2.6994\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 5.7948 - mae: 1.6745 - val_loss: 20.5491 - val_mae: 2.7394\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.5609 - mae: 1.8325 - val_loss: 22.6793 - val_mae: 2.9145\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6.0677 - mae: 1.7362 - val_loss: 19.8900 - val_mae: 2.7003\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.8589 - mae: 1.6878 - val_loss: 19.6775 - val_mae: 2.7122\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 5.7333 - mae: 1.6855 - val_loss: 20.4656 - val_mae: 2.7931\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.0219 - mae: 1.7539 - val_loss: 19.5396 - val_mae: 2.7360\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.6302 - mae: 1.6548 - val_loss: 18.8840 - val_mae: 2.6318\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.7493 - mae: 1.6645 - val_loss: 19.6069 - val_mae: 2.6674\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.6933 - mae: 1.6778 - val_loss: 19.8180 - val_mae: 2.7178\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.7091 - mae: 1.6520 - val_loss: 18.8754 - val_mae: 2.6267\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.8221 - mae: 1.6480 - val_loss: 19.9081 - val_mae: 2.7329\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.5837 - mae: 1.6407 - val_loss: 19.8385 - val_mae: 2.7168\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.5628 - mae: 1.6657 - val_loss: 19.5404 - val_mae: 2.6622\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.5515 - mae: 1.6189 - val_loss: 19.5001 - val_mae: 2.6756\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.4854 - mae: 1.6411 - val_loss: 19.9611 - val_mae: 2.6939\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.6287 - mae: 1.6827 - val_loss: 20.0984 - val_mae: 2.7628\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.4382 - mae: 1.6444 - val_loss: 19.3303 - val_mae: 2.6339\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.3973 - mae: 1.6247 - val_loss: 19.8299 - val_mae: 2.7311\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.3849 - mae: 1.6203 - val_loss: 20.0962 - val_mae: 2.7468\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.3233 - mae: 1.6090 - val_loss: 19.6137 - val_mae: 2.7014\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.4048 - mae: 1.6216 - val_loss: 19.9949 - val_mae: 2.7658\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.4931 - mae: 1.6957 - val_loss: 23.3344 - val_mae: 2.8975\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.5006 - mae: 1.6611 - val_loss: 21.8762 - val_mae: 2.8133\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.4026 - mae: 1.6303 - val_loss: 20.3541 - val_mae: 2.7109\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.4430 - mae: 1.6286 - val_loss: 19.8791 - val_mae: 2.7045\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.4167 - mae: 1.5929 - val_loss: 19.6854 - val_mae: 2.6962\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.4450 - mae: 1.5869 - val_loss: 18.5933 - val_mae: 2.6776\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.2705 - mae: 1.5983 - val_loss: 18.8233 - val_mae: 2.6705\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.1725 - mae: 1.5777 - val_loss: 19.4766 - val_mae: 2.7283\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1508 - mae: 1.5695 - val_loss: 19.9711 - val_mae: 2.7539\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.2794 - mae: 1.6202 - val_loss: 20.2067 - val_mae: 2.6960\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.3442 - mae: 1.6146 - val_loss: 19.4592 - val_mae: 2.6902\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.1140 - mae: 1.5610 - val_loss: 19.6198 - val_mae: 2.7096\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.1529 - mae: 1.5961 - val_loss: 19.4952 - val_mae: 2.7039\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.0856 - mae: 1.5625 - val_loss: 19.5657 - val_mae: 2.7070\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.0926 - mae: 1.5611 - val_loss: 19.7664 - val_mae: 2.7316\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.1884 - mae: 1.5971 - val_loss: 19.3302 - val_mae: 2.6895\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.9974 - mae: 1.5291 - val_loss: 19.4553 - val_mae: 2.7255\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.9895 - mae: 1.5466 - val_loss: 19.5142 - val_mae: 2.7201\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.0124 - mae: 1.5550 - val_loss: 19.3380 - val_mae: 2.6865\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.0747 - mae: 1.5707 - val_loss: 19.7670 - val_mae: 2.7687\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9712 - mae: 1.5713 - val_loss: 19.3305 - val_mae: 2.6586\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.0113 - mae: 1.5412 - val_loss: 18.1287 - val_mae: 2.6563\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9642 - mae: 1.5334 - val_loss: 18.8599 - val_mae: 2.6727\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.9009 - mae: 1.5431 - val_loss: 18.9431 - val_mae: 2.6662\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.8436 - mae: 1.5274 - val_loss: 18.9328 - val_mae: 2.6713\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.8635 - mae: 1.5169 - val_loss: 18.9160 - val_mae: 2.7148\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.9149 - mae: 1.5501 - val_loss: 19.1758 - val_mae: 2.7308\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.8057 - mae: 1.5201 - val_loss: 18.9067 - val_mae: 2.6675\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7711 - mae: 1.5114 - val_loss: 18.9594 - val_mae: 2.6814\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.8661 - mae: 1.5646 - val_loss: 19.3513 - val_mae: 2.6915\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.7861 - mae: 1.5440 - val_loss: 18.7921 - val_mae: 2.6671\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.7849 - mae: 1.5089 - val_loss: 19.0203 - val_mae: 2.6945\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7245 - mae: 1.5150 - val_loss: 19.7325 - val_mae: 2.6973\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7851 - mae: 1.5160 - val_loss: 19.2829 - val_mae: 2.7156\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.7192 - mae: 1.4931 - val_loss: 19.0979 - val_mae: 2.6903\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.7504 - mae: 1.5272 - val_loss: 18.7301 - val_mae: 2.6785\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.6355 - mae: 1.4827 - val_loss: 18.4387 - val_mae: 2.6621\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.6024 - mae: 1.4934 - val_loss: 18.4798 - val_mae: 2.6497\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.6592 - mae: 1.4989 - val_loss: 18.7206 - val_mae: 2.7122\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.6834 - mae: 1.4924 - val_loss: 18.2035 - val_mae: 2.6621\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.7117 - mae: 1.4931 - val_loss: 19.3105 - val_mae: 2.7452\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.6910 - mae: 1.5467 - val_loss: 19.0497 - val_mae: 2.6621\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.6357 - mae: 1.5203 - val_loss: 18.6686 - val_mae: 2.7094\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.6616 - mae: 1.4845 - val_loss: 18.7527 - val_mae: 2.6893\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.6112 - mae: 1.4752 - val_loss: 18.6333 - val_mae: 2.6647\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7073 - mae: 1.5030 - val_loss: 17.7370 - val_mae: 2.6649\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.5568 - mae: 1.4671 - val_loss: 17.4720 - val_mae: 2.6410\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.5954 - mae: 1.5293 - val_loss: 21.1722 - val_mae: 2.8232\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.6160 - mae: 1.5133 - val_loss: 18.8769 - val_mae: 2.7040\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.5298 - mae: 1.4742 - val_loss: 18.6681 - val_mae: 2.7146\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.4289 - mae: 1.4749 - val_loss: 18.4709 - val_mae: 2.7004\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.4608 - mae: 1.4617 - val_loss: 18.2578 - val_mae: 2.6607\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.6752 - mae: 1.4887 - val_loss: 18.0147 - val_mae: 2.6534\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.4942 - mae: 1.4940 - val_loss: 18.8062 - val_mae: 2.7136\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.4431 - mae: 1.4852 - val_loss: 18.1807 - val_mae: 2.6773\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.5242 - mae: 1.4841 - val_loss: 17.8325 - val_mae: 2.6351\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.3598 - mae: 1.4592 - val_loss: 18.6037 - val_mae: 2.6955\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 7.7697 - mae: 1.9765\n",
            "Epoch 1/300\n",
            "11/11 [==============================] - 1s 20ms/step - loss: 570.6578 - mae: 21.9680 - val_loss: 518.8812 - val_mae: 21.0970\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 539.4397 - mae: 21.2987 - val_loss: 487.6563 - val_mae: 20.3892\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 505.0800 - mae: 20.5403 - val_loss: 451.2045 - val_mae: 19.5403\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 462.6762 - mae: 19.5737 - val_loss: 407.3475 - val_mae: 18.4640\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 411.7990 - mae: 18.3327 - val_loss: 353.6804 - val_mae: 17.0505\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 352.2202 - mae: 16.7588 - val_loss: 291.2567 - val_mae: 15.2243\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 283.4379 - mae: 14.7181 - val_loss: 223.7612 - val_mae: 12.9980\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 213.0499 - mae: 12.2927 - val_loss: 159.9617 - val_mae: 10.4037\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 152.4178 - mae: 9.8841 - val_loss: 109.9531 - val_mae: 7.9590\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 106.8750 - mae: 7.8786 - val_loss: 78.7519 - val_mae: 6.6747\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 80.4841 - mae: 6.7038 - val_loss: 61.2114 - val_mae: 5.9982\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 64.2908 - mae: 5.9349 - val_loss: 49.6144 - val_mae: 5.3534\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 51.2587 - mae: 5.2718 - val_loss: 40.3001 - val_mae: 4.7017\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 42.3409 - mae: 4.7358 - val_loss: 33.5552 - val_mae: 4.2414\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 35.9544 - mae: 4.3076 - val_loss: 29.1996 - val_mae: 3.9431\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 31.6800 - mae: 3.9836 - val_loss: 26.4212 - val_mae: 3.6637\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 29.1214 - mae: 3.7903 - val_loss: 24.6829 - val_mae: 3.5485\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 27.6390 - mae: 3.6916 - val_loss: 23.7134 - val_mae: 3.4964\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 26.4775 - mae: 3.6267 - val_loss: 23.1090 - val_mae: 3.4829\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 25.4868 - mae: 3.5735 - val_loss: 22.6618 - val_mae: 3.4712\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 24.7548 - mae: 3.5145 - val_loss: 22.0790 - val_mae: 3.4185\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 24.0447 - mae: 3.4523 - val_loss: 21.6048 - val_mae: 3.3813\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 23.4266 - mae: 3.4206 - val_loss: 21.5548 - val_mae: 3.4086\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 22.9525 - mae: 3.4341 - val_loss: 21.9335 - val_mae: 3.5072\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 22.2766 - mae: 3.3919 - val_loss: 21.0471 - val_mae: 3.3821\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 21.5734 - mae: 3.2894 - val_loss: 20.1607 - val_mae: 3.2001\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 20.8921 - mae: 3.2073 - val_loss: 19.8561 - val_mae: 3.1656\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 20.4565 - mae: 3.1684 - val_loss: 19.6332 - val_mae: 3.1584\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 19.7563 - mae: 3.1461 - val_loss: 19.3878 - val_mae: 3.2521\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 19.6613 - mae: 3.1372 - val_loss: 19.0371 - val_mae: 3.2373\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 19.2298 - mae: 3.0919 - val_loss: 18.4717 - val_mae: 3.1427\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 18.7412 - mae: 3.0330 - val_loss: 17.9737 - val_mae: 3.0354\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 18.5169 - mae: 2.9957 - val_loss: 17.8345 - val_mae: 3.0200\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 18.1560 - mae: 2.9591 - val_loss: 17.5454 - val_mae: 3.0005\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.7901 - mae: 2.9281 - val_loss: 17.4504 - val_mae: 3.0155\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 17.7206 - mae: 2.9364 - val_loss: 17.6455 - val_mae: 3.0555\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 17.3260 - mae: 2.8915 - val_loss: 16.9200 - val_mae: 2.9508\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 17.0995 - mae: 2.8656 - val_loss: 16.5695 - val_mae: 2.8898\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 16.8616 - mae: 2.8350 - val_loss: 16.4254 - val_mae: 2.8639\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 16.5493 - mae: 2.8008 - val_loss: 16.4081 - val_mae: 2.8887\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 16.3060 - mae: 2.7899 - val_loss: 16.2530 - val_mae: 2.8892\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 16.1008 - mae: 2.7774 - val_loss: 15.8999 - val_mae: 2.8295\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 15.9884 - mae: 2.7368 - val_loss: 16.4473 - val_mae: 2.8086\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 15.8810 - mae: 2.6985 - val_loss: 16.2654 - val_mae: 2.8511\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.5445 - mae: 2.6982 - val_loss: 16.0684 - val_mae: 2.8522\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 15.3749 - mae: 2.6933 - val_loss: 15.8510 - val_mae: 2.8143\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 15.2922 - mae: 2.6567 - val_loss: 16.5573 - val_mae: 2.8240\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 15.4715 - mae: 2.6453 - val_loss: 16.5988 - val_mae: 2.8432\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 15.1411 - mae: 2.6475 - val_loss: 15.8493 - val_mae: 2.8143\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.8466 - mae: 2.6608 - val_loss: 15.5329 - val_mae: 2.8049\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 14.5801 - mae: 2.6367 - val_loss: 15.3016 - val_mae: 2.7703\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 14.5639 - mae: 2.6255 - val_loss: 15.1957 - val_mae: 2.7388\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 14.2455 - mae: 2.6217 - val_loss: 15.3513 - val_mae: 2.8018\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 14.2257 - mae: 2.6308 - val_loss: 15.2484 - val_mae: 2.7925\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 14.0170 - mae: 2.5953 - val_loss: 14.7991 - val_mae: 2.7381\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 13.7950 - mae: 2.5800 - val_loss: 14.6769 - val_mae: 2.7419\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.8522 - mae: 2.6177 - val_loss: 14.6071 - val_mae: 2.7777\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 13.6579 - mae: 2.6279 - val_loss: 14.2082 - val_mae: 2.7284\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 13.4257 - mae: 2.5904 - val_loss: 13.7808 - val_mae: 2.6483\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 13.2922 - mae: 2.5321 - val_loss: 13.7667 - val_mae: 2.6479\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 13.1934 - mae: 2.5033 - val_loss: 13.5919 - val_mae: 2.6229\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 13.0672 - mae: 2.5146 - val_loss: 14.2139 - val_mae: 2.7110\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.2118 - mae: 2.5969 - val_loss: 14.3277 - val_mae: 2.7504\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 13.0136 - mae: 2.5603 - val_loss: 13.7621 - val_mae: 2.6426\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.6875 - mae: 2.5135 - val_loss: 13.6432 - val_mae: 2.6299\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.5156 - mae: 2.4880 - val_loss: 13.1790 - val_mae: 2.5812\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.5600 - mae: 2.4841 - val_loss: 12.9722 - val_mae: 2.5640\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 12.5395 - mae: 2.4899 - val_loss: 13.4152 - val_mae: 2.6417\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 12.2804 - mae: 2.4663 - val_loss: 13.0608 - val_mae: 2.5909\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.2044 - mae: 2.4446 - val_loss: 12.7020 - val_mae: 2.5408\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 12.1205 - mae: 2.4332 - val_loss: 12.9469 - val_mae: 2.5740\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.9592 - mae: 2.4254 - val_loss: 12.8503 - val_mae: 2.5545\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.8885 - mae: 2.4066 - val_loss: 12.8226 - val_mae: 2.5522\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 11.7989 - mae: 2.4036 - val_loss: 12.8573 - val_mae: 2.5704\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.7035 - mae: 2.4043 - val_loss: 12.8604 - val_mae: 2.5704\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.6778 - mae: 2.3853 - val_loss: 12.8699 - val_mae: 2.5676\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.6945 - mae: 2.3752 - val_loss: 13.1987 - val_mae: 2.5785\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.7963 - mae: 2.3782 - val_loss: 13.1224 - val_mae: 2.6025\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.8451 - mae: 2.4244 - val_loss: 13.1259 - val_mae: 2.6511\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.4920 - mae: 2.3893 - val_loss: 12.9325 - val_mae: 2.6037\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 11.3437 - mae: 2.3500 - val_loss: 12.6596 - val_mae: 2.5536\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.2948 - mae: 2.3367 - val_loss: 12.4993 - val_mae: 2.5314\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.1917 - mae: 2.3433 - val_loss: 12.2578 - val_mae: 2.5115\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 11.1151 - mae: 2.3533 - val_loss: 12.3395 - val_mae: 2.5209\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 11.0168 - mae: 2.3336 - val_loss: 12.2246 - val_mae: 2.5018\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.9095 - mae: 2.3146 - val_loss: 12.1890 - val_mae: 2.4947\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.9431 - mae: 2.3055 - val_loss: 12.0916 - val_mae: 2.4848\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.8200 - mae: 2.3070 - val_loss: 12.2378 - val_mae: 2.5086\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.7441 - mae: 2.3104 - val_loss: 12.0260 - val_mae: 2.4787\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.6992 - mae: 2.2773 - val_loss: 11.6958 - val_mae: 2.4221\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.6732 - mae: 2.2837 - val_loss: 11.9381 - val_mae: 2.4707\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 10.6064 - mae: 2.2921 - val_loss: 12.1424 - val_mae: 2.5087\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.6543 - mae: 2.3083 - val_loss: 11.9248 - val_mae: 2.4731\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.5441 - mae: 2.2702 - val_loss: 11.3917 - val_mae: 2.3773\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.5893 - mae: 2.2704 - val_loss: 11.4496 - val_mae: 2.4009\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.4199 - mae: 2.2470 - val_loss: 11.4753 - val_mae: 2.4089\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.4810 - mae: 2.2623 - val_loss: 11.7244 - val_mae: 2.4424\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.3480 - mae: 2.2429 - val_loss: 11.5875 - val_mae: 2.4166\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.2340 - mae: 2.2397 - val_loss: 11.6156 - val_mae: 2.4307\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.2060 - mae: 2.2472 - val_loss: 11.4660 - val_mae: 2.4138\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.1178 - mae: 2.2370 - val_loss: 11.4103 - val_mae: 2.4069\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.0526 - mae: 2.2324 - val_loss: 11.4945 - val_mae: 2.4255\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 10.0481 - mae: 2.2336 - val_loss: 11.3656 - val_mae: 2.4079\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.0224 - mae: 2.2165 - val_loss: 11.1385 - val_mae: 2.3663\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.9474 - mae: 2.1988 - val_loss: 11.3308 - val_mae: 2.4097\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.9560 - mae: 2.2457 - val_loss: 11.6332 - val_mae: 2.4662\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.8677 - mae: 2.2310 - val_loss: 11.0710 - val_mae: 2.3665\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.8524 - mae: 2.2105 - val_loss: 10.9048 - val_mae: 2.3516\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.7482 - mae: 2.2071 - val_loss: 11.2340 - val_mae: 2.4111\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.6887 - mae: 2.2179 - val_loss: 11.2830 - val_mae: 2.4120\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.6892 - mae: 2.2020 - val_loss: 11.0409 - val_mae: 2.3420\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.6133 - mae: 2.1982 - val_loss: 11.4682 - val_mae: 2.4143\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.7361 - mae: 2.2174 - val_loss: 11.4214 - val_mae: 2.4078\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.6002 - mae: 2.1728 - val_loss: 10.7951 - val_mae: 2.3078\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.5287 - mae: 2.1608 - val_loss: 11.1039 - val_mae: 2.3729\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.4097 - mae: 2.1718 - val_loss: 11.3249 - val_mae: 2.4225\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.4996 - mae: 2.2008 - val_loss: 11.1746 - val_mae: 2.4023\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.3028 - mae: 2.1651 - val_loss: 10.8543 - val_mae: 2.3347\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.2091 - mae: 2.1504 - val_loss: 10.8935 - val_mae: 2.3448\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.2638 - mae: 2.1614 - val_loss: 11.0412 - val_mae: 2.3907\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.8330 - mae: 2.2610 - val_loss: 11.2326 - val_mae: 2.4117\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.5763 - mae: 2.2421 - val_loss: 10.7279 - val_mae: 2.3079\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 9.1983 - mae: 2.1587 - val_loss: 10.7070 - val_mae: 2.3157\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.1319 - mae: 2.1446 - val_loss: 10.6290 - val_mae: 2.2985\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.9512 - mae: 2.1343 - val_loss: 10.7326 - val_mae: 2.3266\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.9455 - mae: 2.1199 - val_loss: 10.8907 - val_mae: 2.3491\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.9464 - mae: 2.1118 - val_loss: 10.8877 - val_mae: 2.3456\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.7495 - mae: 2.0943 - val_loss: 10.6667 - val_mae: 2.3326\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.8731 - mae: 2.1430 - val_loss: 10.6551 - val_mae: 2.3561\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.9320 - mae: 2.1731 - val_loss: 11.0407 - val_mae: 2.3697\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.6689 - mae: 2.1178 - val_loss: 10.8107 - val_mae: 2.3036\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.6829 - mae: 2.0791 - val_loss: 10.8150 - val_mae: 2.3167\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.5745 - mae: 2.0752 - val_loss: 10.6708 - val_mae: 2.3240\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.5625 - mae: 2.0868 - val_loss: 10.6470 - val_mae: 2.3409\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.9506 - mae: 2.1549 - val_loss: 11.7127 - val_mae: 2.4484\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.9534 - mae: 2.1511 - val_loss: 11.2130 - val_mae: 2.3355\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.5018 - mae: 2.0614 - val_loss: 11.0118 - val_mae: 2.3230\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.3339 - mae: 2.0471 - val_loss: 10.7990 - val_mae: 2.3102\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.2609 - mae: 2.0357 - val_loss: 10.6188 - val_mae: 2.2975\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.3089 - mae: 2.0578 - val_loss: 10.7793 - val_mae: 2.3476\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.2696 - mae: 2.0786 - val_loss: 10.4701 - val_mae: 2.2732\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.1747 - mae: 2.0315 - val_loss: 10.5107 - val_mae: 2.2932\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.1505 - mae: 2.0141 - val_loss: 10.3764 - val_mae: 2.2737\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.0654 - mae: 2.0164 - val_loss: 10.2614 - val_mae: 2.2646\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.0020 - mae: 2.0241 - val_loss: 10.4026 - val_mae: 2.2946\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.9416 - mae: 2.0103 - val_loss: 10.2763 - val_mae: 2.2506\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.1769 - mae: 2.0610 - val_loss: 10.8620 - val_mae: 2.2968\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.0153 - mae: 2.0261 - val_loss: 11.0791 - val_mae: 2.3282\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.8877 - mae: 2.0021 - val_loss: 10.8105 - val_mae: 2.2926\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.8084 - mae: 1.9879 - val_loss: 10.5872 - val_mae: 2.2789\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.7156 - mae: 1.9774 - val_loss: 10.4567 - val_mae: 2.2886\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.6529 - mae: 1.9747 - val_loss: 10.3527 - val_mae: 2.2678\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.6782 - mae: 1.9642 - val_loss: 10.5517 - val_mae: 2.2912\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.5830 - mae: 1.9454 - val_loss: 10.4703 - val_mae: 2.2968\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.5587 - mae: 1.9769 - val_loss: 10.4106 - val_mae: 2.3094\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.5339 - mae: 1.9864 - val_loss: 10.2747 - val_mae: 2.2844\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.4060 - mae: 1.9579 - val_loss: 10.4348 - val_mae: 2.3107\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7.3863 - mae: 1.9425 - val_loss: 10.3293 - val_mae: 2.2889\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.3700 - mae: 1.9267 - val_loss: 10.0837 - val_mae: 2.2567\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 7.4454 - mae: 1.9427 - val_loss: 9.9834 - val_mae: 2.2677\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7.3331 - mae: 1.9390 - val_loss: 10.1002 - val_mae: 2.2995\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 7.2699 - mae: 1.9557 - val_loss: 10.0577 - val_mae: 2.2942\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 7.1938 - mae: 1.9335 - val_loss: 10.1771 - val_mae: 2.2902\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 7.1841 - mae: 1.9141 - val_loss: 10.1666 - val_mae: 2.2820\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 7.1597 - mae: 1.9140 - val_loss: 10.1636 - val_mae: 2.2820\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 7.0436 - mae: 1.8996 - val_loss: 10.0835 - val_mae: 2.2529\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7.0753 - mae: 1.8953 - val_loss: 10.1813 - val_mae: 2.2770\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 7.2259 - mae: 1.9593 - val_loss: 10.7362 - val_mae: 2.3309\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 7.4053 - mae: 1.9938 - val_loss: 10.4793 - val_mae: 2.2760\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 7.0769 - mae: 1.9227 - val_loss: 10.3346 - val_mae: 2.2498\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.1291 - mae: 1.9181 - val_loss: 9.8808 - val_mae: 2.2331\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 7.0068 - mae: 1.9189 - val_loss: 10.0698 - val_mae: 2.2703\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.8653 - mae: 1.9138 - val_loss: 10.1492 - val_mae: 2.2799\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6.8203 - mae: 1.8973 - val_loss: 9.9688 - val_mae: 2.2531\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6.7735 - mae: 1.8980 - val_loss: 9.9145 - val_mae: 2.2387\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.7293 - mae: 1.8570 - val_loss: 9.8628 - val_mae: 2.2501\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.7846 - mae: 1.8824 - val_loss: 10.0467 - val_mae: 2.2863\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 6.6984 - mae: 1.8485 - val_loss: 9.6867 - val_mae: 2.2302\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.7055 - mae: 1.8614 - val_loss: 9.6561 - val_mae: 2.2360\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.6228 - mae: 1.8602 - val_loss: 9.6165 - val_mae: 2.2287\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.5408 - mae: 1.8384 - val_loss: 9.7074 - val_mae: 2.2426\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.5006 - mae: 1.8421 - val_loss: 9.8968 - val_mae: 2.2623\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.5365 - mae: 1.8487 - val_loss: 9.6581 - val_mae: 2.2337\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.3989 - mae: 1.8310 - val_loss: 10.0416 - val_mae: 2.2954\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.6700 - mae: 1.8842 - val_loss: 9.8321 - val_mae: 2.2710\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.4999 - mae: 1.8286 - val_loss: 9.4827 - val_mae: 2.2158\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6.4353 - mae: 1.8258 - val_loss: 9.5199 - val_mae: 2.2111\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 6.3838 - mae: 1.8345 - val_loss: 9.7544 - val_mae: 2.2586\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.3504 - mae: 1.8215 - val_loss: 9.5399 - val_mae: 2.2140\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.3041 - mae: 1.7993 - val_loss: 9.5641 - val_mae: 2.2230\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.4059 - mae: 1.7945 - val_loss: 9.3686 - val_mae: 2.1975\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.6051 - mae: 1.8216 - val_loss: 9.0359 - val_mae: 2.1707\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.3090 - mae: 1.8243 - val_loss: 9.3569 - val_mae: 2.2581\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.3190 - mae: 1.8475 - val_loss: 9.4436 - val_mae: 2.2468\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6.2717 - mae: 1.8182 - val_loss: 9.2939 - val_mae: 2.2081\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.1324 - mae: 1.8196 - val_loss: 9.4295 - val_mae: 2.2525\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6.1300 - mae: 1.8093 - val_loss: 9.2879 - val_mae: 2.2069\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.0569 - mae: 1.7694 - val_loss: 9.3985 - val_mae: 2.2106\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 6.0325 - mae: 1.7526 - val_loss: 9.2632 - val_mae: 2.2073\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6.1077 - mae: 1.7828 - val_loss: 9.3791 - val_mae: 2.2381\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 5.9280 - mae: 1.7561 - val_loss: 9.1747 - val_mae: 2.1762\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 5.9529 - mae: 1.7457 - val_loss: 9.1916 - val_mae: 2.1633\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 5.9602 - mae: 1.7456 - val_loss: 9.1142 - val_mae: 2.1692\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 5.9096 - mae: 1.7716 - val_loss: 9.2564 - val_mae: 2.2000\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 5.9420 - mae: 1.7416 - val_loss: 9.2131 - val_mae: 2.1734\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 5.8889 - mae: 1.7437 - val_loss: 9.3894 - val_mae: 2.2063\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.8495 - mae: 1.7506 - val_loss: 9.3572 - val_mae: 2.2192\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.7958 - mae: 1.7329 - val_loss: 9.3487 - val_mae: 2.1953\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.7754 - mae: 1.7140 - val_loss: 9.1648 - val_mae: 2.1464\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 5.7193 - mae: 1.7052 - val_loss: 9.2063 - val_mae: 2.1699\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.8398 - mae: 1.7651 - val_loss: 10.2966 - val_mae: 2.2919\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.9777 - mae: 1.7497 - val_loss: 10.0086 - val_mae: 2.2289\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.8966 - mae: 1.7548 - val_loss: 10.1883 - val_mae: 2.2592\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.6656 - mae: 1.7055 - val_loss: 9.5603 - val_mae: 2.1978\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.6708 - mae: 1.7180 - val_loss: 9.4809 - val_mae: 2.2012\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.5738 - mae: 1.6976 - val_loss: 9.5207 - val_mae: 2.2144\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.5998 - mae: 1.7145 - val_loss: 9.7330 - val_mae: 2.2494\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.5069 - mae: 1.6880 - val_loss: 9.5759 - val_mae: 2.2136\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.5502 - mae: 1.6976 - val_loss: 9.0963 - val_mae: 2.1896\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.4974 - mae: 1.6920 - val_loss: 9.0205 - val_mae: 2.1708\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.5001 - mae: 1.6917 - val_loss: 9.0707 - val_mae: 2.1602\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.4475 - mae: 1.6830 - val_loss: 9.2091 - val_mae: 2.1761\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.3959 - mae: 1.6617 - val_loss: 9.3242 - val_mae: 2.2043\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.4258 - mae: 1.6871 - val_loss: 9.4652 - val_mae: 2.2383\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.4281 - mae: 1.6977 - val_loss: 9.4322 - val_mae: 2.2365\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 5.5152 - mae: 1.6726 - val_loss: 9.1944 - val_mae: 2.1641\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.3707 - mae: 1.6492 - val_loss: 9.3467 - val_mae: 2.1974\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.3173 - mae: 1.6629 - val_loss: 9.1558 - val_mae: 2.1652\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.3941 - mae: 1.6950 - val_loss: 9.2735 - val_mae: 2.1673\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.2834 - mae: 1.6496 - val_loss: 9.1418 - val_mae: 2.1537\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.3005 - mae: 1.6356 - val_loss: 9.4074 - val_mae: 2.1837\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.2761 - mae: 1.6711 - val_loss: 9.1461 - val_mae: 2.1776\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.3914 - mae: 1.6542 - val_loss: 8.9386 - val_mae: 2.1081\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.3482 - mae: 1.6628 - val_loss: 8.8163 - val_mae: 2.1504\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.2268 - mae: 1.6523 - val_loss: 9.0568 - val_mae: 2.1587\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.1810 - mae: 1.6374 - val_loss: 8.9797 - val_mae: 2.1593\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1289 - mae: 1.6403 - val_loss: 8.8889 - val_mae: 2.1145\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.0883 - mae: 1.6116 - val_loss: 8.8598 - val_mae: 2.1172\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.0389 - mae: 1.6030 - val_loss: 8.9379 - val_mae: 2.1241\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.0404 - mae: 1.6032 - val_loss: 9.0132 - val_mae: 2.1258\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.0523 - mae: 1.6016 - val_loss: 9.2959 - val_mae: 2.1350\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.0615 - mae: 1.5890 - val_loss: 9.1594 - val_mae: 2.1241\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1735 - mae: 1.6304 - val_loss: 9.0951 - val_mae: 2.1309\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.0797 - mae: 1.6051 - val_loss: 8.8745 - val_mae: 2.0935\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.0092 - mae: 1.5990 - val_loss: 9.1420 - val_mae: 2.1534\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.9231 - mae: 1.5923 - val_loss: 9.0000 - val_mae: 2.1304\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.9214 - mae: 1.5749 - val_loss: 9.0449 - val_mae: 2.1380\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.9159 - mae: 1.5756 - val_loss: 9.0563 - val_mae: 2.1351\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.9192 - mae: 1.5645 - val_loss: 9.1601 - val_mae: 2.1376\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.8653 - mae: 1.5682 - val_loss: 9.1871 - val_mae: 2.1441\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.8546 - mae: 1.5641 - val_loss: 9.0089 - val_mae: 2.1410\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9546 - mae: 1.5979 - val_loss: 8.7953 - val_mae: 2.1465\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.8962 - mae: 1.5816 - val_loss: 8.8168 - val_mae: 2.1137\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9738 - mae: 1.5727 - val_loss: 9.2333 - val_mae: 2.1765\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9638 - mae: 1.6083 - val_loss: 9.2561 - val_mae: 2.2200\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7894 - mae: 1.5654 - val_loss: 9.0088 - val_mae: 2.1357\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.8852 - mae: 1.5792 - val_loss: 9.1973 - val_mae: 2.2466\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.0197 - mae: 1.6267 - val_loss: 9.5210 - val_mae: 2.2215\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.8974 - mae: 1.6081 - val_loss: 9.2312 - val_mae: 2.2173\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.8468 - mae: 1.5765 - val_loss: 9.0594 - val_mae: 2.1407\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.7621 - mae: 1.5591 - val_loss: 9.1196 - val_mae: 2.1424\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7285 - mae: 1.5324 - val_loss: 9.0855 - val_mae: 2.1607\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.8028 - mae: 1.5958 - val_loss: 9.6321 - val_mae: 2.2828\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.8671 - mae: 1.5734 - val_loss: 9.0731 - val_mae: 2.1398\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7577 - mae: 1.5465 - val_loss: 9.0083 - val_mae: 2.1766\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9664 - mae: 1.6426 - val_loss: 9.1710 - val_mae: 2.1777\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.6704 - mae: 1.5328 - val_loss: 8.9608 - val_mae: 2.1346\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7020 - mae: 1.5254 - val_loss: 9.0793 - val_mae: 2.1645\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.7532 - mae: 1.5909 - val_loss: 9.0245 - val_mae: 2.2091\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.6830 - mae: 1.5392 - val_loss: 8.8758 - val_mae: 2.1411\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.5787 - mae: 1.5072 - val_loss: 9.1299 - val_mae: 2.2092\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.5303 - mae: 1.5098 - val_loss: 9.0077 - val_mae: 2.1747\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.5807 - mae: 1.5040 - val_loss: 8.9848 - val_mae: 2.1392\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.5798 - mae: 1.5128 - val_loss: 8.7034 - val_mae: 2.1205\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.5511 - mae: 1.5225 - val_loss: 8.9219 - val_mae: 2.1473\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.5006 - mae: 1.5130 - val_loss: 9.0623 - val_mae: 2.1364\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.4891 - mae: 1.4905 - val_loss: 9.1649 - val_mae: 2.1909\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.4512 - mae: 1.5028 - val_loss: 9.4283 - val_mae: 2.2329\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.4640 - mae: 1.4977 - val_loss: 9.1866 - val_mae: 2.1759\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.4257 - mae: 1.4887 - val_loss: 9.0530 - val_mae: 2.1459\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.4171 - mae: 1.4874 - val_loss: 9.1300 - val_mae: 2.1941\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.3957 - mae: 1.4782 - val_loss: 9.1511 - val_mae: 2.2041\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.4186 - mae: 1.4977 - val_loss: 9.0405 - val_mae: 2.1852\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3338 - mae: 1.4705 - val_loss: 9.0624 - val_mae: 2.1564\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3656 - mae: 1.4649 - val_loss: 9.2243 - val_mae: 2.1959\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.3388 - mae: 1.4642 - val_loss: 9.1100 - val_mae: 2.1742\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.3022 - mae: 1.4716 - val_loss: 9.1253 - val_mae: 2.1748\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.3217 - mae: 1.4747 - val_loss: 9.2845 - val_mae: 2.2063\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.3629 - mae: 1.4665 - val_loss: 9.0131 - val_mae: 2.1630\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.3605 - mae: 1.5106 - val_loss: 9.0552 - val_mae: 2.2153\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.2646 - mae: 1.4698 - val_loss: 8.9377 - val_mae: 2.1382\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.3196 - mae: 1.4619 - val_loss: 9.1913 - val_mae: 2.1687\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.3355 - mae: 1.4921 - val_loss: 9.1549 - val_mae: 2.2046\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.2589 - mae: 1.4795 - val_loss: 9.1221 - val_mae: 2.2120\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.3194 - mae: 1.4938 - val_loss: 9.4325 - val_mae: 2.2659\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.2863 - mae: 1.4618 - val_loss: 9.2207 - val_mae: 2.1765\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.2595 - mae: 1.4478 - val_loss: 9.0114 - val_mae: 2.1613\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3641 - mae: 1.5167 - val_loss: 9.1304 - val_mae: 2.2071\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.2684 - mae: 1.4568 - val_loss: 9.1538 - val_mae: 2.1553\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.2780 - mae: 1.4754 - val_loss: 9.5233 - val_mae: 2.2573\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 7.8761 - mae: 1.9751\n",
            "Epoch 1/300\n",
            "11/11 [==============================] - 1s 22ms/step - loss: 565.5410 - mae: 21.9120 - val_loss: 460.9772 - val_mae: 19.7512\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 524.5430 - mae: 21.0135 - val_loss: 423.6484 - val_mae: 18.8381\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 481.7188 - mae: 20.0076 - val_loss: 381.3335 - val_mae: 17.7351\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 432.8112 - mae: 18.7947 - val_loss: 331.8937 - val_mae: 16.3338\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 373.6907 - mae: 17.2444 - val_loss: 273.6670 - val_mae: 14.5668\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 303.9382 - mae: 15.2235 - val_loss: 211.4897 - val_mae: 12.5194\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 231.9910 - mae: 12.8590 - val_loss: 152.3242 - val_mae: 10.4806\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 166.6625 - mae: 10.3694 - val_loss: 107.2840 - val_mae: 8.6790\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 118.4420 - mae: 8.3967 - val_loss: 81.7757 - val_mae: 7.4481\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 91.4613 - mae: 7.2096 - val_loss: 67.4379 - val_mae: 6.6464\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 73.0161 - mae: 6.4030 - val_loss: 55.0189 - val_mae: 5.9595\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 59.7854 - mae: 5.7589 - val_loss: 43.9389 - val_mae: 5.3041\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 49.8931 - mae: 5.2057 - val_loss: 35.0175 - val_mae: 4.7252\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 41.7259 - mae: 4.6995 - val_loss: 29.0251 - val_mae: 4.2790\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 35.9057 - mae: 4.3519 - val_loss: 25.5027 - val_mae: 3.9826\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 31.7971 - mae: 4.0668 - val_loss: 21.9817 - val_mae: 3.6480\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 28.7728 - mae: 3.8600 - val_loss: 19.3254 - val_mae: 3.4084\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 26.6525 - mae: 3.6607 - val_loss: 17.2068 - val_mae: 3.2262\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 25.2579 - mae: 3.5182 - val_loss: 16.0634 - val_mae: 3.1050\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 24.2510 - mae: 3.4426 - val_loss: 15.4905 - val_mae: 3.0253\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 23.3509 - mae: 3.3916 - val_loss: 14.9999 - val_mae: 2.9533\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 22.7228 - mae: 3.3355 - val_loss: 14.4143 - val_mae: 2.8887\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 22.0635 - mae: 3.2985 - val_loss: 14.3573 - val_mae: 2.9010\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 21.4701 - mae: 3.2551 - val_loss: 14.0643 - val_mae: 2.8548\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 21.0411 - mae: 3.2134 - val_loss: 13.6782 - val_mae: 2.7946\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 20.5400 - mae: 3.1755 - val_loss: 13.3630 - val_mae: 2.7490\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 20.1202 - mae: 3.1395 - val_loss: 13.1758 - val_mae: 2.7206\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 19.7410 - mae: 3.1003 - val_loss: 12.6420 - val_mae: 2.6749\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 19.4050 - mae: 3.0582 - val_loss: 12.6103 - val_mae: 2.6817\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 19.0102 - mae: 3.0377 - val_loss: 12.8367 - val_mae: 2.6960\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 18.7000 - mae: 3.0388 - val_loss: 12.8682 - val_mae: 2.6795\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 18.3781 - mae: 3.0313 - val_loss: 13.1103 - val_mae: 2.7105\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 18.0242 - mae: 3.0014 - val_loss: 12.6294 - val_mae: 2.6389\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.6976 - mae: 2.9522 - val_loss: 11.8185 - val_mae: 2.5520\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 17.4903 - mae: 2.8972 - val_loss: 11.4540 - val_mae: 2.5145\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 17.1237 - mae: 2.8654 - val_loss: 11.4819 - val_mae: 2.5103\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.8441 - mae: 2.8684 - val_loss: 11.8407 - val_mae: 2.5417\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 16.5111 - mae: 2.8428 - val_loss: 11.4663 - val_mae: 2.4956\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 16.2565 - mae: 2.8162 - val_loss: 11.4096 - val_mae: 2.4907\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 16.1586 - mae: 2.8166 - val_loss: 11.3600 - val_mae: 2.4812\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 15.8717 - mae: 2.7829 - val_loss: 10.9927 - val_mae: 2.4382\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 15.5449 - mae: 2.7608 - val_loss: 11.3820 - val_mae: 2.5008\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 15.3572 - mae: 2.7699 - val_loss: 11.7781 - val_mae: 2.5642\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 15.2188 - mae: 2.7900 - val_loss: 12.3968 - val_mae: 2.6497\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 15.0972 - mae: 2.7691 - val_loss: 11.5438 - val_mae: 2.5478\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 14.8516 - mae: 2.7289 - val_loss: 10.9103 - val_mae: 2.4710\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 14.7043 - mae: 2.7059 - val_loss: 10.9653 - val_mae: 2.4831\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 14.5975 - mae: 2.6915 - val_loss: 10.5304 - val_mae: 2.4169\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 14.3352 - mae: 2.6655 - val_loss: 10.8438 - val_mae: 2.4736\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 14.6222 - mae: 2.7402 - val_loss: 13.6018 - val_mae: 2.7936\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 14.2624 - mae: 2.7292 - val_loss: 12.2264 - val_mae: 2.6216\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.8488 - mae: 2.6807 - val_loss: 11.5609 - val_mae: 2.5556\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 13.8608 - mae: 2.6306 - val_loss: 10.5673 - val_mae: 2.4387\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 13.6022 - mae: 2.6004 - val_loss: 10.9888 - val_mae: 2.4972\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.4310 - mae: 2.6144 - val_loss: 11.4081 - val_mae: 2.5495\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 13.3305 - mae: 2.5870 - val_loss: 10.5732 - val_mae: 2.4470\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 13.2845 - mae: 2.5747 - val_loss: 11.1698 - val_mae: 2.5244\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 13.0337 - mae: 2.5681 - val_loss: 10.9117 - val_mae: 2.4904\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.9430 - mae: 2.5433 - val_loss: 10.9233 - val_mae: 2.4949\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.8180 - mae: 2.5344 - val_loss: 10.9906 - val_mae: 2.5087\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.8014 - mae: 2.5419 - val_loss: 11.1011 - val_mae: 2.5258\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 12.7191 - mae: 2.5215 - val_loss: 10.6825 - val_mae: 2.4690\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 12.6103 - mae: 2.5169 - val_loss: 11.5073 - val_mae: 2.5593\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.5982 - mae: 2.5339 - val_loss: 12.0118 - val_mae: 2.6248\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 12.6793 - mae: 2.5863 - val_loss: 13.6824 - val_mae: 2.7951\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 12.6471 - mae: 2.5441 - val_loss: 11.7088 - val_mae: 2.5825\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 12.1894 - mae: 2.5000 - val_loss: 11.5405 - val_mae: 2.5663\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 12.0904 - mae: 2.4678 - val_loss: 10.9064 - val_mae: 2.4810\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 11.9966 - mae: 2.4554 - val_loss: 11.0131 - val_mae: 2.4920\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 11.9402 - mae: 2.4606 - val_loss: 11.6098 - val_mae: 2.5710\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.8691 - mae: 2.4640 - val_loss: 11.4504 - val_mae: 2.5547\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.7661 - mae: 2.4353 - val_loss: 10.9893 - val_mae: 2.4912\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.7808 - mae: 2.4205 - val_loss: 10.6712 - val_mae: 2.4410\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.6812 - mae: 2.4162 - val_loss: 10.8385 - val_mae: 2.4801\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 11.5156 - mae: 2.4132 - val_loss: 11.0153 - val_mae: 2.5080\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.4490 - mae: 2.4041 - val_loss: 10.6038 - val_mae: 2.4450\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.4576 - mae: 2.3824 - val_loss: 10.5355 - val_mae: 2.4348\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.3652 - mae: 2.3842 - val_loss: 10.8200 - val_mae: 2.4978\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.3073 - mae: 2.3913 - val_loss: 11.3256 - val_mae: 2.5466\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.2159 - mae: 2.3848 - val_loss: 11.1386 - val_mae: 2.5075\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.0784 - mae: 2.3620 - val_loss: 11.3652 - val_mae: 2.5326\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 11.1522 - mae: 2.3741 - val_loss: 11.5147 - val_mae: 2.5449\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.9630 - mae: 2.3457 - val_loss: 10.6826 - val_mae: 2.4320\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 11.0616 - mae: 2.3482 - val_loss: 10.8116 - val_mae: 2.4490\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.8783 - mae: 2.3196 - val_loss: 10.5189 - val_mae: 2.4139\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.8467 - mae: 2.3056 - val_loss: 10.5054 - val_mae: 2.4162\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.6648 - mae: 2.3051 - val_loss: 11.2607 - val_mae: 2.5182\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.7186 - mae: 2.3012 - val_loss: 10.6525 - val_mae: 2.4311\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.7219 - mae: 2.3116 - val_loss: 10.8208 - val_mae: 2.4828\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.6045 - mae: 2.3122 - val_loss: 11.3726 - val_mae: 2.5211\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.4940 - mae: 2.2898 - val_loss: 10.9078 - val_mae: 2.4679\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.3665 - mae: 2.2724 - val_loss: 11.2336 - val_mae: 2.5107\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.3197 - mae: 2.2827 - val_loss: 11.2992 - val_mae: 2.5183\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.3361 - mae: 2.2751 - val_loss: 10.2375 - val_mae: 2.3864\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.3877 - mae: 2.2664 - val_loss: 10.8311 - val_mae: 2.4496\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 10.2007 - mae: 2.2581 - val_loss: 11.1201 - val_mae: 2.4884\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 10.2262 - mae: 2.2711 - val_loss: 10.8812 - val_mae: 2.4664\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 10.0264 - mae: 2.2328 - val_loss: 11.2721 - val_mae: 2.5047\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 10.1157 - mae: 2.2414 - val_loss: 11.0189 - val_mae: 2.4773\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 10.0438 - mae: 2.2501 - val_loss: 11.5899 - val_mae: 2.5482\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 9.8931 - mae: 2.2367 - val_loss: 10.9543 - val_mae: 2.4573\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.9114 - mae: 2.2217 - val_loss: 10.7402 - val_mae: 2.4360\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.8767 - mae: 2.2171 - val_loss: 11.2032 - val_mae: 2.4844\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.8381 - mae: 2.2197 - val_loss: 11.4764 - val_mae: 2.5258\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.7206 - mae: 2.2129 - val_loss: 11.9441 - val_mae: 2.5650\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.9162 - mae: 2.2520 - val_loss: 13.0882 - val_mae: 2.6889\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.7291 - mae: 2.2299 - val_loss: 11.4050 - val_mae: 2.5025\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.5745 - mae: 2.1998 - val_loss: 11.2857 - val_mae: 2.4858\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 9.5008 - mae: 2.1834 - val_loss: 11.3221 - val_mae: 2.4866\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.4520 - mae: 2.1776 - val_loss: 11.2685 - val_mae: 2.4897\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.3834 - mae: 2.1984 - val_loss: 12.1828 - val_mae: 2.5867\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.3448 - mae: 2.1723 - val_loss: 11.5409 - val_mae: 2.5027\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.3651 - mae: 2.1836 - val_loss: 11.3389 - val_mae: 2.4793\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.1966 - mae: 2.1453 - val_loss: 10.9259 - val_mae: 2.4351\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.1860 - mae: 2.1398 - val_loss: 11.0642 - val_mae: 2.4521\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.1322 - mae: 2.1521 - val_loss: 11.7853 - val_mae: 2.5355\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.2325 - mae: 2.1941 - val_loss: 12.0399 - val_mae: 2.6057\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.0418 - mae: 2.1485 - val_loss: 10.8575 - val_mae: 2.4340\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.9892 - mae: 2.1300 - val_loss: 10.8529 - val_mae: 2.4219\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.9654 - mae: 2.1220 - val_loss: 10.9255 - val_mae: 2.4303\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.9052 - mae: 2.1074 - val_loss: 10.9878 - val_mae: 2.4410\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.8196 - mae: 2.1120 - val_loss: 11.9564 - val_mae: 2.5450\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 9.7683 - mae: 2.2429 - val_loss: 15.3706 - val_mae: 2.8655\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.8429 - mae: 2.1768 - val_loss: 10.7083 - val_mae: 2.3997\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 9.0514 - mae: 2.1281 - val_loss: 10.2567 - val_mae: 2.3668\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.7542 - mae: 2.1025 - val_loss: 11.3140 - val_mae: 2.4830\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.6307 - mae: 2.1042 - val_loss: 11.4776 - val_mae: 2.4898\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.5959 - mae: 2.0873 - val_loss: 11.2000 - val_mae: 2.4617\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8.5616 - mae: 2.0805 - val_loss: 11.2485 - val_mae: 2.4675\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.7570 - mae: 2.1286 - val_loss: 12.1792 - val_mae: 2.5607\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.5462 - mae: 2.1103 - val_loss: 11.4452 - val_mae: 2.4713\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 8.4402 - mae: 2.0669 - val_loss: 10.5703 - val_mae: 2.3824\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.4726 - mae: 2.0595 - val_loss: 10.8376 - val_mae: 2.4113\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.3348 - mae: 2.0651 - val_loss: 11.7140 - val_mae: 2.5209\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.3893 - mae: 2.0858 - val_loss: 11.6187 - val_mae: 2.5063\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.3407 - mae: 2.0671 - val_loss: 10.9406 - val_mae: 2.4166\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.3706 - mae: 2.0516 - val_loss: 10.7352 - val_mae: 2.4041\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.2242 - mae: 2.0401 - val_loss: 12.1596 - val_mae: 2.5511\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.6282 - mae: 2.1323 - val_loss: 12.5790 - val_mae: 2.6055\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.4998 - mae: 2.0801 - val_loss: 10.6368 - val_mae: 2.4312\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.1560 - mae: 2.0484 - val_loss: 11.1380 - val_mae: 2.4347\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.2022 - mae: 2.0366 - val_loss: 10.7358 - val_mae: 2.3910\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.1365 - mae: 2.0255 - val_loss: 11.1185 - val_mae: 2.4271\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.0926 - mae: 2.0116 - val_loss: 10.6709 - val_mae: 2.3823\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.9653 - mae: 2.0086 - val_loss: 11.3477 - val_mae: 2.4562\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.0228 - mae: 2.0040 - val_loss: 10.3051 - val_mae: 2.3496\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.0283 - mae: 2.0115 - val_loss: 10.7899 - val_mae: 2.4041\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.9354 - mae: 1.9951 - val_loss: 10.8495 - val_mae: 2.4026\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 8.4352 - mae: 2.0821 - val_loss: 13.9317 - val_mae: 2.7141\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 8.1407 - mae: 2.0569 - val_loss: 11.4675 - val_mae: 2.4508\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7.9572 - mae: 1.9864 - val_loss: 10.7340 - val_mae: 2.3834\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.8898 - mae: 2.0049 - val_loss: 11.2692 - val_mae: 2.4358\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 8.3672 - mae: 2.0914 - val_loss: 14.0713 - val_mae: 2.7107\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 8.2011 - mae: 2.0366 - val_loss: 11.3330 - val_mae: 2.4257\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 7.7787 - mae: 2.0009 - val_loss: 11.1289 - val_mae: 2.4258\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.8098 - mae: 2.0200 - val_loss: 11.4664 - val_mae: 2.4760\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 7.6756 - mae: 1.9982 - val_loss: 11.1151 - val_mae: 2.4410\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.6924 - mae: 1.9858 - val_loss: 10.7088 - val_mae: 2.3990\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 7.6619 - mae: 1.9839 - val_loss: 11.1493 - val_mae: 2.4292\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.5560 - mae: 1.9676 - val_loss: 10.5669 - val_mae: 2.3565\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7.7512 - mae: 1.9950 - val_loss: 11.7282 - val_mae: 2.4848\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.8222 - mae: 2.0187 - val_loss: 9.7835 - val_mae: 2.2796\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.5687 - mae: 1.9506 - val_loss: 10.8885 - val_mae: 2.3938\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.5287 - mae: 1.9872 - val_loss: 11.3016 - val_mae: 2.4419\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.4863 - mae: 1.9749 - val_loss: 11.1939 - val_mae: 2.4179\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 7.5044 - mae: 1.9660 - val_loss: 11.2959 - val_mae: 2.4186\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 7.4542 - mae: 1.9608 - val_loss: 10.7206 - val_mae: 2.3853\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 8.1340 - mae: 2.0355 - val_loss: 11.3423 - val_mae: 2.4770\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.7653 - mae: 2.0403 - val_loss: 11.8359 - val_mae: 2.5263\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 7.4097 - mae: 1.9796 - val_loss: 10.2436 - val_mae: 2.3190\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7.3957 - mae: 1.9385 - val_loss: 11.0141 - val_mae: 2.3872\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7.3134 - mae: 1.9514 - val_loss: 11.1111 - val_mae: 2.3870\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.4144 - mae: 1.9999 - val_loss: 11.6680 - val_mae: 2.4622\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.3786 - mae: 1.9704 - val_loss: 11.6801 - val_mae: 2.4554\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 7.2132 - mae: 1.9443 - val_loss: 10.8197 - val_mae: 2.3497\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.2145 - mae: 1.9077 - val_loss: 10.8631 - val_mae: 2.3998\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7.2403 - mae: 1.9231 - val_loss: 11.1441 - val_mae: 2.4015\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.3084 - mae: 2.0013 - val_loss: 11.1015 - val_mae: 2.4169\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.0968 - mae: 1.9382 - val_loss: 10.9043 - val_mae: 2.3888\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.1042 - mae: 1.9263 - val_loss: 10.8068 - val_mae: 2.3705\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 7.0859 - mae: 1.9293 - val_loss: 10.9687 - val_mae: 2.3690\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.9701 - mae: 1.9099 - val_loss: 11.1505 - val_mae: 2.4067\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 7.0186 - mae: 1.9251 - val_loss: 11.2508 - val_mae: 2.4194\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.9756 - mae: 1.9045 - val_loss: 10.5515 - val_mae: 2.3423\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 6.9169 - mae: 1.8895 - val_loss: 10.6061 - val_mae: 2.3344\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 6.8751 - mae: 1.8987 - val_loss: 10.6833 - val_mae: 2.3429\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.9723 - mae: 1.9009 - val_loss: 9.7563 - val_mae: 2.2581\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 7.0120 - mae: 1.9043 - val_loss: 10.4958 - val_mae: 2.3597\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.9423 - mae: 1.9264 - val_loss: 10.9163 - val_mae: 2.3909\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.9199 - mae: 1.9444 - val_loss: 10.1313 - val_mae: 2.2866\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.1639 - mae: 1.9334 - val_loss: 11.0734 - val_mae: 2.4040\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.8761 - mae: 1.9101 - val_loss: 9.9022 - val_mae: 2.2646\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.7500 - mae: 1.8671 - val_loss: 10.5232 - val_mae: 2.3523\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.7280 - mae: 1.8802 - val_loss: 10.9383 - val_mae: 2.3762\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.8222 - mae: 1.8962 - val_loss: 10.3057 - val_mae: 2.2775\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.7192 - mae: 1.8579 - val_loss: 10.6135 - val_mae: 2.3397\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.6571 - mae: 1.8409 - val_loss: 10.4303 - val_mae: 2.2953\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.6456 - mae: 1.8461 - val_loss: 10.2147 - val_mae: 2.2812\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.5986 - mae: 1.8417 - val_loss: 10.8134 - val_mae: 2.3620\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.7174 - mae: 1.8824 - val_loss: 10.4885 - val_mae: 2.3136\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.5863 - mae: 1.8468 - val_loss: 10.3266 - val_mae: 2.2922\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.5035 - mae: 1.8309 - val_loss: 10.6890 - val_mae: 2.3146\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.5699 - mae: 1.8467 - val_loss: 10.1854 - val_mae: 2.2531\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.5589 - mae: 1.8377 - val_loss: 9.9388 - val_mae: 2.2543\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.4465 - mae: 1.8191 - val_loss: 10.8028 - val_mae: 2.3351\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.5214 - mae: 1.8361 - val_loss: 10.3348 - val_mae: 2.2763\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.4273 - mae: 1.8100 - val_loss: 10.4685 - val_mae: 2.2858\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.4689 - mae: 1.8299 - val_loss: 10.1012 - val_mae: 2.2557\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.4227 - mae: 1.8408 - val_loss: 10.8806 - val_mae: 2.3547\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.4806 - mae: 1.8152 - val_loss: 10.5439 - val_mae: 2.3017\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.4537 - mae: 1.8119 - val_loss: 10.1833 - val_mae: 2.2482\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.3834 - mae: 1.7972 - val_loss: 10.3333 - val_mae: 2.2624\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.4706 - mae: 1.8430 - val_loss: 9.9207 - val_mae: 2.2318\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.3431 - mae: 1.8011 - val_loss: 10.3838 - val_mae: 2.2915\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.3089 - mae: 1.8090 - val_loss: 10.1281 - val_mae: 2.2510\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.2647 - mae: 1.7758 - val_loss: 10.1495 - val_mae: 2.2692\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.3495 - mae: 1.8489 - val_loss: 11.2294 - val_mae: 2.3716\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.3644 - mae: 1.8135 - val_loss: 10.3661 - val_mae: 2.2776\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.4357 - mae: 1.8460 - val_loss: 9.7785 - val_mae: 2.2238\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.3511 - mae: 1.8141 - val_loss: 10.3683 - val_mae: 2.3108\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.1298 - mae: 1.7727 - val_loss: 10.3454 - val_mae: 2.2690\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.2522 - mae: 1.8123 - val_loss: 10.1570 - val_mae: 2.2762\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.2609 - mae: 1.7877 - val_loss: 10.6282 - val_mae: 2.3208\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.2276 - mae: 1.8100 - val_loss: 9.9397 - val_mae: 2.2449\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.0878 - mae: 1.7650 - val_loss: 10.4563 - val_mae: 2.3075\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.0823 - mae: 1.7555 - val_loss: 10.1239 - val_mae: 2.2343\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.1249 - mae: 1.7983 - val_loss: 9.8657 - val_mae: 2.2443\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.1458 - mae: 1.7629 - val_loss: 9.9843 - val_mae: 2.2607\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.1011 - mae: 1.7676 - val_loss: 10.5032 - val_mae: 2.2813\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.0578 - mae: 1.7499 - val_loss: 10.0803 - val_mae: 2.2456\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 6.0690 - mae: 1.7448 - val_loss: 10.3460 - val_mae: 2.2826\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.1050 - mae: 1.8140 - val_loss: 10.4366 - val_mae: 2.2943\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 6.0276 - mae: 1.7615 - val_loss: 10.2601 - val_mae: 2.2781\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.9925 - mae: 1.7668 - val_loss: 9.8383 - val_mae: 2.2294\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 6.0731 - mae: 1.7831 - val_loss: 10.4608 - val_mae: 2.3246\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.9548 - mae: 1.7544 - val_loss: 9.7284 - val_mae: 2.2131\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.8650 - mae: 1.7243 - val_loss: 10.0987 - val_mae: 2.2648\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.9270 - mae: 1.7386 - val_loss: 10.1383 - val_mae: 2.2541\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.8098 - mae: 1.7526 - val_loss: 10.7198 - val_mae: 2.3342\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.9059 - mae: 1.7790 - val_loss: 10.4084 - val_mae: 2.3121\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.9583 - mae: 1.7726 - val_loss: 11.8595 - val_mae: 2.4508\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.9252 - mae: 1.7883 - val_loss: 10.4760 - val_mae: 2.2950\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.8270 - mae: 1.6998 - val_loss: 10.4102 - val_mae: 2.2981\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.8734 - mae: 1.7645 - val_loss: 10.5633 - val_mae: 2.3146\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.7793 - mae: 1.7270 - val_loss: 10.4522 - val_mae: 2.3282\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.7263 - mae: 1.7004 - val_loss: 9.8579 - val_mae: 2.2688\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.7014 - mae: 1.7227 - val_loss: 10.3307 - val_mae: 2.3217\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 5.6514 - mae: 1.7201 - val_loss: 10.0195 - val_mae: 2.2433\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.6120 - mae: 1.6894 - val_loss: 10.2827 - val_mae: 2.2583\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.6235 - mae: 1.6985 - val_loss: 10.1426 - val_mae: 2.2401\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.6673 - mae: 1.6807 - val_loss: 9.4939 - val_mae: 2.2053\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.5086 - mae: 1.6749 - val_loss: 10.2878 - val_mae: 2.2787\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.5380 - mae: 1.6751 - val_loss: 9.6806 - val_mae: 2.2299\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.6203 - mae: 1.7536 - val_loss: 11.0069 - val_mae: 2.3273\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.5931 - mae: 1.7198 - val_loss: 9.7511 - val_mae: 2.2030\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.5442 - mae: 1.6919 - val_loss: 9.1472 - val_mae: 2.1465\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.5816 - mae: 1.6793 - val_loss: 10.2791 - val_mae: 2.2755\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.5281 - mae: 1.6942 - val_loss: 9.6184 - val_mae: 2.1687\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.3987 - mae: 1.6624 - val_loss: 9.6707 - val_mae: 2.2081\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.4519 - mae: 1.6361 - val_loss: 9.3095 - val_mae: 2.2027\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.3406 - mae: 1.6336 - val_loss: 10.2737 - val_mae: 2.2836\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.4873 - mae: 1.6977 - val_loss: 10.4797 - val_mae: 2.2967\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.3724 - mae: 1.6302 - val_loss: 8.6635 - val_mae: 2.1230\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.5429 - mae: 1.6597 - val_loss: 9.5970 - val_mae: 2.2584\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.4676 - mae: 1.6466 - val_loss: 9.4085 - val_mae: 2.2145\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.3641 - mae: 1.6489 - val_loss: 9.6163 - val_mae: 2.2335\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.2629 - mae: 1.6086 - val_loss: 9.4285 - val_mae: 2.1942\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.2805 - mae: 1.6159 - val_loss: 9.1585 - val_mae: 2.1716\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.1671 - mae: 1.6057 - val_loss: 9.7221 - val_mae: 2.2366\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1490 - mae: 1.6140 - val_loss: 9.7508 - val_mae: 2.2120\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1397 - mae: 1.6151 - val_loss: 9.9800 - val_mae: 2.2519\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.1288 - mae: 1.6178 - val_loss: 9.4617 - val_mae: 2.2174\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.0813 - mae: 1.6113 - val_loss: 10.3011 - val_mae: 2.3131\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.5320 - mae: 1.7364 - val_loss: 12.7365 - val_mae: 2.4845\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.5156 - mae: 1.6809 - val_loss: 9.4974 - val_mae: 2.1944\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 5.0874 - mae: 1.5956 - val_loss: 10.4559 - val_mae: 2.2661\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.0423 - mae: 1.6308 - val_loss: 10.1302 - val_mae: 2.2720\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 5.1313 - mae: 1.6055 - val_loss: 9.1914 - val_mae: 2.1825\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.9932 - mae: 1.5812 - val_loss: 9.6114 - val_mae: 2.2008\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 5.0913 - mae: 1.6158 - val_loss: 10.1662 - val_mae: 2.2407\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.9252 - mae: 1.6063 - val_loss: 9.7053 - val_mae: 2.2169\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.9365 - mae: 1.5869 - val_loss: 10.0296 - val_mae: 2.2915\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.8661 - mae: 1.5671 - val_loss: 9.5032 - val_mae: 2.2290\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.8343 - mae: 1.5566 - val_loss: 10.0866 - val_mae: 2.2581\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.8792 - mae: 1.5808 - val_loss: 9.9917 - val_mae: 2.2438\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.8992 - mae: 1.5596 - val_loss: 9.5191 - val_mae: 2.1972\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7929 - mae: 1.5786 - val_loss: 9.8980 - val_mae: 2.2517\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.7727 - mae: 1.5775 - val_loss: 9.6844 - val_mae: 2.2129\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.7433 - mae: 1.5361 - val_loss: 9.7185 - val_mae: 2.2203\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.7396 - mae: 1.5607 - val_loss: 9.4381 - val_mae: 2.2126\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.7124 - mae: 1.5534 - val_loss: 9.7519 - val_mae: 2.2239\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.7661 - mae: 1.5843 - val_loss: 9.6941 - val_mae: 2.2172\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.7974 - mae: 1.5469 - val_loss: 9.5833 - val_mae: 2.2397\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.9030 - mae: 1.6223 - val_loss: 9.4414 - val_mae: 2.2715\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.6192 - mae: 1.5432 - val_loss: 9.4302 - val_mae: 2.2172\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.6328 - mae: 1.5207 - val_loss: 9.1750 - val_mae: 2.1656\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.5730 - mae: 1.5329 - val_loss: 9.9886 - val_mae: 2.2611\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.6507 - mae: 1.5213 - val_loss: 9.5074 - val_mae: 2.2259\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 4.5644 - mae: 1.5148 - val_loss: 9.5590 - val_mae: 2.2553\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.5760 - mae: 1.5416 - val_loss: 9.4080 - val_mae: 2.2303\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.5740 - mae: 2.1884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(mae_list) # 2.06 → 실제 집값과 2,060달러 차이"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNFhwl_ZUPHZ",
        "outputId": "9d9803f2-225e-4f60-fa8d-16566566d7ad"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0620089530944825"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}